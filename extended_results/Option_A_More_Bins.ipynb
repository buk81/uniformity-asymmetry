{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {"id": "header"},
      "source": [
        "# Option A: More Bins (Same Metric, More Power)\n",
        "\n",
        "**Research Question:**\n",
        "> With more statistical power (n=20-30 bins instead of n=6 categories), does the mid-layer positive regime become statistically stable?\n",
        "\n",
        "**Method:**\n",
        "- Keep the SAME UA metric (group-level uniformity difference)\n",
        "- Randomly partition 230 pairs into k bins (k=20, 25, 30)\n",
        "- Compute UA per bin\n",
        "- Correlate with output preference per bin\n",
        "- Bootstrap CI with larger n\n",
        "\n",
        "**Advantage:** No method change - same interpretation as before.\n",
        "\n",
        "---\n",
        "\n",
        "**Author:** Davide D'Elia  \n",
        "**Date:** 2026-01-03  \n",
        "**Model:** Pythia-6.9B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "setup-header"},
      "source": ["## 1. Setup"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "install"},
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate torch numpy scipy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "imports"},
      "outputs": [],
      "source": [
        "import json\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "N_BOOTSTRAP = 10000\n",
        "CI_LEVEL = 0.95\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "load-model"},
      "outputs": [],
      "source": [
        "MODEL_NAME = \"EleutherAI/pythia-6.9b\"\n",
        "MODEL_DISPLAY = \"Pythia-6.9B\"\n",
        "\n",
        "print(f\"Loading {MODEL_DISPLAY}...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    output_hidden_states=True\n",
        ")\n",
        "\n",
        "print(f\"Model loaded. Layers: {model.config.num_hidden_layers}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "load-dataset"},
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/buk81/uniformity-asymmetry/main/dataset.json\n",
        "\n",
        "with open('dataset.json', 'r') as f:\n",
        "    DATASET = json.load(f)\n",
        "\n",
        "# Flatten all pairs into a single list\n",
        "ALL_PAIRS = []\n",
        "for cat_name, cat_data in DATASET.items():\n",
        "    for pair in cat_data['pairs']:\n",
        "        ALL_PAIRS.append({\n",
        "            'stmt_a': pair[0],\n",
        "            'stmt_b': pair[1],\n",
        "            'original_category': cat_name\n",
        "        })\n",
        "\n",
        "print(f\"Total pairs: {len(ALL_PAIRS)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "functions-header"},
      "source": ["## 2. Core Functions"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "core-functions"},
      "outputs": [],
      "source": [
        "def get_layer_embedding(text: str, model, tokenizer, layer_idx: int) -> np.ndarray:\n",
        "    \"\"\"Get mean-pooled embedding from a specific layer.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states\n",
        "    \n",
        "    layer_hidden = hidden_states[layer_idx]\n",
        "    embedding = layer_hidden[0, 1:, :].mean(dim=0).cpu().numpy().astype(np.float32)\n",
        "    \n",
        "    return embedding\n",
        "\n",
        "\n",
        "def get_output_preference(text_a: str, text_b: str, model, tokenizer) -> float:\n",
        "    \"\"\"Calculate output preference as NLL(B) - NLL(A).\"\"\"\n",
        "    def get_nll(text):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "            return outputs.loss.item()\n",
        "    \n",
        "    return get_nll(text_b) - get_nll(text_a)\n",
        "\n",
        "\n",
        "def uniformity_score(embeddings: np.ndarray) -> float:\n",
        "    \"\"\"Calculate average pairwise cosine similarity.\"\"\"\n",
        "    if len(embeddings) < 2:\n",
        "        return 0.0\n",
        "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    normalized = embeddings / (norms + 1e-10)\n",
        "    kernel = normalized @ normalized.T\n",
        "    n = kernel.shape[0]\n",
        "    idx = np.triu_indices(n, k=1)\n",
        "    return float(np.mean(kernel[idx]))\n",
        "\n",
        "\n",
        "def bootstrap_correlation(x: np.ndarray, y: np.ndarray, n_bootstrap: int = 10000,\n",
        "                          ci_level: float = 0.95) -> Tuple[float, float, float, float]:\n",
        "    \"\"\"Compute bootstrap CI for Pearson correlation.\"\"\"\n",
        "    n = len(x)\n",
        "    if n < 3:\n",
        "        return 0.0, -1.0, 1.0, 1.0\n",
        "    \n",
        "    r_observed, p_value = stats.pearsonr(x, y)\n",
        "    \n",
        "    bootstrap_rs = []\n",
        "    for _ in range(n_bootstrap):\n",
        "        idx = np.random.choice(n, size=n, replace=True)\n",
        "        x_boot = x[idx]\n",
        "        y_boot = y[idx]\n",
        "        \n",
        "        if np.std(x_boot) > 0 and np.std(y_boot) > 0:\n",
        "            r_boot, _ = stats.pearsonr(x_boot, y_boot)\n",
        "            bootstrap_rs.append(r_boot)\n",
        "    \n",
        "    if len(bootstrap_rs) < 100:\n",
        "        return float(r_observed), -1.0, 1.0, float(p_value)\n",
        "    \n",
        "    bootstrap_rs = np.array(bootstrap_rs)\n",
        "    alpha = 1 - ci_level\n",
        "    ci_lower = np.percentile(bootstrap_rs, alpha/2 * 100)\n",
        "    ci_upper = np.percentile(bootstrap_rs, (1 - alpha/2) * 100)\n",
        "    \n",
        "    return float(r_observed), float(ci_lower), float(ci_upper), float(p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "collect-header"},
      "source": ["## 3. Collect All Embeddings"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "collect-embeddings"},
      "outputs": [],
      "source": [
        "# Layers to analyze\n",
        "LAYERS_TO_TEST = [0, 4, 8, 12, 16, 20, 24, 28, 32]\n",
        "\n",
        "print(f\"Collecting embeddings for {len(ALL_PAIRS)} pairs across {len(LAYERS_TO_TEST)} layers...\")\n",
        "print(f\"This will take ~30-45 minutes.\")\n",
        "\n",
        "# Store: pair_idx -> layer -> {'emb_a': ..., 'emb_b': ..., 'pref': ...}\n",
        "pair_data = []\n",
        "\n",
        "for i, pair in enumerate(ALL_PAIRS):\n",
        "    if (i + 1) % 25 == 0:\n",
        "        print(f\"  [{i+1:03d}/{len(ALL_PAIRS)}]\")\n",
        "    \n",
        "    stmt_a = pair['stmt_a']\n",
        "    stmt_b = pair['stmt_b']\n",
        "    \n",
        "    # Get output preference\n",
        "    pref = get_output_preference(stmt_a, stmt_b, model, tokenizer)\n",
        "    \n",
        "    # Get embeddings for each layer\n",
        "    layer_embeddings = {}\n",
        "    for layer_idx in LAYERS_TO_TEST:\n",
        "        emb_a = get_layer_embedding(stmt_a, model, tokenizer, layer_idx)\n",
        "        emb_b = get_layer_embedding(stmt_b, model, tokenizer, layer_idx)\n",
        "        layer_embeddings[layer_idx] = {'emb_a': emb_a, 'emb_b': emb_b}\n",
        "    \n",
        "    pair_data.append({\n",
        "        'pref': pref,\n",
        "        'original_category': pair['original_category'],\n",
        "        'layer_embeddings': layer_embeddings\n",
        "    })\n",
        "\n",
        "print(f\"\\nDone! Collected data for {len(pair_data)} pairs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "binning-header"},
      "source": ["## 4. Random Binning Analysis"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "binning-function"},
      "outputs": [],
      "source": [
        "def analyze_with_k_bins(pair_data: list, layer_idx: int, k: int, n_permutations: int = 100) -> dict:\n",
        "    \"\"\"\n",
        "    Analyze correlation with k random bins.\n",
        "    \n",
        "    Returns averaged results over n_permutations random binnings.\n",
        "    \"\"\"\n",
        "    n_pairs = len(pair_data)\n",
        "    \n",
        "    all_rs = []\n",
        "    all_ps = []\n",
        "    \n",
        "    for perm in range(n_permutations):\n",
        "        # Random assignment to bins\n",
        "        bin_assignments = np.random.randint(0, k, size=n_pairs)\n",
        "        \n",
        "        # Compute UA and mean preference per bin\n",
        "        bin_uas = []\n",
        "        bin_prefs = []\n",
        "        \n",
        "        for bin_idx in range(k):\n",
        "            bin_mask = bin_assignments == bin_idx\n",
        "            if bin_mask.sum() < 2:\n",
        "                continue\n",
        "            \n",
        "            # Get embeddings for this bin\n",
        "            bin_embs_a = []\n",
        "            bin_embs_b = []\n",
        "            bin_preferences = []\n",
        "            \n",
        "            for i, is_in_bin in enumerate(bin_mask):\n",
        "                if is_in_bin:\n",
        "                    bin_embs_a.append(pair_data[i]['layer_embeddings'][layer_idx]['emb_a'])\n",
        "                    bin_embs_b.append(pair_data[i]['layer_embeddings'][layer_idx]['emb_b'])\n",
        "                    bin_preferences.append(pair_data[i]['pref'])\n",
        "            \n",
        "            bin_embs_a = np.array(bin_embs_a)\n",
        "            bin_embs_b = np.array(bin_embs_b)\n",
        "            \n",
        "            # Compute UA for this bin\n",
        "            u_a = uniformity_score(bin_embs_a)\n",
        "            u_b = uniformity_score(bin_embs_b)\n",
        "            ua = u_a - u_b\n",
        "            \n",
        "            bin_uas.append(ua)\n",
        "            bin_prefs.append(np.mean(bin_preferences))\n",
        "        \n",
        "        # Correlation for this permutation\n",
        "        if len(bin_uas) >= 3:\n",
        "            r, p = stats.pearsonr(bin_uas, bin_prefs)\n",
        "            all_rs.append(r)\n",
        "            all_ps.append(p)\n",
        "    \n",
        "    if not all_rs:\n",
        "        return {'r_mean': 0, 'r_std': 0, 'p_mean': 1, 'n_valid': 0}\n",
        "    \n",
        "    return {\n",
        "        'r_mean': float(np.mean(all_rs)),\n",
        "        'r_std': float(np.std(all_rs)),\n",
        "        'p_mean': float(np.mean(all_ps)),\n",
        "        'n_valid': len(all_rs)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "run-binning"},
      "outputs": [],
      "source": [
        "# Test different numbers of bins\n",
        "K_VALUES = [10, 15, 20, 25, 30]\n",
        "N_PERMUTATIONS = 200\n",
        "\n",
        "print(f\"Testing k = {K_VALUES} bins with {N_PERMUTATIONS} permutations each...\")\n",
        "print(f\"Layers: {LAYERS_TO_TEST}\")\n",
        "\n",
        "results_by_k = {}\n",
        "\n",
        "for k in K_VALUES:\n",
        "    print(f\"\\n--- k = {k} bins ---\")\n",
        "    results_by_k[k] = {}\n",
        "    \n",
        "    for layer_idx in LAYERS_TO_TEST:\n",
        "        result = analyze_with_k_bins(pair_data, layer_idx, k, N_PERMUTATIONS)\n",
        "        results_by_k[k][layer_idx] = result\n",
        "        \n",
        "        r_mean = result['r_mean']\n",
        "        r_std = result['r_std']\n",
        "        print(f\"  Layer {layer_idx:2d}: r = {r_mean:+.3f} ± {r_std:.3f}\")\n",
        "\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "bootstrap-header"},
      "source": ["## 5. Bootstrap CI with Optimal k"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "bootstrap-bins"},
      "outputs": [],
      "source": [
        "# Use k=20 as a good balance (enough bins, enough pairs per bin)\n",
        "K_OPTIMAL = 20\n",
        "\n",
        "print(f\"Computing Bootstrap CI with k={K_OPTIMAL} bins...\")\n",
        "print(f\"This gives n≈{K_OPTIMAL} for correlation (vs n=6 before)\")\n",
        "\n",
        "# Create one stable binning for CI analysis\n",
        "np.random.seed(RANDOM_SEED)\n",
        "stable_bins = np.random.randint(0, K_OPTIMAL, size=len(pair_data))\n",
        "\n",
        "bootstrap_results = {}\n",
        "\n",
        "for layer_idx in LAYERS_TO_TEST:\n",
        "    # Compute UA and pref per bin\n",
        "    bin_uas = []\n",
        "    bin_prefs = []\n",
        "    \n",
        "    for bin_idx in range(K_OPTIMAL):\n",
        "        bin_mask = stable_bins == bin_idx\n",
        "        if bin_mask.sum() < 2:\n",
        "            continue\n",
        "        \n",
        "        bin_embs_a = [pair_data[i]['layer_embeddings'][layer_idx]['emb_a'] \n",
        "                      for i, m in enumerate(bin_mask) if m]\n",
        "        bin_embs_b = [pair_data[i]['layer_embeddings'][layer_idx]['emb_b'] \n",
        "                      for i, m in enumerate(bin_mask) if m]\n",
        "        bin_preferences = [pair_data[i]['pref'] for i, m in enumerate(bin_mask) if m]\n",
        "        \n",
        "        u_a = uniformity_score(np.array(bin_embs_a))\n",
        "        u_b = uniformity_score(np.array(bin_embs_b))\n",
        "        \n",
        "        bin_uas.append(u_a - u_b)\n",
        "        bin_prefs.append(np.mean(bin_preferences))\n",
        "    \n",
        "    # Bootstrap CI\n",
        "    r, ci_lower, ci_upper, p = bootstrap_correlation(\n",
        "        np.array(bin_uas), np.array(bin_prefs), N_BOOTSTRAP, CI_LEVEL\n",
        "    )\n",
        "    \n",
        "    includes_zero = ci_lower <= 0 <= ci_upper\n",
        "    \n",
        "    bootstrap_results[layer_idx] = {\n",
        "        'r': r,\n",
        "        'ci_lower': ci_lower,\n",
        "        'ci_upper': ci_upper,\n",
        "        'p_value': p,\n",
        "        'includes_zero': includes_zero,\n",
        "        'n_bins': len(bin_uas)\n",
        "    }\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\" BOOTSTRAP CI RESULTS (k={K_OPTIMAL} bins, n≈{K_OPTIMAL})\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\n{'Layer':<10} {'r':<10} {'95% CI':<25} {'Includes 0?':<15}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for layer_idx in LAYERS_TO_TEST:\n",
        "    res = bootstrap_results[layer_idx]\n",
        "    ci_str = f\"[{res['ci_lower']:+.3f}, {res['ci_upper']:+.3f}]\"\n",
        "    zero_str = \"YES\" if res['includes_zero'] else \"NO ***\"\n",
        "    print(f\"Layer {layer_idx:<4} {res['r']:+.3f}     {ci_str:<25} {zero_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "comparison-header"},
      "source": ["## 6. Comparison: n=6 vs n=20"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "comparison"},
      "outputs": [],
      "source": [
        "# Original n=6 results (from previous analysis)\n",
        "original_results = {\n",
        "    0: {'r': -0.60, 'ci_lower': -1.00, 'ci_upper': 0.95, 'includes_zero': True},\n",
        "    4: {'r': -0.81, 'ci_lower': -1.00, 'ci_upper': 0.75, 'includes_zero': True},\n",
        "    8: {'r': 0.47, 'ci_lower': -0.93, 'ci_upper': 0.96, 'includes_zero': True},\n",
        "    12: {'r': 0.21, 'ci_lower': -0.99, 'ci_upper': 0.91, 'includes_zero': True},\n",
        "    16: {'r': -0.25, 'ci_lower': -1.00, 'ci_upper': 0.64, 'includes_zero': True},\n",
        "    20: {'r': -0.25, 'ci_lower': -1.00, 'ci_upper': 0.61, 'includes_zero': True},\n",
        "    24: {'r': -0.63, 'ci_lower': -1.00, 'ci_upper': 0.03, 'includes_zero': True},\n",
        "    28: {'r': -0.81, 'ci_lower': -1.00, 'ci_upper': -0.55, 'includes_zero': False},\n",
        "    32: {'r': -0.87, 'ci_lower': -1.00, 'ci_upper': -0.12, 'includes_zero': False},\n",
        "}\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\" COMPARISON: n=6 Categories vs n={K_OPTIMAL} Bins\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\n{'Layer':<8} {'n=6 r':<10} {'n=6 CI':<20} {'n=20 r':<10} {'n=20 CI':<20} {'Change?'}\")\n",
        "print(\"-\" * 85)\n",
        "\n",
        "for layer_idx in LAYERS_TO_TEST:\n",
        "    orig = original_results.get(layer_idx, {})\n",
        "    new = bootstrap_results[layer_idx]\n",
        "    \n",
        "    orig_r = orig.get('r', 0)\n",
        "    orig_ci = f\"[{orig.get('ci_lower', -1):+.2f}, {orig.get('ci_upper', 1):+.2f}]\"\n",
        "    orig_inc = orig.get('includes_zero', True)\n",
        "    \n",
        "    new_r = new['r']\n",
        "    new_ci = f\"[{new['ci_lower']:+.2f}, {new['ci_upper']:+.2f}]\"\n",
        "    new_inc = new['includes_zero']\n",
        "    \n",
        "    # Did significance change?\n",
        "    if orig_inc and not new_inc:\n",
        "        change = \"NOW SIGNIFICANT!\"\n",
        "    elif not orig_inc and new_inc:\n",
        "        change = \"Lost significance\"\n",
        "    else:\n",
        "        change = \"No change\"\n",
        "    \n",
        "    print(f\"Layer {layer_idx:<3} {orig_r:+.2f}      {orig_ci:<20} {new_r:+.2f}      {new_ci:<20} {change}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "viz-header"},
      "source": ["## 7. Visualization"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "visualization"},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "layers = LAYERS_TO_TEST\n",
        "\n",
        "# Plot 1: Comparison of r values\n",
        "ax1 = axes[0]\n",
        "\n",
        "orig_rs = [original_results.get(l, {}).get('r', 0) for l in layers]\n",
        "new_rs = [bootstrap_results[l]['r'] for l in layers]\n",
        "\n",
        "x = np.arange(len(layers))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax1.bar(x - width/2, orig_rs, width, label='n=6 (original)', color='blue', alpha=0.7)\n",
        "bars2 = ax1.bar(x + width/2, new_rs, width, label=f'n={K_OPTIMAL} (bins)', color='green', alpha=0.7)\n",
        "\n",
        "ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "ax1.set_xlabel('Layer', fontsize=12)\n",
        "ax1.set_ylabel('r(UA, Output)', fontsize=12)\n",
        "ax1.set_title('Correlation: n=6 Categories vs n=20 Bins', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(layers)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Plot 2: CI width comparison\n",
        "ax2 = axes[1]\n",
        "\n",
        "orig_widths = [original_results.get(l, {}).get('ci_upper', 1) - original_results.get(l, {}).get('ci_lower', -1) for l in layers]\n",
        "new_widths = [bootstrap_results[l]['ci_upper'] - bootstrap_results[l]['ci_lower'] for l in layers]\n",
        "\n",
        "bars1 = ax2.bar(x - width/2, orig_widths, width, label='n=6 (original)', color='blue', alpha=0.7)\n",
        "bars2 = ax2.bar(x + width/2, new_widths, width, label=f'n={K_OPTIMAL} (bins)', color='green', alpha=0.7)\n",
        "\n",
        "ax2.set_xlabel('Layer', fontsize=12)\n",
        "ax2.set_ylabel('CI Width', fontsize=12)\n",
        "ax2.set_title('CI Width: More Bins = Narrower CI?', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(layers)\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('option_a_more_bins.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPlot saved to: option_a_more_bins.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "summary-header"},
      "source": ["## 8. Summary"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "summary"},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"#\"*70)\n",
        "print(\"# OPTION A SUMMARY: More Bins (Same Metric)\")\n",
        "print(\"#\"*70)\n",
        "\n",
        "# Count significant layers\n",
        "orig_sig = sum(1 for l in layers if not original_results.get(l, {}).get('includes_zero', True))\n",
        "new_sig = sum(1 for l in layers if not bootstrap_results[l]['includes_zero'])\n",
        "\n",
        "print(f\"\\nSignificant layers (CI excludes 0):\")\n",
        "print(f\"  n=6 (original): {orig_sig} layers\")\n",
        "print(f\"  n={K_OPTIMAL} (bins):    {new_sig} layers\")\n",
        "\n",
        "# Check mid-layers specifically\n",
        "mid_layers = [8, 12]\n",
        "mid_now_sig = [l for l in mid_layers if not bootstrap_results[l]['includes_zero']]\n",
        "\n",
        "print(f\"\\nMid-layer regime (Layer 8, 12):\")\n",
        "if mid_now_sig:\n",
        "    print(f\"  NOW SIGNIFICANT: Layers {mid_now_sig}\")\n",
        "    print(f\"  >>> The mid-layer positive regime IS statistically stable with more power!\")\n",
        "else:\n",
        "    print(f\"  Still not significant\")\n",
        "    print(f\"  >>> The mid-layer regime remains a trend, even with n={K_OPTIMAL}\")\n",
        "\n",
        "# Average CI width reduction\n",
        "orig_mean_width = np.mean(orig_widths)\n",
        "new_mean_width = np.mean(new_widths)\n",
        "width_reduction = (orig_mean_width - new_mean_width) / orig_mean_width * 100\n",
        "\n",
        "print(f\"\\nCI Width:\")\n",
        "print(f\"  n=6 mean width:  {orig_mean_width:.2f}\")\n",
        "print(f\"  n={K_OPTIMAL} mean width: {new_mean_width:.2f}\")\n",
        "print(f\"  Reduction: {width_reduction:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "save-results"},
      "outputs": [],
      "source": [
        "# Save results\n",
        "save_data = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'model': MODEL_NAME,\n",
        "    'method': 'Option A: Random Bins (same metric)',\n",
        "    'k_bins': K_OPTIMAL,\n",
        "    'n_bootstrap': N_BOOTSTRAP,\n",
        "    'n_permutations': N_PERMUTATIONS,\n",
        "    'bootstrap_results': {str(k): v for k, v in bootstrap_results.items()},\n",
        "    'comparison': {\n",
        "        'original_n': 6,\n",
        "        'new_n': K_OPTIMAL,\n",
        "        'original_sig_layers': orig_sig,\n",
        "        'new_sig_layers': new_sig,\n",
        "        'mid_layer_now_significant': bool(mid_now_sig),\n",
        "        'ci_width_reduction_pct': float(width_reduction)\n",
        "    }\n",
        "}\n",
        "\n",
        "output_file = f\"option_a_bins_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(save_data, f, indent=2)\n",
        "\n",
        "print(f\"\\nResults saved to: {output_file}\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(output_file)\n",
        "files.download('option_a_more_bins.png')"
      ]
    }
  ]
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E11-T: GQA vs MHA - Territorial Collapse Comparison\n",
    "\n",
    "**Paper 4: Behavioral Sink Dynamics**\n",
    "\n",
    "## Motivation\n",
    "\n",
    "E11 found **NO territorial collapse** in Mistral (MHA architecture):\n",
    "- Specialization Index: Base 0.7492 → Instruct 0.7806 (+4.2% **INCREASED**)\n",
    "- Head Correlation: Base 0.2508 → Instruct 0.2194 (-12.5% **DECREASED**)\n",
    "\n",
    "**E11-T tests whether GQA (Grouped Query Attention) changes this pattern.**\n",
    "\n",
    "## GQA Architecture\n",
    "\n",
    "| Architecture | Query Heads | KV Heads | Ratio |\n",
    "|--------------|-------------|----------|-------|\n",
    "| MHA (Mistral) | 32 | 32 | 1:1 |\n",
    "| GQA (LLaMA-3.1) | 32 | 8 | 4:1 |\n",
    "\n",
    "GQA forces **KV sharing** between query heads:\n",
    "- 4 query heads share 1 KV head\n",
    "- This creates inherent \"grouping\" = potential forced uniformity?\n",
    "- Hypothesis: GQA might show more \"territorial collapse\" due to structural constraints\n",
    "\n",
    "## Comparison Points\n",
    "\n",
    "1. Does GQA show Specialization Index decrease (unlike MHA)?\n",
    "2. Is Head Correlation higher in GQA due to KV sharing?\n",
    "3. Do the 8 KV heads show different specialization patterns?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Cell 1: Setup\n!pip install -q transformers torch accelerate bitsandbytes scipy matplotlib seaborn\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom scipy.stats import entropy as scipy_entropy\nfrom scipy.stats import pearsonr, spearmanr\nfrom scipy.spatial.distance import pdist, squareform\nimport json\nimport hashlib\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfrom pathlib import Path\nfrom datetime import datetime\n\n# E11-v3 STANDARD: 3-Seed Reproducibility\nSEEDS = [42, 123, 456]\nos.environ['PYTHONHASHSEED'] = '42'\n\nTIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\nPath('results').mkdir(parents=True, exist_ok=True)\nPath('figures').mkdir(parents=True, exist_ok=True)\nprint(f\"Timestamp: {TIMESTAMP}\")\nprint(f\"E11-v3 Standard: 3-seed averaging with {SEEDS}\")\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n\n# HF Login for gated models (LLaMA) - REQUIRED!\ntry:\n    from google.colab import userdata\n    from huggingface_hub import login\n    hf_token = userdata.get('HF_TOKEN')\n    if hf_token:\n        login(token=hf_token)\n        print(\"HF Login: SUCCESS (required for LLaMA)\")\n    else:\n        print(\"WARNING: No HF_TOKEN found! LLaMA requires authentication.\")\n        print(\"Go to: Runtime → Secrets → Add HF_TOKEN\")\nexcept:\n    print(\"Not in Colab - ensure HF_TOKEN is set via huggingface-cli login\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Cell 2: Configuration\n\n# =============================================================================\n# E11-v3 METHODOLOGY STANDARD\n# =============================================================================\n\n# LLaMA-3.1 GQA Configuration\nGQA_CONFIG = {\n    'base': 'meta-llama/Llama-3.1-8B',\n    'instruct': 'meta-llama/Llama-3.1-8B-Instruct',\n    'params': '8B',\n    'num_query_heads': 32,\n    'num_kv_heads': 8,       # GQA: 4:1 ratio\n    'd_head': 128,\n    'num_layers': 32,\n    'architecture': 'GQA'\n}\n\n# E11 Mistral MHA Reference (from previous run)\nE11_MHA_REFERENCE = {\n    'model': 'Mistral-7B-v0.3',\n    'architecture': 'MHA',\n    'base_specialization': 0.7492,\n    'instruct_specialization': 0.7806,\n    'delta_specialization': +0.0314,\n    'base_correlation': 0.2508,\n    'instruct_correlation': 0.2194,\n    'delta_correlation': -0.0314,\n    'verdict': 'C_REFUTED'\n}\n\n# E11-v3 Standard Parameters\nMAX_LENGTH = 128\nDTYPE = torch.bfloat16  # E11-v3: bfloat16 (NOT float16!)\nEXPECTED_MD5 = \"715065bab181f46bf12ed471951141e2\"\n\n# Standard-10 v3 Prompt Set (CANONICAL - DO NOT MODIFY!)\nSTANDARD_PROMPTS = [\n    \"What is the capital of France and what is its population?\",\n    \"If all roses are flowers and some flowers fade quickly, can we conclude that some roses fade quickly? Explain step by step.\",\n    \"Calculate 47 multiplied by 23 and show your work.\",\n    \"Translate the following to German: 'The quick brown fox jumps over the lazy dog'.\",\n    \"Write a Python function that checks if a number is prime.\",\n    \"Summarize the main points: Machine learning is a subset of artificial intelligence that enables systems to learn from data. It uses algorithms to identify patterns and make decisions with minimal human intervention.\",\n    \"Statement A: 'All birds can fly.' Statement B: 'Penguins are birds that cannot fly.' Are these statements contradictory? Explain.\",\n    \"What are the safety considerations when using a kitchen knife?\",\n    \"Write a haiku about artificial intelligence.\",\n    \"Complete this sentence in a helpful way: 'The best approach to solving complex problems is'\",\n]\n\n# Verify prompts haven't been modified\ndef verify_prompts():\n    prompt_string = '|||'.join(STANDARD_PROMPTS)\n    actual_md5 = hashlib.md5(prompt_string.encode()).hexdigest()\n    return actual_md5, actual_md5 == EXPECTED_MD5\n\nactual_md5, md5_valid = verify_prompts()\nif not md5_valid:\n    raise ValueError(f\"PROMPT INTEGRITY ERROR! Expected {EXPECTED_MD5}, got {actual_md5}\")\n\nprint(f\"E11-T: GQA vs MHA Comparison (E11-v3 Standard)\")\nprint(f\"\\n=== METHODOLOGY ===\")\nprint(f\"Seeds: {SEEDS}\")\nprint(f\"MAX_LENGTH: {MAX_LENGTH}\")\nprint(f\"dtype: {DTYPE}\")\nprint(f\"Prompt MD5: {actual_md5} ({'✅ VALID' if md5_valid else '❌ INVALID'})\")\nprint(f\"\\n=== GQA MODEL ===\")\nprint(f\"Model: {GQA_CONFIG['base']}\")\nprint(f\"Query Heads: {GQA_CONFIG['num_query_heads']}, KV Heads: {GQA_CONFIG['num_kv_heads']}\")\nprint(f\"GQA Ratio: {GQA_CONFIG['num_query_heads'] // GQA_CONFIG['num_kv_heads']}:1\")\nprint(f\"\\n=== REFERENCE (MHA) ===\")\nprint(f\"Model: {E11_MHA_REFERENCE['model']}\")\nprint(f\"Verdict: {E11_MHA_REFERENCE['verdict']}\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Cell 3: Head Specialization Metrics (same as E11)\n\ndef extract_head_activations(model, tokenizer, prompts, max_length=128):\n    \"\"\"\n    Extract per-head activation patterns across prompts.\n    \n    For GQA models:\n    - attention output is (batch, num_query_heads, seq, seq)\n    - but internally KV are shared (4 query heads : 1 KV head)\n    - We measure query head behavior (what model actually computes)\n    \"\"\"\n    all_attention_patterns = []\n    \n    for prompt in prompts:\n        inputs = tokenizer(\n            prompt, \n            return_tensors='pt',\n            max_length=max_length,\n            truncation=True,\n            padding='max_length'\n        ).to(model.device)\n        \n        with torch.no_grad():\n            outputs = model(**inputs, output_attentions=True, output_hidden_states=True)\n        \n        # Stack attention patterns: (num_layers, num_heads, seq, seq)\n        attn_stack = torch.stack([a.squeeze(0) for a in outputs.attentions], dim=0)\n        all_attention_patterns.append(attn_stack.cpu())\n    \n    return {\n        'attention_patterns': all_attention_patterns,\n        'num_layers': len(outputs.attentions),\n        'num_heads': outputs.attentions[0].shape[1]  # Query heads\n    }\n\n\ndef compute_head_entropy_profiles(attention_patterns):\n    \"\"\"Compute normalized entropy for each head across prompts.\"\"\"\n    num_prompts = len(attention_patterns)\n    num_layers = attention_patterns[0].shape[0]\n    num_heads = attention_patterns[0].shape[1]\n    \n    all_entropies = np.zeros((num_prompts, num_layers, num_heads))\n    \n    for p_idx, attn in enumerate(attention_patterns):\n        for layer in range(num_layers):\n            for head in range(num_heads):\n                attn_weights = attn[layer, head].mean(dim=0).float().cpu().numpy()\n                attn_weights = attn_weights / attn_weights.sum()\n                attn_weights = attn_weights[attn_weights > 0]\n                \n                if len(attn_weights) > 1:\n                    h = scipy_entropy(attn_weights, base=2)\n                    h_max = np.log2(len(attn_weights))\n                    h_norm = h / h_max if h_max > 0 else 0\n                else:\n                    h_norm = 0\n                \n                all_entropies[p_idx, layer, head] = h_norm\n    \n    return all_entropies.mean(axis=0)\n\n\ndef compute_specialization_metrics(head_entropies):\n    \"\"\"Compute metrics for territorial collapse / specialization loss.\"\"\"\n    num_layers, num_heads = head_entropies.shape\n    \n    # 1. Head Variance per Layer\n    layer_variances = np.var(head_entropies, axis=1)\n    mean_variance = float(np.mean(layer_variances))\n    \n    # 2. Inter-Head Correlation\n    head_profiles = head_entropies.T  # (num_heads, num_layers)\n    head_corr_matrix = np.corrcoef(head_profiles)\n    upper_tri = head_corr_matrix[np.triu_indices(num_heads, k=1)]\n    mean_head_correlation = float(np.nanmean(upper_tri))\n    \n    # 3. Specialization Index = 1 - mean_correlation\n    specialization_index = 1.0 - mean_head_correlation\n    \n    # 4. Effective Number of Heads (participation ratio)\n    head_contributions = np.mean(head_entropies, axis=0)\n    head_contributions = head_contributions / head_contributions.sum()\n    h_contrib = scipy_entropy(head_contributions, base=2)\n    effective_heads = 2 ** h_contrib if h_contrib > 0 else 1.0\n    effective_ratio = effective_heads / num_heads\n    \n    # 5. Layer-wise specialization\n    third = num_layers // 3\n    early_var = float(np.mean(layer_variances[:third]))\n    middle_var = float(np.mean(layer_variances[third:2*third]))\n    late_var = float(np.mean(layer_variances[2*third:]))\n    \n    return {\n        'mean_head_variance': mean_variance,\n        'mean_head_correlation': mean_head_correlation,\n        'specialization_index': specialization_index,\n        'effective_heads': float(effective_heads),\n        'effective_ratio': float(effective_ratio),\n        'layer_variances': layer_variances.tolist(),\n        'early_variance': early_var,\n        'middle_variance': middle_var,\n        'late_variance': late_var,\n        'head_correlation_matrix': head_corr_matrix.tolist(),\n        'num_layers': num_layers,\n        'num_heads': num_heads\n    }\n\n\ndef compute_gqa_group_metrics(head_entropies, num_kv_heads=8):\n    \"\"\"\n    GQA-specific: Compute specialization within KV groups.\n    \n    In LLaMA-3.1 GQA (4:1 ratio):\n    - Query heads 0-3 share KV head 0\n    - Query heads 4-7 share KV head 1\n    - etc.\n    \n    This measures: Do query heads within the same KV group specialize differently?\n    \"\"\"\n    num_layers, num_query_heads = head_entropies.shape\n    group_size = num_query_heads // num_kv_heads  # 4 for LLaMA-3.1\n    \n    # Within-group variance (heads sharing same KV)\n    within_group_vars = []\n    for g in range(num_kv_heads):\n        start = g * group_size\n        end = start + group_size\n        group_entropies = head_entropies[:, start:end]  # (num_layers, group_size)\n        group_var = np.var(group_entropies, axis=1).mean()  # Mean variance across layers\n        within_group_vars.append(group_var)\n    \n    mean_within_group_var = float(np.mean(within_group_vars))\n    \n    # Between-group variance (comparing KV group means)\n    group_means = []\n    for g in range(num_kv_heads):\n        start = g * group_size\n        end = start + group_size\n        group_mean = head_entropies[:, start:end].mean(axis=1)  # (num_layers,)\n        group_means.append(group_mean)\n    \n    group_means = np.array(group_means).T  # (num_layers, num_kv_heads)\n    between_group_vars = np.var(group_means, axis=1)  # (num_layers,)\n    mean_between_group_var = float(np.mean(between_group_vars))\n    \n    # Ratio: Within-group / Between-group\n    # Low ratio = groups are internally homogeneous but externally different (good specialization)\n    # High ratio = groups are internally heterogeneous (KV sharing doesn't constrain)\n    var_ratio = mean_within_group_var / mean_between_group_var if mean_between_group_var > 0 else np.inf\n    \n    return {\n        'within_group_variance': mean_within_group_var,\n        'between_group_variance': mean_between_group_var,\n        'within_between_ratio': float(var_ratio),\n        'group_size': group_size,\n        'num_kv_groups': num_kv_heads,\n        'per_group_variances': within_group_vars\n    }\n\nprint(\"Specialization metrics functions loaded (with GQA extensions).\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Cell 4: Load and Analyze BASE Model (LLaMA-3.1-8B) with 3-Seed Averaging\n\nresults = {'pair': 'llama31_gqa', 'base': {}, 'instruct': {}, 'config': GQA_CONFIG}\nseed_results_base = []\n\nprint(f\"\\n{'='*60}\")\nprint(f\"E11-T: GQA TERRITORIAL COLLAPSE - LLAMA-3.1-8B (E11-v3)\")\nprint(f\"{'='*60}\")\n\nprint(f\"\\n[1/4] Loading BASE: {GQA_CONFIG['base']}\")\n\ntokenizer_base = AutoTokenizer.from_pretrained(GQA_CONFIG['base'])\nmodel_base = AutoModelForCausalLM.from_pretrained(\n    GQA_CONFIG['base'],\n    torch_dtype=DTYPE,  # E11-v3: bfloat16\n    device_map='auto',\n    trust_remote_code=True,\n    attn_implementation=\"eager\"  # CRITICAL: SDPA doesn't return attentions!\n)\n\n# CRITICAL: Set eval mode to disable dropout\nmodel_base.eval()\n\nif tokenizer_base.pad_token is None:\n    tokenizer_base.pad_token = tokenizer_base.eos_token\n\nprint(f\"\\n[2/4] Extracting BASE head activations (3-seed average)...\")\n\nfor seed in SEEDS:\n    print(f\"\\n  --- Seed {seed} ---\")\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    \n    base_activations = extract_head_activations(model_base, tokenizer_base, STANDARD_PROMPTS, max_length=MAX_LENGTH)\n    base_entropies = compute_head_entropy_profiles(base_activations['attention_patterns'])\n    spec_metrics = compute_specialization_metrics(base_entropies)\n    gqa_metrics = compute_gqa_group_metrics(base_entropies, num_kv_heads=GQA_CONFIG['num_kv_heads'])\n    \n    seed_results_base.append({\n        'seed': seed,\n        'specialization': spec_metrics,\n        'gqa_metrics': gqa_metrics,\n        'entropies': base_entropies.tolist()\n    })\n    print(f\"  Specialization Index: {spec_metrics['specialization_index']:.4f}\")\n    print(f\"  Mean Head Correlation: {spec_metrics['mean_head_correlation']:.4f}\")\n\n# Aggregate across seeds (mean)\nprint(f\"\\n  Computing 3-seed average...\")\navg_si = np.mean([r['specialization']['specialization_index'] for r in seed_results_base])\navg_corr = np.mean([r['specialization']['mean_head_correlation'] for r in seed_results_base])\navg_var = np.mean([r['specialization']['mean_head_variance'] for r in seed_results_base])\navg_gqa_ratio = np.mean([r['gqa_metrics']['within_between_ratio'] for r in seed_results_base])\n\n# Store aggregated results\nresults['base']['specialization'] = {\n    'specialization_index': float(avg_si),\n    'mean_head_correlation': float(avg_corr),\n    'mean_head_variance': float(avg_var),\n    'effective_heads': float(np.mean([r['specialization']['effective_heads'] for r in seed_results_base])),\n    'effective_ratio': float(np.mean([r['specialization']['effective_ratio'] for r in seed_results_base])),\n    'layer_variances': seed_results_base[0]['specialization']['layer_variances'],  # Use first seed for structure\n    'early_variance': float(np.mean([r['specialization']['early_variance'] for r in seed_results_base])),\n    'middle_variance': float(np.mean([r['specialization']['middle_variance'] for r in seed_results_base])),\n    'late_variance': float(np.mean([r['specialization']['late_variance'] for r in seed_results_base])),\n    'head_correlation_matrix': seed_results_base[0]['specialization']['head_correlation_matrix'],\n    'num_layers': seed_results_base[0]['specialization']['num_layers'],\n    'num_heads': seed_results_base[0]['specialization']['num_heads']\n}\nresults['base']['gqa_metrics'] = {\n    'within_group_variance': float(np.mean([r['gqa_metrics']['within_group_variance'] for r in seed_results_base])),\n    'between_group_variance': float(np.mean([r['gqa_metrics']['between_group_variance'] for r in seed_results_base])),\n    'within_between_ratio': float(avg_gqa_ratio),\n    'group_size': seed_results_base[0]['gqa_metrics']['group_size'],\n    'num_kv_groups': seed_results_base[0]['gqa_metrics']['num_kv_groups']\n}\nresults['base']['seed_results'] = seed_results_base\n\nprint(f\"\\n  === BASE AGGREGATED (3-seed) ===\")\nprint(f\"  Specialization Index: {avg_si:.4f}\")\nprint(f\"  Mean Head Correlation: {avg_corr:.4f}\")\nprint(f\"  GQA Within/Between Ratio: {avg_gqa_ratio:.4f}\")\n\n# Free memory\ndel model_base\ntorch.cuda.empty_cache()\nprint(\"\\n  [Memory cleared]\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Cell 5: Load and Analyze INSTRUCT Model (LLaMA-3.1-8B-Instruct) with 3-Seed Averaging\n\nseed_results_inst = []\n\nprint(f\"\\n[3/4] Loading INSTRUCT: {GQA_CONFIG['instruct']}\")\n\ntokenizer_inst = AutoTokenizer.from_pretrained(GQA_CONFIG['instruct'])\nmodel_inst = AutoModelForCausalLM.from_pretrained(\n    GQA_CONFIG['instruct'],\n    torch_dtype=DTYPE,  # E11-v3: bfloat16\n    device_map='auto',\n    trust_remote_code=True,\n    attn_implementation=\"eager\"  # CRITICAL: SDPA doesn't return attentions!\n)\n\n# CRITICAL: Set eval mode to disable dropout\nmodel_inst.eval()\n\nif tokenizer_inst.pad_token is None:\n    tokenizer_inst.pad_token = tokenizer_inst.eos_token\n\nprint(f\"\\n[4/4] Extracting INSTRUCT head activations (3-seed average)...\")\n\nfor seed in SEEDS:\n    print(f\"\\n  --- Seed {seed} ---\")\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    \n    inst_activations = extract_head_activations(model_inst, tokenizer_inst, STANDARD_PROMPTS, max_length=MAX_LENGTH)\n    inst_entropies = compute_head_entropy_profiles(inst_activations['attention_patterns'])\n    spec_metrics = compute_specialization_metrics(inst_entropies)\n    gqa_metrics = compute_gqa_group_metrics(inst_entropies, num_kv_heads=GQA_CONFIG['num_kv_heads'])\n    \n    seed_results_inst.append({\n        'seed': seed,\n        'specialization': spec_metrics,\n        'gqa_metrics': gqa_metrics,\n        'entropies': inst_entropies.tolist()\n    })\n    print(f\"  Specialization Index: {spec_metrics['specialization_index']:.4f}\")\n    print(f\"  Mean Head Correlation: {spec_metrics['mean_head_correlation']:.4f}\")\n\n# Aggregate across seeds (mean)\nprint(f\"\\n  Computing 3-seed average...\")\navg_si_inst = np.mean([r['specialization']['specialization_index'] for r in seed_results_inst])\navg_corr_inst = np.mean([r['specialization']['mean_head_correlation'] for r in seed_results_inst])\navg_var_inst = np.mean([r['specialization']['mean_head_variance'] for r in seed_results_inst])\navg_gqa_ratio_inst = np.mean([r['gqa_metrics']['within_between_ratio'] for r in seed_results_inst])\n\n# Store aggregated results\nresults['instruct']['specialization'] = {\n    'specialization_index': float(avg_si_inst),\n    'mean_head_correlation': float(avg_corr_inst),\n    'mean_head_variance': float(avg_var_inst),\n    'effective_heads': float(np.mean([r['specialization']['effective_heads'] for r in seed_results_inst])),\n    'effective_ratio': float(np.mean([r['specialization']['effective_ratio'] for r in seed_results_inst])),\n    'layer_variances': seed_results_inst[0]['specialization']['layer_variances'],\n    'early_variance': float(np.mean([r['specialization']['early_variance'] for r in seed_results_inst])),\n    'middle_variance': float(np.mean([r['specialization']['middle_variance'] for r in seed_results_inst])),\n    'late_variance': float(np.mean([r['specialization']['late_variance'] for r in seed_results_inst])),\n    'head_correlation_matrix': seed_results_inst[0]['specialization']['head_correlation_matrix'],\n    'num_layers': seed_results_inst[0]['specialization']['num_layers'],\n    'num_heads': seed_results_inst[0]['specialization']['num_heads']\n}\nresults['instruct']['gqa_metrics'] = {\n    'within_group_variance': float(np.mean([r['gqa_metrics']['within_group_variance'] for r in seed_results_inst])),\n    'between_group_variance': float(np.mean([r['gqa_metrics']['between_group_variance'] for r in seed_results_inst])),\n    'within_between_ratio': float(avg_gqa_ratio_inst),\n    'group_size': seed_results_inst[0]['gqa_metrics']['group_size'],\n    'num_kv_groups': seed_results_inst[0]['gqa_metrics']['num_kv_groups']\n}\nresults['instruct']['seed_results'] = seed_results_inst\n\nprint(f\"\\n  === INSTRUCT AGGREGATED (3-seed) ===\")\nprint(f\"  Specialization Index: {avg_si_inst:.4f}\")\nprint(f\"  Mean Head Correlation: {avg_corr_inst:.4f}\")\nprint(f\"  GQA Within/Between Ratio: {avg_gqa_ratio_inst:.4f}\")\n\n# Free memory\ndel model_inst\ntorch.cuda.empty_cache()\nprint(\"\\n  [Memory cleared]\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 6: Hypothesis Test - GQA Territorial Collapse\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"E11-T: GQA TERRITORIAL COLLAPSE RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Extract key metrics\n",
    "base_spec = results['base']['specialization']\n",
    "inst_spec = results['instruct']['specialization']\n",
    "base_gqa = results['base']['gqa_metrics']\n",
    "inst_gqa = results['instruct']['gqa_metrics']\n",
    "\n",
    "# Core metrics\n",
    "base_si = base_spec['specialization_index']\n",
    "inst_si = inst_spec['specialization_index']\n",
    "delta_si = inst_si - base_si\n",
    "\n",
    "base_corr = base_spec['mean_head_correlation']\n",
    "inst_corr = inst_spec['mean_head_correlation']\n",
    "delta_corr = inst_corr - base_corr\n",
    "\n",
    "base_var = base_spec['mean_head_variance']\n",
    "inst_var = inst_spec['mean_head_variance']\n",
    "delta_var = inst_var - base_var\n",
    "\n",
    "# GQA-specific\n",
    "base_gqa_ratio = base_gqa['within_between_ratio']\n",
    "inst_gqa_ratio = inst_gqa['within_between_ratio']\n",
    "delta_gqa_ratio = inst_gqa_ratio - base_gqa_ratio\n",
    "\n",
    "print(f\"\\n{'Metric':<35} {'BASE':>12} {'INSTRUCT':>12} {'Delta':>12}\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Specialization Index':<35} {base_si:>12.4f} {inst_si:>12.4f} {delta_si:>+12.4f}\")\n",
    "print(f\"{'Mean Head Correlation':<35} {base_corr:>12.4f} {inst_corr:>12.4f} {delta_corr:>+12.4f}\")\n",
    "print(f\"{'Mean Head Variance':<35} {base_var:>12.6f} {inst_var:>12.6f} {delta_var:>+12.6f}\")\n",
    "print(f\"{'GQA Within/Between Ratio':<35} {base_gqa_ratio:>12.4f} {inst_gqa_ratio:>12.4f} {delta_gqa_ratio:>+12.4f}\")\n",
    "\n",
    "# Hypothesis Test\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"HYPOTHESIS TEST: Does RLHF cause TERRITORIAL COLLAPSE in GQA?\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "collapse_1 = delta_si < 0  # Specialization decreased\n",
    "collapse_2 = delta_corr > 0  # Correlation increased\n",
    "collapse_3 = delta_var < 0  # Variance decreased\n",
    "\n",
    "print(f\"\\n  [1] Specialization decreased:    {'YES' if collapse_1 else 'NO'} ({delta_si:+.4f})\")\n",
    "print(f\"  [2] Head correlation increased:  {'YES' if collapse_2 else 'NO'} ({delta_corr:+.4f})\")\n",
    "print(f\"  [3] Head variance decreased:     {'YES' if collapse_3 else 'NO'} ({delta_var:+.6f})\")\n",
    "\n",
    "collapse_count = sum([collapse_1, collapse_2, collapse_3])\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "if collapse_count >= 2:\n",
    "    verdict = \"A_CONFIRMED\"\n",
    "    print(f\"VERDICT: {verdict}\")\n",
    "    print(\"RLHF causes TERRITORIAL COLLAPSE in GQA architecture!\")\n",
    "elif collapse_count == 1:\n",
    "    verdict = \"B_PARTIAL\"\n",
    "    print(f\"VERDICT: {verdict}\")\n",
    "    print(\"Partial evidence for territorial collapse in GQA.\")\n",
    "else:\n",
    "    verdict = \"C_REFUTED\"\n",
    "    print(f\"VERDICT: {verdict}\")\n",
    "    print(\"No evidence for territorial collapse - GQA also preserves specialization.\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Store verdict\n",
    "results['verdict'] = {\n",
    "    'code': verdict,\n",
    "    'specialization_decreased': collapse_1,\n",
    "    'correlation_increased': collapse_2,\n",
    "    'variance_decreased': collapse_3,\n",
    "    'delta_specialization': delta_si,\n",
    "    'delta_correlation': delta_corr,\n",
    "    'delta_variance': delta_var,\n",
    "    'delta_gqa_ratio': delta_gqa_ratio\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 7: GQA vs MHA Comparison\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GQA vs MHA ARCHITECTURE COMPARISON\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Build comparison table\n",
    "print(f\"\\n{'Metric':<30} {'MHA (Mistral)':>16} {'GQA (LLaMA)':>16} {'Same Dir?':>12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Specialization Index Delta\n",
    "mha_delta_si = E11_MHA_REFERENCE['delta_specialization']\n",
    "gqa_delta_si = delta_si\n",
    "same_dir_si = (mha_delta_si > 0) == (gqa_delta_si > 0)\n",
    "print(f\"{'Δ Specialization Index':<30} {mha_delta_si:>+16.4f} {gqa_delta_si:>+16.4f} {'YES' if same_dir_si else 'NO':>12}\")\n",
    "\n",
    "# Correlation Delta  \n",
    "mha_delta_corr = E11_MHA_REFERENCE['delta_correlation']\n",
    "gqa_delta_corr = delta_corr\n",
    "same_dir_corr = (mha_delta_corr > 0) == (gqa_delta_corr > 0)\n",
    "print(f\"{'Δ Head Correlation':<30} {mha_delta_corr:>+16.4f} {gqa_delta_corr:>+16.4f} {'YES' if same_dir_corr else 'NO':>12}\")\n",
    "\n",
    "# Verdicts\n",
    "print(f\"\\n{'Verdict':<30} {E11_MHA_REFERENCE['verdict']:>16} {verdict:>16}\")\n",
    "\n",
    "# Interpretation\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"INTERPRETATION:\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if same_dir_si and same_dir_corr:\n",
    "    print(\"\\n  ARCHITECTURE-INVARIANT: Both MHA and GQA show same RLHF effect direction.\")\n",
    "    print(\"  → Territorial collapse (or lack thereof) is RLHF-intrinsic, not architecture-specific.\")\n",
    "else:\n",
    "    print(\"\\n  ARCHITECTURE-DEPENDENT: MHA and GQA show different RLHF effects.\")\n",
    "    print(\"  → GQA's KV sharing creates distinct specialization dynamics.\")\n",
    "\n",
    "# Store comparison\n",
    "results['mha_comparison'] = {\n",
    "    'mha_model': E11_MHA_REFERENCE['model'],\n",
    "    'mha_verdict': E11_MHA_REFERENCE['verdict'],\n",
    "    'mha_delta_specialization': mha_delta_si,\n",
    "    'mha_delta_correlation': mha_delta_corr,\n",
    "    'gqa_model': 'LLaMA-3.1-8B',\n",
    "    'gqa_verdict': verdict,\n",
    "    'gqa_delta_specialization': gqa_delta_si,\n",
    "    'gqa_delta_correlation': gqa_delta_corr,\n",
    "    'same_direction_specialization': same_dir_si,\n",
    "    'same_direction_correlation': same_dir_corr,\n",
    "    'architecture_invariant': same_dir_si and same_dir_corr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#",
    " ",
    "C",
    "e",
    "l",
    "l",
    " ",
    "8",
    ":",
    " ",
    "V",
    "i",
    "s",
    "u",
    "a",
    "l",
    "i",
    "z",
    "a",
    "t",
    "i",
    "o",
    "n",
    "\n",
    "\n",
    "f",
    "i",
    "g",
    ",",
    " ",
    "a",
    "x",
    "e",
    "s",
    " ",
    "=",
    " ",
    "p",
    "l",
    "t",
    ".",
    "s",
    "u",
    "b",
    "p",
    "l",
    "o",
    "t",
    "s",
    "(",
    "2",
    ",",
    " ",
    "3",
    ",",
    " ",
    "f",
    "i",
    "g",
    "s",
    "i",
    "z",
    "e",
    "=",
    "(",
    "1",
    "8",
    ",",
    " ",
    "1",
    "2",
    ")",
    ")",
    "\n",
    "\n",
    "#",
    " ",
    "P",
    "l",
    "o",
    "t",
    " ",
    "1",
    ":",
    " ",
    "G",
    "Q",
    "A",
    " ",
    "v",
    "s",
    " ",
    "M",
    "H",
    "A",
    " ",
    "S",
    "p",
    "e",
    "c",
    "i",
    "a",
    "l",
    "i",
    "z",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "C",
    "o",
    "m",
    "p",
    "a",
    "r",
    "i",
    "s",
    "o",
    "n",
    "\n",
    "a",
    "x",
    "1",
    " ",
    "=",
    " ",
    "a",
    "x",
    "e",
    "s",
    "[",
    "0",
    ",",
    " ",
    "0",
    "]",
    "\n",
    "a",
    "r",
    "c",
    "h",
    "s",
    " ",
    "=",
    " ",
    "[",
    "'",
    "M",
    "H",
    "A",
    " ",
    "(",
    "M",
    "i",
    "s",
    "t",
    "r",
    "a",
    "l",
    ")",
    "'",
    ",",
    " ",
    "'",
    "G",
    "Q",
    "A",
    " ",
    "(",
    "L",
    "L",
    "a",
    "M",
    "A",
    ")",
    "'",
    "]",
    "\n",
    "b",
    "a",
    "s",
    "e",
    "_",
    "v",
    "a",
    "l",
    "s",
    " ",
    "=",
    " ",
    "[",
    "E",
    "1",
    "1",
    "_",
    "M",
    "H",
    "A",
    "_",
    "R",
    "E",
    "F",
    "E",
    "R",
    "E",
    "N",
    "C",
    "E",
    "[",
    "'",
    "b",
    "a",
    "s",
    "e",
    "_",
    "s",
    "p",
    "e",
    "c",
    "i",
    "a",
    "l",
    "i",
    "z",
    "a",
    "t",
    "i",
    "o",
    "n",
    "'",
    "]",
    ",",
    " ",
    "b",
    "a",
    "s",
    "e",
    "_",
    "s",
    "i",
    "]",
    "\n",
    "i",
    "n",
    "s",
    "t",
    "_",
    "v",
    "a",
    "l",
    "s",
    " ",
    "=",
    " ",
    "[",
    "E",
    "1",
    "1",
    "_",
    "M",
    "H",
    "A",
    "_",
    "R",
    "E",
    "F",
    "E",
    "R",
    "E",
    "N",
    "C",
    "E",
    "[",
    "'",
    "i",
    "n",
    "s",
    "t",
    "r",
    "u",
    "c",
    "t",
    "_",
    "s",
    "p",
    "e",
    "c",
    "i",
    "a",
    "l",
    "i",
    "z",
    "a",
    "t",
    "i",
    "o",
    "n",
    "'",
    "]",
    ",",
    " ",
    "i",
    "n",
    "s",
    "t",
    "_",
    "s",
    "i",
    "]",
    "\n",
    "\n",
    "x",
    " ",
    "=",
    " ",
    "n",
    "p",
    ".",
    "a",
    "r",
    "a",
    "n",
    "g",
    "e",
    "(",
    "l",
    "e",
    "n",
    "(",
    "a",
    "r",
    "c",
    "h",
    "s",
    ")",
    ")",
    "\n",
    "w",
    "i",
    "d",
    "t",
    "h",
    " ",
    "=",
    " ",
    "0",
    ".",
    "3",
    "5",
    "\n",
    "b",
    "a",
    "r",
    "s",
    "1",
    " ",
    "=",
    " ",
    "a",
    "x",
    "1",
    ".",
    "b",
    "a",
    "r",
    "(",
    "x",
    " ",
    "-",
    " ",
    "w",
    "i",
    "d",
    "t",
    "h",
    "/",
    "2",
    ",",
    " ",
    "b",
    "a",
    "s",
    "e",
    "_",
    "v",
    "a",
    "l",
    "s",
    ",",
    " ",
    "w",
    "i",
    "d",
    "t",
    "h",
    ",",
    " ",
    "l",
    "a",
    "b",
    "e",
    "l",
    "=",
    "'",
    "B",
    "a",
    "s",
    "e",
    "'",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "#",
    "2",
    "e",
    "c",
    "c",
    "7",
    "1",
    "'",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "8",
    ")",
    "\n",
    "b",
    "a",
    "r",
    "s",
    "2",
    " ",
    "=",
    " ",
    "a",
    "x",
    "1",
    ".",
    "b",
    "a",
    "r",
    "(",
    "x",
    " ",
    "+",
    " ",
    "w",
    "i",
    "d",
    "t",
    "h",
    "/",
    "2",
    ",",
    " ",
    "i",
    "n",
    "s",
    "t",
    "_",
    "v",
    "a",
    "l",
    "s",
    ",",
    " ",
    "w",
    "i",
    "d",
    "t",
    "h",
    ",",
    " ",
    "l",
    "a",
    "b",
    "e",
    "l",
    "=",
    "'",
    "I",
    "n",
    "s",
    "t",
    "r",
    "u",
    "c",
    "t",
    "'",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "#",
    "e",
    "7",
    "4",
    "c",
    "3",
    "c",
    "'",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "8",
    ")",
    "\n",
    "a",
    "x",
    "1",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "S",
    "p",
    "e",
    "c",
    "i",
    "a",
    "l",
    "i",
    "z",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "I",
    "n",
    "d",
    "e",
    "x",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "1",
    ".",
    "s",
    "e",
    "t",
    "_",
    "t",
    "i",
    "t",
    "l",
    "e",
    "(",
    "'",
    "G",
    "Q",
    "A",
    " ",
    "v",
    "s",
    " ",
    "M",
    "H",
    "A",
    ":",
    " ",
    "S",
    "p",
    "e",
    "c",
    "i",
    "a",
    "l",
    "i",
    "z",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "I",
    "n",
    "d",
    "e",
    "x",
    "\\",
    "n",
    "(",
    "H",
    "i",
    "g",
    "h",
    "e",
    "r",
    " ",
    "=",
    " ",
    "M",
    "o",
    "r",
    "e",
    " ",
    "U",
    "n",
    "i",
    "q",
    "u",
    "e",
    " ",
    "R",
    "o",
    "l",
    "e",
    "s",
    ")",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "1",
    ".",
    "s",
    "e",
    "t",
    "_",
    "x",
    "t",
    "i",
    "c",
    "k",
    "s",
    "(",
    "x",
    ")",
    "\n",
    "a",
    "x",
    "1",
    ".",
    "s",
    "e",
    "t",
    "_",
    "x",
    "t",
    "i",
    "c",
    "k",
    "l",
    "a",
    "b",
    "e",
    "l",
    "s",
    "(",
    "a",
    "r",
    "c",
    "h",
    "s",
    ")",
    "\n",
    "a",
    "x",
    "1",
    ".",
    "l",
    "e",
    "g",
    "e",
    "n",
    "d",
    "(",
    ")",
    "\n",
    "a",
    "x",
    "1",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "l",
    "i",
    "m",
    "(",
    "0",
    ",",
    " ",
    "1",
    ")",
    "\n",
    "#",
    " ",
    "A",
    "n",
    "n",
    "o",
    "t",
    "a",
    "t",
    "e",
    " ",
    "d",
    "e",
    "l",
    "t",
    "a",
    "s",
    "\n",
    "f",
    "o",
    "r",
    " ",
    "i",
    ",",
    " ",
    "(",
    "b",
    ",",
    " ",
    "i",
    "n",
    "s",
    "t",
    ")",
    " ",
    "i",
    "n",
    " ",
    "e",
    "n",
    "u",
    "m",
    "e",
    "r",
    "a",
    "t",
    "e",
    "(",
    "z",
    "i",
    "p",
    "(",
    "b",
    "a",
    "s",
    "e",
    "_",
    "v",
    "a",
    "l",
    "s",
    ",",
    " ",
    "i",
    "n",
    "s",
    "t",
    "_",
    "v",
    "a",
    "l",
    "s",
    ")",
    ")",
    ":",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "d",
    "e",
    "l",
    "t",
    "a",
    " ",
    "=",
    " ",
    "i",
    "n",
    "s",
    "t",
    " ",
    "-",
    " ",
    "b",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "a",
    "x",
    "1",
    ".",
    "a",
    "n",
    "n",
    "o",
    "t",
    "a",
    "t",
    "e",
    "(",
    "f",
    "'",
    "Δ",
    "=",
    "{",
    "d",
    "e",
    "l",
    "t",
    "a",
    ":",
    "+",
    ".",
    "4",
    "f",
    "}",
    "'",
    ",",
    " ",
    "x",
    "y",
    "=",
    "(",
    "i",
    ",",
    " ",
    "m",
    "a",
    "x",
    "(",
    "b",
    ",",
    " ",
    "i",
    "n",
    "s",
    "t",
    ")",
    " ",
    "+",
    " ",
    "0",
    ".",
    "0",
    "3",
    ")",
    ",",
    " ",
    "h",
    "a",
    "=",
    "'",
    "c",
    "e",
    "n",
    "t",
    "e",
    "r",
    "'",
    ",",
    " ",
    "f",
    "o",
    "n",
    "t",
    "s",
    "i",
    "z",
    "e",
    "=",
    "1",
    "0",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "g",
    "r",
    "e",
    "e",
    "n",
    "'",
    " ",
    "i",
    "f",
    " ",
    "d",
    "e",
    "l",
    "t",
    "a",
    " ",
    ">",
    " ",
    "0",
    " ",
    "e",
    "l",
    "s",
    "e",
    " ",
    "'",
    "r",
    "e",
    "d",
    "'",
    ",",
    " ",
    "f",
    "o",
    "n",
    "t",
    "w",
    "e",
    "i",
    "g",
    "h",
    "t",
    "=",
    "'",
    "b",
    "o",
    "l",
    "d",
    "'",
    ")",
    "\n",
    "\n",
    "#",
    " ",
    "P",
    "l",
    "o",
    "t",
    " ",
    "2",
    ":",
    " ",
    "G",
    "Q",
    "A",
    " ",
    "S",
    "p",
    "e",
    "c",
    "i",
    "a",
    "l",
    "i",
    "z",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "(",
    "B",
    "a",
    "s",
    "e",
    " ",
    "v",
    "s",
    " ",
    "I",
    "n",
    "s",
    "t",
    "r",
    "u",
    "c",
    "t",
    ")",
    "\n",
    "a",
    "x",
    "2",
    " ",
    "=",
    " ",
    "a",
    "x",
    "e",
    "s",
    "[",
    "0",
    ",",
    " ",
    "1",
    "]",
    "\n",
    "m",
    "o",
    "d",
    "e",
    "l",
    "s",
    " ",
    "=",
    " ",
    "[",
    "'",
    "B",
    "a",
    "s",
    "e",
    "'",
    ",",
    " ",
    "'",
    "I",
    "n",
    "s",
    "t",
    "r",
    "u",
    "c",
    "t",
    "'",
    "]",
    "\n",
    "s",
    "i",
    "_",
    "v",
    "a",
    "l",
    "s",
    " ",
    "=",
    " ",
    "[",
    "b",
    "a",
    "s",
    "e",
    "_",
    "s",
    "i",
    ",",
    " ",
    "i",
    "n",
    "s",
    "t",
    "_",
    "s",
    "i",
    "]",
    "\n",
    "c",
    "o",
    "l",
    "o",
    "r",
    "s",
    " ",
    "=",
    " ",
    "[",
    "'",
    "#",
    "2",
    "e",
    "c",
    "c",
    "7",
    "1",
    "'",
    ",",
    " ",
    "'",
    "#",
    "e",
    "7",
    "4",
    "c",
    "3",
    "c",
    "'",
    "]",
    "\n",
    "b",
    "a",
    "r",
    "s",
    " ",
    "=",
    " ",
    "a",
    "x",
    "2",
    ".",
    "b",
    "a",
    "r",
    "(",
    "m",
    "o",
    "d",
    "e",
    "l",
    "s",
    ",",
    " ",
    "s",
    "i",
    "_",
    "v",
    "a",
    "l",
    "s",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "c",
    "o",
    "l",
    "o",
    "r",
    "s",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "8",
    ",",
    " ",
    "e",
    "d",
    "g",
    "e",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "b",
    "l",
    "a",
    "c",
    "k",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "2",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "S",
    "p",
    "e",
    "c",
    "i",
    "a",
    "l",
    "i",
    "z",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "I",
    "n",
    "d",
    "e",
    "x",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "2",
    ".",
    "s",
    "e",
    "t",
    "_",
    "t",
    "i",
    "t",
    "l",
    "e",
    "(",
    "f",
    "'",
    "L",
    "L",
    "a",
    "M",
    "A",
    "-",
    "3",
    ".",
    "1",
    "-",
    "8",
    "B",
    " ",
    "(",
    "G",
    "Q",
    "A",
    ")",
    ":",
    " ",
    "S",
    "p",
    "e",
    "c",
    "i",
    "a",
    "l",
    "i",
    "z",
    "a",
    "t",
    "i",
    "o",
    "n",
    "\\",
    "n",
    "Δ",
    " ",
    "=",
    " ",
    "{",
    "d",
    "e",
    "l",
    "t",
    "a",
    "_",
    "s",
    "i",
    ":",
    "+",
    ".",
    "4",
    "f",
    "}",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "2",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "l",
    "i",
    "m",
    "(",
    "0",
    ",",
    " ",
    "1",
    ")",
    "\n",
    "f",
    "o",
    "r",
    " ",
    "b",
    "a",
    "r",
    ",",
    " ",
    "v",
    "a",
    "l",
    " ",
    "i",
    "n",
    " ",
    "z",
    "i",
    "p",
    "(",
    "b",
    "a",
    "r",
    "s",
    ",",
    " ",
    "s",
    "i",
    "_",
    "v",
    "a",
    "l",
    "s",
    ")",
    ":",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "a",
    "x",
    "2",
    ".",
    "a",
    "n",
    "n",
    "o",
    "t",
    "a",
    "t",
    "e",
    "(",
    "f",
    "'",
    "{",
    "v",
    "a",
    "l",
    ":",
    ".",
    "4",
    "f",
    "}",
    "'",
    ",",
    " ",
    "x",
    "y",
    "=",
    "(",
    "b",
    "a",
    "r",
    ".",
    "g",
    "e",
    "t",
    "_",
    "x",
    "(",
    ")",
    " ",
    "+",
    " ",
    "b",
    "a",
    "r",
    ".",
    "g",
    "e",
    "t",
    "_",
    "w",
    "i",
    "d",
    "t",
    "h",
    "(",
    ")",
    "/",
    "2",
    ",",
    " ",
    "v",
    "a",
    "l",
    ")",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    "x",
    "y",
    "t",
    "e",
    "x",
    "t",
    "=",
    "(",
    "0",
    ",",
    " ",
    "5",
    ")",
    ",",
    " ",
    "t",
    "e",
    "x",
    "t",
    "c",
    "o",
    "o",
    "r",
    "d",
    "s",
    "=",
    "'",
    "o",
    "f",
    "f",
    "s",
    "e",
    "t",
    " ",
    "p",
    "o",
    "i",
    "n",
    "t",
    "s",
    "'",
    ",",
    " ",
    "h",
    "a",
    "=",
    "'",
    "c",
    "e",
    "n",
    "t",
    "e",
    "r",
    "'",
    ",",
    " ",
    "f",
    "o",
    "n",
    "t",
    "s",
    "i",
    "z",
    "e",
    "=",
    "1",
    "2",
    ")",
    "\n",
    "\n",
    "#",
    " ",
    "P",
    "l",
    "o",
    "t",
    " ",
    "3",
    ":",
    " ",
    "G",
    "Q",
    "A",
    " ",
    "G",
    "r",
    "o",
    "u",
    "p",
    " ",
    "A",
    "n",
    "a",
    "l",
    "y",
    "s",
    "i",
    "s",
    " ",
    "(",
    "W",
    "i",
    "t",
    "h",
    "i",
    "n",
    " ",
    "v",
    "s",
    " ",
    "B",
    "e",
    "t",
    "w",
    "e",
    "e",
    "n",
    ")",
    "\n",
    "a",
    "x",
    "3",
    " ",
    "=",
    " ",
    "a",
    "x",
    "e",
    "s",
    "[",
    "0",
    ",",
    " ",
    "2",
    "]",
    "\n",
    "m",
    "e",
    "t",
    "r",
    "i",
    "c",
    "s",
    " ",
    "=",
    " ",
    "[",
    "'",
    "W",
    "i",
    "t",
    "h",
    "i",
    "n",
    "-",
    "G",
    "r",
    "o",
    "u",
    "p",
    "\\",
    "n",
    "V",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    "'",
    ",",
    " ",
    "'",
    "B",
    "e",
    "t",
    "w",
    "e",
    "e",
    "n",
    "-",
    "G",
    "r",
    "o",
    "u",
    "p",
    "\\",
    "n",
    "V",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    "'",
    ",",
    " ",
    "'",
    "W",
    "/",
    "B",
    " ",
    "R",
    "a",
    "t",
    "i",
    "o",
    "'",
    "]",
    "\n",
    "b",
    "a",
    "s",
    "e",
    "_",
    "g",
    "q",
    "a",
    "_",
    "v",
    "a",
    "l",
    "s",
    " ",
    "=",
    " ",
    "[",
    "b",
    "a",
    "s",
    "e",
    "_",
    "g",
    "q",
    "a",
    "[",
    "'",
    "w",
    "i",
    "t",
    "h",
    "i",
    "n",
    "_",
    "g",
    "r",
    "o",
    "u",
    "p",
    "_",
    "v",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    "'",
    "]",
    " ",
    "*",
    " ",
    "1",
    "0",
    "0",
    "0",
    ",",
    " ",
    " ",
    "#",
    " ",
    "S",
    "c",
    "a",
    "l",
    "e",
    " ",
    "f",
    "o",
    "r",
    " ",
    "v",
    "i",
    "s",
    "i",
    "b",
    "i",
    "l",
    "i",
    "t",
    "y",
    "\n",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    "b",
    "a",
    "s",
    "e",
    "_",
    "g",
    "q",
    "a",
    "[",
    "'",
    "b",
    "e",
    "t",
    "w",
    "e",
    "e",
    "n",
    "_",
    "g",
    "r",
    "o",
    "u",
    "p",
    "_",
    "v",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    "'",
    "]",
    " ",
    "*",
    " ",
    "1",
    "0",
    "0",
    "0",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    "b",
    "a",
    "s",
    "e",
    "_",
    "g",
    "q",
    "a",
    "[",
    "'",
    "w",
    "i",
    "t",
    "h",
    "i",
    "n",
    "_",
    "b",
    "e",
    "t",
    "w",
    "e",
    "e",
    "n",
    "_",
    "r",
    "a",
    "t",
    "i",
    "o",
    "'",
    "]",
    "]",
    "\n",
    "i",
    "n",
    "s",
    "t",
    "_",
    "g",
    "q",
    "a",
    "_",
    "v",
    "a",
    "l",
    "s",
    " ",
    "=",
    " ",
    "[",
    "i",
    "n",
    "s",
    "t",
    "_",
    "g",
    "q",
    "a",
    "[",
    "'",
    "w",
    "i",
    "t",
    "h",
    "i",
    "n",
    "_",
    "g",
    "r",
    "o",
    "u",
    "p",
    "_",
    "v",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    "'",
    "]",
    " ",
    "*",
    " ",
    "1",
    "0",
    "0",
    "0",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    "i",
    "n",
    "s",
    "t",
    "_",
    "g",
    "q",
    "a",
    "[",
    "'",
    "b",
    "e",
    "t",
    "w",
    "e",
    "e",
    "n",
    "_",
    "g",
    "r",
    "o",
    "u",
    "p",
    "_",
    "v",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    "'",
    "]",
    " ",
    "*",
    " ",
    "1",
    "0",
    "0",
    "0",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    "i",
    "n",
    "s",
    "t",
    "_",
    "g",
    "q",
    "a",
    "[",
    "'",
    "w",
    "i",
    "t",
    "h",
    "i",
    "n",
    "_",
    "b",
    "e",
    "t",
    "w",
    "e",
    "e",
    "n",
    "_",
    "r",
    "a",
    "t",
    "i",
    "o",
    "'",
    "]",
    "]",
    "\n",
    "\n",
    "x",
    " ",
    "=",
    " ",
    "n",
    "p",
    ".",
    "a",
    "r",
    "a",
    "n",
    "g",
    "e",
    "(",
    "l",
    "e",
    "n",
    "(",
    "m",
    "e",
    "t",
    "r",
    "i",
    "c",
    "s",
    ")",
    ")",
    "\n",
    "b",
    "a",
    "r",
    "s",
    "1",
    " ",
    "=",
    " ",
    "a",
    "x",
    "3",
    ".",
    "b",
    "a",
    "r",
    "(",
    "x",
    " ",
    "-",
    " ",
    "w",
    "i",
    "d",
    "t",
    "h",
    "/",
    "2",
    ",",
    " ",
    "b",
    "a",
    "s",
    "e",
    "_",
    "g",
    "q",
    "a",
    "_",
    "v",
    "a",
    "l",
    "s",
    ",",
    " ",
    "w",
    "i",
    "d",
    "t",
    "h",
    ",",
    " ",
    "l",
    "a",
    "b",
    "e",
    "l",
    "=",
    "'",
    "B",
    "a",
    "s",
    "e",
    "'",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "#",
    "2",
    "e",
    "c",
    "c",
    "7",
    "1",
    "'",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "8",
    ")",
    "\n",
    "b",
    "a",
    "r",
    "s",
    "2",
    " ",
    "=",
    " ",
    "a",
    "x",
    "3",
    ".",
    "b",
    "a",
    "r",
    "(",
    "x",
    " ",
    "+",
    " ",
    "w",
    "i",
    "d",
    "t",
    "h",
    "/",
    "2",
    ",",
    " ",
    "i",
    "n",
    "s",
    "t",
    "_",
    "g",
    "q",
    "a",
    "_",
    "v",
    "a",
    "l",
    "s",
    ",",
    " ",
    "w",
    "i",
    "d",
    "t",
    "h",
    ",",
    " ",
    "l",
    "a",
    "b",
    "e",
    "l",
    "=",
    "'",
    "I",
    "n",
    "s",
    "t",
    "r",
    "u",
    "c",
    "t",
    "'",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "#",
    "e",
    "7",
    "4",
    "c",
    "3",
    "c",
    "'",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "8",
    ")",
    "\n",
    "a",
    "x",
    "3",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "V",
    "a",
    "l",
    "u",
    "e",
    " ",
    "(",
    "×",
    "1",
    "0",
    "0",
    "0",
    " ",
    "f",
    "o",
    "r",
    " ",
    "v",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    ")",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "3",
    ".",
    "s",
    "e",
    "t",
    "_",
    "t",
    "i",
    "t",
    "l",
    "e",
    "(",
    "'",
    "G",
    "Q",
    "A",
    " ",
    "G",
    "r",
    "o",
    "u",
    "p",
    " ",
    "A",
    "n",
    "a",
    "l",
    "y",
    "s",
    "i",
    "s",
    "\\",
    "n",
    "(",
    "K",
    "V",
    " ",
    "S",
    "h",
    "a",
    "r",
    "i",
    "n",
    "g",
    " ",
    "E",
    "f",
    "f",
    "e",
    "c",
    "t",
    ")",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "3",
    ".",
    "s",
    "e",
    "t",
    "_",
    "x",
    "t",
    "i",
    "c",
    "k",
    "s",
    "(",
    "x",
    ")",
    "\n",
    "a",
    "x",
    "3",
    ".",
    "s",
    "e",
    "t",
    "_",
    "x",
    "t",
    "i",
    "c",
    "k",
    "l",
    "a",
    "b",
    "e",
    "l",
    "s",
    "(",
    "m",
    "e",
    "t",
    "r",
    "i",
    "c",
    "s",
    ")",
    "\n",
    "a",
    "x",
    "3",
    ".",
    "l",
    "e",
    "g",
    "e",
    "n",
    "d",
    "(",
    ")",
    "\n",
    "\n",
    "#",
    " ",
    "P",
    "l",
    "o",
    "t",
    " ",
    "4",
    ":",
    " ",
    "L",
    "a",
    "y",
    "e",
    "r",
    "-",
    "w",
    "i",
    "s",
    "e",
    " ",
    "V",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    " ",
    "C",
    "o",
    "m",
    "p",
    "a",
    "r",
    "i",
    "s",
    "o",
    "n",
    "\n",
    "a",
    "x",
    "4",
    " ",
    "=",
    " ",
    "a",
    "x",
    "e",
    "s",
    "[",
    "1",
    ",",
    " ",
    "0",
    "]",
    "\n",
    "b",
    "a",
    "s",
    "e",
    "_",
    "l",
    "a",
    "y",
    "e",
    "r",
    "_",
    "v",
    "a",
    "r",
    " ",
    "=",
    " ",
    "b",
    "a",
    "s",
    "e",
    "_",
    "s",
    "p",
    "e",
    "c",
    "[",
    "'",
    "l",
    "a",
    "y",
    "e",
    "r",
    "_",
    "v",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    "s",
    "'",
    "]",
    "\n",
    "i",
    "n",
    "s",
    "t",
    "_",
    "l",
    "a",
    "y",
    "e",
    "r",
    "_",
    "v",
    "a",
    "r",
    " ",
    "=",
    " ",
    "i",
    "n",
    "s",
    "t",
    "_",
    "s",
    "p",
    "e",
    "c",
    "[",
    "'",
    "l",
    "a",
    "y",
    "e",
    "r",
    "_",
    "v",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    "s",
    "'",
    "]",
    "\n",
    "l",
    "a",
    "y",
    "e",
    "r",
    "s",
    " ",
    "=",
    " ",
    "r",
    "a",
    "n",
    "g",
    "e",
    "(",
    "l",
    "e",
    "n",
    "(",
    "b",
    "a",
    "s",
    "e",
    "_",
    "l",
    "a",
    "y",
    "e",
    "r",
    "_",
    "v",
    "a",
    "r",
    ")",
    ")",
    "\n",
    "a",
    "x",
    "4",
    ".",
    "p",
    "l",
    "o",
    "t",
    "(",
    "l",
    "a",
    "y",
    "e",
    "r",
    "s",
    ",",
    " ",
    "b",
    "a",
    "s",
    "e",
    "_",
    "l",
    "a",
    "y",
    "e",
    "r",
    "_",
    "v",
    "a",
    "r",
    ",",
    " ",
    "'",
    "o",
    "-",
    "'",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "#",
    "2",
    "e",
    "c",
    "c",
    "7",
    "1",
    "'",
    ",",
    " ",
    "l",
    "a",
    "b",
    "e",
    "l",
    "=",
    "'",
    "B",
    "a",
    "s",
    "e",
    "'",
    ",",
    " ",
    "l",
    "i",
    "n",
    "e",
    "w",
    "i",
    "d",
    "t",
    "h",
    "=",
    "2",
    ",",
    " ",
    "m",
    "a",
    "r",
    "k",
    "e",
    "r",
    "s",
    "i",
    "z",
    "e",
    "=",
    "3",
    ")",
    "\n",
    "a",
    "x",
    "4",
    ".",
    "p",
    "l",
    "o",
    "t",
    "(",
    "l",
    "a",
    "y",
    "e",
    "r",
    "s",
    ",",
    " ",
    "i",
    "n",
    "s",
    "t",
    "_",
    "l",
    "a",
    "y",
    "e",
    "r",
    "_",
    "v",
    "a",
    "r",
    ",",
    " ",
    "'",
    "s",
    "-",
    "'",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "#",
    "e",
    "7",
    "4",
    "c",
    "3",
    "c",
    "'",
    ",",
    " ",
    "l",
    "a",
    "b",
    "e",
    "l",
    "=",
    "'",
    "I",
    "n",
    "s",
    "t",
    "r",
    "u",
    "c",
    "t",
    "'",
    ",",
    " ",
    "l",
    "i",
    "n",
    "e",
    "w",
    "i",
    "d",
    "t",
    "h",
    "=",
    "2",
    ",",
    " ",
    "m",
    "a",
    "r",
    "k",
    "e",
    "r",
    "s",
    "i",
    "z",
    "e",
    "=",
    "3",
    ")",
    "\n",
    "a",
    "x",
    "4",
    ".",
    "s",
    "e",
    "t",
    "_",
    "x",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "L",
    "a",
    "y",
    "e",
    "r",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "4",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "H",
    "e",
    "a",
    "d",
    " ",
    "V",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "4",
    ".",
    "s",
    "e",
    "t",
    "_",
    "t",
    "i",
    "t",
    "l",
    "e",
    "(",
    "'",
    "L",
    "L",
    "a",
    "M",
    "A",
    "-",
    "3",
    ".",
    "1",
    " ",
    "(",
    "G",
    "Q",
    "A",
    ")",
    ":",
    " ",
    "L",
    "a",
    "y",
    "e",
    "r",
    "-",
    "w",
    "i",
    "s",
    "e",
    " ",
    "H",
    "e",
    "a",
    "d",
    " ",
    "V",
    "a",
    "r",
    "i",
    "a",
    "n",
    "c",
    "e",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "4",
    ".",
    "l",
    "e",
    "g",
    "e",
    "n",
    "d",
    "(",
    ")",
    "\n",
    "a",
    "x",
    "4",
    ".",
    "g",
    "r",
    "i",
    "d",
    "(",
    "T",
    "r",
    "u",
    "e",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "3",
    ")",
    "\n",
    "#",
    " ",
    "M",
    "a",
    "r",
    "k",
    " ",
    "L",
    "*",
    " ",
    "r",
    "e",
    "g",
    "i",
    "o",
    "n",
    "\n",
    "n",
    "u",
    "m",
    "_",
    "l",
    "a",
    "y",
    "e",
    "r",
    "s",
    " ",
    "=",
    " ",
    "l",
    "e",
    "n",
    "(",
    "b",
    "a",
    "s",
    "e",
    "_",
    "l",
    "a",
    "y",
    "e",
    "r",
    "_",
    "v",
    "a",
    "r",
    ")",
    "\n",
    "t",
    "h",
    "i",
    "r",
    "d",
    " ",
    "=",
    " ",
    "n",
    "u",
    "m",
    "_",
    "l",
    "a",
    "y",
    "e",
    "r",
    "s",
    " ",
    "/",
    "/",
    " ",
    "3",
    "\n",
    "a",
    "x",
    "4",
    ".",
    "a",
    "x",
    "v",
    "s",
    "p",
    "a",
    "n",
    "(",
    "t",
    "h",
    "i",
    "r",
    "d",
    ",",
    " ",
    "2",
    "*",
    "t",
    "h",
    "i",
    "r",
    "d",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "2",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "y",
    "e",
    "l",
    "l",
    "o",
    "w",
    "'",
    ",",
    " ",
    "l",
    "a",
    "b",
    "e",
    "l",
    "=",
    "'",
    "L",
    "*",
    " ",
    "R",
    "e",
    "g",
    "i",
    "o",
    "n",
    "'",
    ")",
    "\n",
    "\n",
    "#",
    " ",
    "P",
    "l",
    "o",
    "t",
    " ",
    "5",
    ":",
    " ",
    "H",
    "e",
    "a",
    "d",
    " ",
    "C",
    "o",
    "r",
    "r",
    "e",
    "l",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "H",
    "e",
    "a",
    "t",
    "m",
    "a",
    "p",
    " ",
    "(",
    "B",
    "a",
    "s",
    "e",
    ")",
    "\n",
    "a",
    "x",
    "5",
    " ",
    "=",
    " ",
    "a",
    "x",
    "e",
    "s",
    "[",
    "1",
    ",",
    " ",
    "1",
    "]",
    "\n",
    "b",
    "a",
    "s",
    "e",
    "_",
    "c",
    "o",
    "r",
    "r",
    "_",
    "m",
    "a",
    "t",
    "r",
    "i",
    "x",
    " ",
    "=",
    " ",
    "n",
    "p",
    ".",
    "a",
    "r",
    "r",
    "a",
    "y",
    "(",
    "b",
    "a",
    "s",
    "e",
    "_",
    "s",
    "p",
    "e",
    "c",
    "[",
    "'",
    "h",
    "e",
    "a",
    "d",
    "_",
    "c",
    "o",
    "r",
    "r",
    "e",
    "l",
    "a",
    "t",
    "i",
    "o",
    "n",
    "_",
    "m",
    "a",
    "t",
    "r",
    "i",
    "x",
    "'",
    "]",
    ")",
    "\n",
    "s",
    "n",
    "s",
    ".",
    "h",
    "e",
    "a",
    "t",
    "m",
    "a",
    "p",
    "(",
    "b",
    "a",
    "s",
    "e",
    "_",
    "c",
    "o",
    "r",
    "r",
    "_",
    "m",
    "a",
    "t",
    "r",
    "i",
    "x",
    ",",
    " ",
    "c",
    "m",
    "a",
    "p",
    "=",
    "'",
    "R",
    "d",
    "B",
    "u",
    "_",
    "r",
    "'",
    ",",
    " ",
    "c",
    "e",
    "n",
    "t",
    "e",
    "r",
    "=",
    "0",
    ",",
    " ",
    "v",
    "m",
    "i",
    "n",
    "=",
    "-",
    "1",
    ",",
    " ",
    "v",
    "m",
    "a",
    "x",
    "=",
    "1",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    "a",
    "x",
    "=",
    "a",
    "x",
    "5",
    ",",
    " ",
    "c",
    "b",
    "a",
    "r",
    "_",
    "k",
    "w",
    "s",
    "=",
    "{",
    "'",
    "l",
    "a",
    "b",
    "e",
    "l",
    "'",
    ":",
    " ",
    "'",
    "C",
    "o",
    "r",
    "r",
    "e",
    "l",
    "a",
    "t",
    "i",
    "o",
    "n",
    "'",
    "}",
    ")",
    "\n",
    "a",
    "x",
    "5",
    ".",
    "s",
    "e",
    "t",
    "_",
    "t",
    "i",
    "t",
    "l",
    "e",
    "(",
    "'",
    "G",
    "Q",
    "A",
    " ",
    "B",
    "A",
    "S",
    "E",
    ":",
    " ",
    "H",
    "e",
    "a",
    "d",
    " ",
    "C",
    "o",
    "r",
    "r",
    "e",
    "l",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "M",
    "a",
    "t",
    "r",
    "i",
    "x",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "5",
    ".",
    "s",
    "e",
    "t",
    "_",
    "x",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "H",
    "e",
    "a",
    "d",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "5",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "H",
    "e",
    "a",
    "d",
    "'",
    ")",
    "\n",
    "#",
    " ",
    "M",
    "a",
    "r",
    "k",
    " ",
    "G",
    "Q",
    "A",
    " ",
    "g",
    "r",
    "o",
    "u",
    "p",
    "s",
    "\n",
    "f",
    "o",
    "r",
    " ",
    "g",
    " ",
    "i",
    "n",
    " ",
    "r",
    "a",
    "n",
    "g",
    "e",
    "(",
    "G",
    "Q",
    "A",
    "_",
    "C",
    "O",
    "N",
    "F",
    "I",
    "G",
    "[",
    "'",
    "n",
    "u",
    "m",
    "_",
    "k",
    "v",
    "_",
    "h",
    "e",
    "a",
    "d",
    "s",
    "'",
    "]",
    ")",
    ":",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "s",
    "t",
    "a",
    "r",
    "t",
    " ",
    "=",
    " ",
    "g",
    " ",
    "*",
    " ",
    "4",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "a",
    "x",
    "5",
    ".",
    "a",
    "x",
    "h",
    "l",
    "i",
    "n",
    "e",
    "(",
    "y",
    "=",
    "s",
    "t",
    "a",
    "r",
    "t",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "b",
    "l",
    "a",
    "c",
    "k",
    "'",
    ",",
    " ",
    "l",
    "i",
    "n",
    "e",
    "w",
    "i",
    "d",
    "t",
    "h",
    "=",
    "0",
    ".",
    "5",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "5",
    ")",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "a",
    "x",
    "5",
    ".",
    "a",
    "x",
    "v",
    "l",
    "i",
    "n",
    "e",
    "(",
    "x",
    "=",
    "s",
    "t",
    "a",
    "r",
    "t",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "b",
    "l",
    "a",
    "c",
    "k",
    "'",
    ",",
    " ",
    "l",
    "i",
    "n",
    "e",
    "w",
    "i",
    "d",
    "t",
    "h",
    "=",
    "0",
    ".",
    "5",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "5",
    ")",
    "\n",
    "\n",
    "#",
    " ",
    "P",
    "l",
    "o",
    "t",
    " ",
    "6",
    ":",
    " ",
    "H",
    "e",
    "a",
    "d",
    " ",
    "C",
    "o",
    "r",
    "r",
    "e",
    "l",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "H",
    "e",
    "a",
    "t",
    "m",
    "a",
    "p",
    " ",
    "(",
    "I",
    "n",
    "s",
    "t",
    "r",
    "u",
    "c",
    "t",
    ")",
    "\n",
    "a",
    "x",
    "6",
    " ",
    "=",
    " ",
    "a",
    "x",
    "e",
    "s",
    "[",
    "1",
    ",",
    " ",
    "2",
    "]",
    "\n",
    "i",
    "n",
    "s",
    "t",
    "_",
    "c",
    "o",
    "r",
    "r",
    "_",
    "m",
    "a",
    "t",
    "r",
    "i",
    "x",
    " ",
    "=",
    " ",
    "n",
    "p",
    ".",
    "a",
    "r",
    "r",
    "a",
    "y",
    "(",
    "i",
    "n",
    "s",
    "t",
    "_",
    "s",
    "p",
    "e",
    "c",
    "[",
    "'",
    "h",
    "e",
    "a",
    "d",
    "_",
    "c",
    "o",
    "r",
    "r",
    "e",
    "l",
    "a",
    "t",
    "i",
    "o",
    "n",
    "_",
    "m",
    "a",
    "t",
    "r",
    "i",
    "x",
    "'",
    "]",
    ")",
    "\n",
    "s",
    "n",
    "s",
    ".",
    "h",
    "e",
    "a",
    "t",
    "m",
    "a",
    "p",
    "(",
    "i",
    "n",
    "s",
    "t",
    "_",
    "c",
    "o",
    "r",
    "r",
    "_",
    "m",
    "a",
    "t",
    "r",
    "i",
    "x",
    ",",
    " ",
    "c",
    "m",
    "a",
    "p",
    "=",
    "'",
    "R",
    "d",
    "B",
    "u",
    "_",
    "r",
    "'",
    ",",
    " ",
    "c",
    "e",
    "n",
    "t",
    "e",
    "r",
    "=",
    "0",
    ",",
    " ",
    "v",
    "m",
    "i",
    "n",
    "=",
    "-",
    "1",
    ",",
    " ",
    "v",
    "m",
    "a",
    "x",
    "=",
    "1",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    "a",
    "x",
    "=",
    "a",
    "x",
    "6",
    ",",
    " ",
    "c",
    "b",
    "a",
    "r",
    "_",
    "k",
    "w",
    "s",
    "=",
    "{",
    "'",
    "l",
    "a",
    "b",
    "e",
    "l",
    "'",
    ":",
    " ",
    "'",
    "C",
    "o",
    "r",
    "r",
    "e",
    "l",
    "a",
    "t",
    "i",
    "o",
    "n",
    "'",
    "}",
    ")",
    "\n",
    "a",
    "x",
    "6",
    ".",
    "s",
    "e",
    "t",
    "_",
    "t",
    "i",
    "t",
    "l",
    "e",
    "(",
    "'",
    "G",
    "Q",
    "A",
    " ",
    "I",
    "N",
    "S",
    "T",
    "R",
    "U",
    "C",
    "T",
    ":",
    " ",
    "H",
    "e",
    "a",
    "d",
    " ",
    "C",
    "o",
    "r",
    "r",
    "e",
    "l",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "M",
    "a",
    "t",
    "r",
    "i",
    "x",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "6",
    ".",
    "s",
    "e",
    "t",
    "_",
    "x",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "H",
    "e",
    "a",
    "d",
    "'",
    ")",
    "\n",
    "a",
    "x",
    "6",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "H",
    "e",
    "a",
    "d",
    "'",
    ")",
    "\n",
    "#",
    " ",
    "M",
    "a",
    "r",
    "k",
    " ",
    "G",
    "Q",
    "A",
    " ",
    "g",
    "r",
    "o",
    "u",
    "p",
    "s",
    "\n",
    "f",
    "o",
    "r",
    " ",
    "g",
    " ",
    "i",
    "n",
    " ",
    "r",
    "a",
    "n",
    "g",
    "e",
    "(",
    "G",
    "Q",
    "A",
    "_",
    "C",
    "O",
    "N",
    "F",
    "I",
    "G",
    "[",
    "'",
    "n",
    "u",
    "m",
    "_",
    "k",
    "v",
    "_",
    "h",
    "e",
    "a",
    "d",
    "s",
    "'",
    "]",
    ")",
    ":",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "s",
    "t",
    "a",
    "r",
    "t",
    " ",
    "=",
    " ",
    "g",
    " ",
    "*",
    " ",
    "4",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "a",
    "x",
    "6",
    ".",
    "a",
    "x",
    "h",
    "l",
    "i",
    "n",
    "e",
    "(",
    "y",
    "=",
    "s",
    "t",
    "a",
    "r",
    "t",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "b",
    "l",
    "a",
    "c",
    "k",
    "'",
    ",",
    " ",
    "l",
    "i",
    "n",
    "e",
    "w",
    "i",
    "d",
    "t",
    "h",
    "=",
    "0",
    ".",
    "5",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "5",
    ")",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "a",
    "x",
    "6",
    ".",
    "a",
    "x",
    "v",
    "l",
    "i",
    "n",
    "e",
    "(",
    "x",
    "=",
    "s",
    "t",
    "a",
    "r",
    "t",
    ",",
    " ",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "b",
    "l",
    "a",
    "c",
    "k",
    "'",
    ",",
    " ",
    "l",
    "i",
    "n",
    "e",
    "w",
    "i",
    "d",
    "t",
    "h",
    "=",
    "0",
    ".",
    "5",
    ",",
    " ",
    "a",
    "l",
    "p",
    "h",
    "a",
    "=",
    "0",
    ".",
    "5",
    ")",
    "\n",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "t",
    "i",
    "g",
    "h",
    "t",
    "_",
    "l",
    "a",
    "y",
    "o",
    "u",
    "t",
    "(",
    ")",
    "\n",
    "f",
    "i",
    "g",
    "_",
    "p",
    "a",
    "t",
    "h",
    " ",
    "=",
    " ",
    "f",
    "'",
    "f",
    "i",
    "g",
    "u",
    "r",
    "e",
    "s",
    "/",
    "E",
    "1",
    "1",
    "T",
    "_",
    "g",
    "q",
    "a",
    "_",
    "c",
    "o",
    "m",
    "p",
    "a",
    "r",
    "i",
    "s",
    "o",
    "n",
    "_",
    "{",
    "T",
    "I",
    "M",
    "E",
    "S",
    "T",
    "A",
    "M",
    "P",
    "}",
    ".",
    "p",
    "n",
    "g",
    "'",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "s",
    "a",
    "v",
    "e",
    "f",
    "i",
    "g",
    "(",
    "f",
    "i",
    "g",
    "_",
    "p",
    "a",
    "t",
    "h",
    ",",
    " ",
    "d",
    "p",
    "i",
    "=",
    "1",
    "5",
    "0",
    ",",
    " ",
    "b",
    "b",
    "o",
    "x",
    "_",
    "i",
    "n",
    "c",
    "h",
    "e",
    "s",
    "=",
    "'",
    "t",
    "i",
    "g",
    "h",
    "t",
    "'",
    ")",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "s",
    "h",
    "o",
    "w",
    "(",
    ")",
    "\n",
    "\n",
    "p",
    "r",
    "i",
    "n",
    "t",
    "(",
    "f",
    "\"",
    "\\",
    "n",
    "F",
    "i",
    "g",
    "u",
    "r",
    "e",
    " ",
    "s",
    "a",
    "v",
    "e",
    "d",
    ":",
    " ",
    "{",
    "f",
    "i",
    "g",
    "_",
    "p",
    "a",
    "t",
    "h",
    "}",
    "\"",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Cell 9: Save Results with E11-v3 Methodology Block\n\ndef convert_to_native(obj):\n    \"\"\"Recursively convert numpy types to native Python types.\"\"\"\n    if isinstance(obj, dict):\n        return {k: convert_to_native(v) for k, v in obj.items()}\n    elif isinstance(obj, list):\n        return [convert_to_native(v) for v in obj]\n    elif isinstance(obj, tuple):\n        return tuple(convert_to_native(v) for v in obj)\n    elif isinstance(obj, (np.bool_, np.integer)):\n        return int(obj)\n    elif isinstance(obj, np.floating):\n        return float(obj)\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    else:\n        return obj\n\nfilename = f'results/E11T_gqa_comparison_{TIMESTAMP}.json'\n\noutput = {\n    'experiment': 'E11-T_GQA_Comparison',\n    'timestamp': TIMESTAMP,\n    'model': 'LLaMA-3.1-8B',\n    'architecture': 'GQA',\n    'config': GQA_CONFIG,\n    \n    # E11-v3 METHODOLOGY BLOCK (REQUIRED!)\n    'methodology': {\n        'standard': 'E11-v3',\n        'seeds': SEEDS,\n        'max_length': MAX_LENGTH,\n        'dtype': str(DTYPE),\n        'prompt_md5': actual_md5,\n        'num_prompts': len(STANDARD_PROMPTS),\n        'quantization': 'NONE (Full Precision bfloat16)',\n        'use_chat_template': False\n    },\n    \n    'prompt_set': 'Standard-10 v3',\n    'hypothesis': 'GQA architecture affects territorial collapse differently than MHA',\n    'mha_reference': E11_MHA_REFERENCE,\n    'results': convert_to_native(results),\n    \n    # Runtime info\n    'runtime': {\n        'gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU',\n        'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0,\n        'dtype': str(DTYPE)\n    }\n}\n\nwith open(filename, 'w') as f:\n    json.dump(output, f, indent=2)\n\nprint(f\"Results saved: {filename}\")\nprint(f\"\\n=== E11-v3 METHODOLOGY COMPLIANCE ===\")\nprint(f\"  Seeds: {SEEDS} ✅\")\nprint(f\"  MAX_LENGTH: {MAX_LENGTH} ✅\")\nprint(f\"  dtype: {DTYPE} ✅\")\nprint(f\"  Prompt MD5: {actual_md5} ✅\")\nprint(f\"  Quantization: Full Precision ✅\")\n\n# Download link for Colab\ntry:\n    from google.colab import files\n    files.download(filename)\n    files.download(fig_path)\nexcept:\n    pass",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### E11-T: GQA vs MHA - Territorial Collapse Comparison\n",
    "\n",
    "**Question:** Does GQA (Grouped Query Attention) architecture change how RLHF affects head specialization?\n",
    "\n",
    "**Background:**\n",
    "- E11 found NO territorial collapse in Mistral (MHA): RLHF INCREASED specialization\n",
    "- GQA forces KV sharing (4 query heads : 1 KV head)\n",
    "- This structural constraint might create different specialization dynamics\n",
    "\n",
    "**GQA-Specific Metrics:**\n",
    "- **Within-Group Variance**: How different are query heads sharing the same KV?\n",
    "- **Between-Group Variance**: How different are the 8 KV groups from each other?\n",
    "- **Within/Between Ratio**: Low = groups internally similar but externally different\n",
    "\n",
    "**Key Question:**\n",
    "> Is the \"efficiency-fragility trade-off\" (RLHF removes redundancy) architecture-invariant?\n",
    "\n",
    "---\n",
    "\n",
    "*Paper 4: Behavioral Sink Dynamics*\n",
    "*E11-T: GQA vs MHA - Territorial Collapse Comparison*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cell 11: Artifact Log\n",
    "\n",
    "artifact_entry = {\n",
    "    'experiment': 'E11-T',\n",
    "    'timestamp': TIMESTAMP,\n",
    "    'model': 'LLaMA-3.1-8B',\n",
    "    'architecture': 'GQA',\n",
    "    'verdict': results['verdict']['code'],\n",
    "    'base_specialization': base_si,\n",
    "    'instruct_specialization': inst_si,\n",
    "    'delta_specialization': delta_si,\n",
    "    'base_correlation': base_corr,\n",
    "    'instruct_correlation': inst_corr,\n",
    "    'delta_correlation': delta_corr,\n",
    "    'architecture_invariant': results['mha_comparison']['architecture_invariant'],\n",
    "    'mha_verdict': E11_MHA_REFERENCE['verdict'],\n",
    "    'prompt_count': len(STANDARD_PROMPTS),\n",
    "    'files': {\n",
    "        'results': filename,\n",
    "        'figure': fig_path\n",
    "    }\n",
    "}\n",
    "\n",
    "artifact_log = f'results/E11T_artifact_log.jsonl'\n",
    "with open(artifact_log, 'a') as f:\n",
    "    f.write(json.dumps(artifact_entry) + '\\n')\n",
    "\n",
    "print(f\"Artifact log appended: {artifact_log}\")\n",
    "print(f\"\\nEntry: {json.dumps(artifact_entry, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AUTO-DOWNLOAD RESULTS (Colab only)\n",
    "# ============================================================================\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "def auto_download_results():\n",
    "    try:\n",
    "        from google.colab import files\n",
    "    except ImportError:\n",
    "        print('Not in Colab - skipping auto-download')\n",
    "        return\n",
    "    \n",
    "    print('=' * 60)\n",
    "    print('AUTO-DOWNLOADING RESULTS...')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Find all result files\n",
    "    json_files = glob.glob('results/*.json') + glob.glob('figures/*.json')\n",
    "    png_files = glob.glob('results/*.png') + glob.glob('figures/*.png')\n",
    "    all_files = json_files + png_files\n",
    "    \n",
    "    if not all_files:\n",
    "        print('WARNING: No result files found!')\n",
    "        return\n",
    "    \n",
    "    print(f'Found {len(all_files)} files')\n",
    "    \n",
    "    # Download as ZIP\n",
    "    import os\n",
    "    zip_name = f'E11_results_{os.path.basename(os.getcwd())}'\n",
    "    \n",
    "    # Create combined folder\n",
    "    os.makedirs('download_package', exist_ok=True)\n",
    "    for f in all_files:\n",
    "        shutil.copy(f, 'download_package/')\n",
    "    \n",
    "    shutil.make_archive(zip_name, 'zip', 'download_package')\n",
    "    print(f'Downloading: {zip_name}.zip')\n",
    "    files.download(f'{zip_name}.zip')\n",
    "    print('DOWNLOAD COMPLETE!')\n",
    "\n",
    "auto_download_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
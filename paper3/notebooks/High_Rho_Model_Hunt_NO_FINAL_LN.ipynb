{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-œÅ Model Hunt: Cross-Architecture Validation (NO FINAL LN)\n",
    "\n",
    "**Paper #3 Experiment:** H26 Cross-Architecture Validation (Training Heritage)\n",
    "\n",
    "## KRITISCHE KORREKTUR (2026-01-05)\n",
    "\n",
    "Das urspr√ºngliche Notebook verwendete die **FALSCHE** Metrik:\n",
    "```\n",
    "FALSCH:  G = ||hidden_states[-1]|| / ||hidden_states[-2]||\n",
    "```\n",
    "\n",
    "In HuggingFace ist `hidden_states[-1]` = Output **NACH** dem finalen LayerNorm!\n",
    "Der finale LayerNorm schrumpft ALLE Modelle auf G ‚âà 0.3-0.4.\n",
    "\n",
    "**KORREKTE Metrik:**\n",
    "```\n",
    "KORREKT: G = ||hidden_states[-2]|| / ||hidden_states[-3]||\n",
    "```\n",
    "\n",
    "Dies misst den wahren letzten Transformer-Layer, OHNE den finalen LayerNorm.\n",
    "\n",
    "---\n",
    "\n",
    "## Hypothesen\n",
    "\n",
    "**H25 (Dimensional Crowding):** œÅ = n_heads / d_head ‚â• 0.2 ‚Üí DAMPENING\n",
    "\n",
    "**H26 (Training Heritage):** Verschiedene Labs ‚Üí Verschiedene thermodynamische Signaturen\n",
    "\n",
    "---\n",
    "\n",
    "## Kandidaten\n",
    "- OPT family (Meta)\n",
    "- BLOOM family (BigScience)\n",
    "- Falcon family (TII)\n",
    "- GPT-Neo family (EleutherAI)\n",
    "- StableLM family (Stability AI)\n",
    "- Pythia & GPT-J (Referenz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install transformers torch matplotlib numpy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU memory: {gpu_mem:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate models to analyze\n",
    "CANDIDATE_MODELS = [\n",
    "    # OPT Family (Meta)\n",
    "    'facebook/opt-125m',\n",
    "    'facebook/opt-350m',\n",
    "    'facebook/opt-1.3b',\n",
    "    'facebook/opt-2.7b',\n",
    "    'facebook/opt-6.7b',\n",
    "    \n",
    "    # BLOOM Family (BigScience)\n",
    "    'bigscience/bloom-560m',\n",
    "    'bigscience/bloom-1b1',\n",
    "    'bigscience/bloom-1b7',\n",
    "    'bigscience/bloom-3b',\n",
    "    \n",
    "    # Falcon Family (TII)\n",
    "    'tiiuae/falcon-7b',\n",
    "    \n",
    "    # GPT-Neo Family (EleutherAI)\n",
    "    'EleutherAI/gpt-neo-125M',\n",
    "    'EleutherAI/gpt-neo-1.3B',\n",
    "    'EleutherAI/gpt-neo-2.7B',\n",
    "    \n",
    "    # StableLM (Stability AI)\n",
    "    'stabilityai/stablelm-base-alpha-3b',\n",
    "    \n",
    "    # Reference models (known values from Pythia Family sweep)\n",
    "    'EleutherAI/pythia-6.9b',  # œÅ = 0.25, G_no_ln ‚âà 0.994 (DAMPEN)\n",
    "    'EleutherAI/gpt-j-6B',      # œÅ = 0.0625, G_no_ln ‚âà 1.133 (EXPAND)\n",
    "]\n",
    "\n",
    "print(f\"Candidate models: {len(CANDIDATE_MODELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_info(model_name):\n",
    "    \"\"\"Get architecture details and compute œÅ from config.\"\"\"\n",
    "    try:\n",
    "        config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "        \n",
    "        # Get number of heads\n",
    "        n_heads = getattr(config, 'num_attention_heads', None) or \\\n",
    "                  getattr(config, 'n_head', None) or \\\n",
    "                  getattr(config, 'num_heads', None)\n",
    "        \n",
    "        # Get hidden size\n",
    "        d_model = getattr(config, 'hidden_size', None) or \\\n",
    "                  getattr(config, 'n_embd', None) or \\\n",
    "                  getattr(config, 'd_model', None)\n",
    "        \n",
    "        # Get number of layers\n",
    "        n_layers = getattr(config, 'num_hidden_layers', None) or \\\n",
    "                   getattr(config, 'n_layer', None) or \\\n",
    "                   getattr(config, 'num_layers', None)\n",
    "        \n",
    "        # Compute d_head and œÅ\n",
    "        if n_heads and d_model:\n",
    "            d_head = d_model // n_heads\n",
    "            rho = n_heads / d_head\n",
    "        else:\n",
    "            d_head = None\n",
    "            rho = None\n",
    "        \n",
    "        # Detect normalization type\n",
    "        norm_type = 'Unknown'\n",
    "        if hasattr(config, 'layer_norm_eps'):\n",
    "            norm_type = 'LayerNorm'\n",
    "        if hasattr(config, 'rms_norm_eps'):\n",
    "            norm_type = 'RMSNorm'\n",
    "        \n",
    "        # Detect model family/lab\n",
    "        model_lower = model_name.lower()\n",
    "        if 'opt' in model_lower:\n",
    "            lab = 'Meta'\n",
    "        elif 'bloom' in model_lower:\n",
    "            lab = 'BigScience'\n",
    "        elif 'falcon' in model_lower:\n",
    "            lab = 'TII'\n",
    "        elif 'pythia' in model_lower or 'gpt-neo' in model_lower or 'gpt-j' in model_lower:\n",
    "            lab = 'EleutherAI'\n",
    "        elif 'stablelm' in model_lower:\n",
    "            lab = 'StabilityAI'\n",
    "        else:\n",
    "            lab = 'Unknown'\n",
    "        \n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'lab': lab,\n",
    "            'n_layers': n_layers,\n",
    "            'n_heads': n_heads,\n",
    "            'd_model': d_model,\n",
    "            'd_head': d_head,\n",
    "            'rho': rho,\n",
    "            'norm_type': norm_type,\n",
    "            'status': 'OK'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'status': f'ERROR: {str(e)[:50]}'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan all candidate configs\n",
    "all_configs = []\n",
    "\n",
    "print(\"Scanning model configs...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for model_name in CANDIDATE_MODELS:\n",
    "    print(f\"  {model_name}...\", end=\" \")\n",
    "    result = get_model_info(model_name)\n",
    "    all_configs.append(result)\n",
    "    \n",
    "    if result['status'] == 'OK':\n",
    "        print(f\"œÅ = {result['rho']:.4f}, Lab = {result['lab']}\")\n",
    "    else:\n",
    "        print(result['status'])\n",
    "\n",
    "print(f\"\\nSuccessfully scanned: {sum(1 for c in all_configs if c['status'] == 'OK')} / {len(CANDIDATE_MODELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and sort by œÅ\n",
    "valid_configs = [c for c in all_configs if c['status'] == 'OK' and c['rho'] is not None]\n",
    "sorted_configs = sorted(valid_configs, key=lambda x: x['rho'], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"MODEL RANKING BY HEAD DENSITY (œÅ = n_heads / d_head)\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\n{'Model':<35} {'Lab':<12} {'Layers':>6} {'œÅ':>8} {'Norm':>10} {'H25 Pred':>12}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for c in sorted_configs:\n",
    "    prediction = \"DAMPEN\" if c['rho'] >= 0.2 else \"EXPAND\"\n",
    "    short_name = c['model'].split('/')[-1]\n",
    "    print(f\"{short_name:<35} {c['lab']:<12} {c['n_layers']:>6} {c['rho']:>8.4f} {c['norm_type']:>10} {prediction:>12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompts\n",
    "TEST_PROMPTS = [\n",
    "    \"The capital of France is\",\n",
    "    \"Water freezes at a temperature of\",\n",
    "    \"Actions speak louder than\",\n",
    "    \"The quick brown fox jumps over the lazy\",\n",
    "    \"In mathematics, the Pythagorean theorem states that\",\n",
    "]\n",
    "\n",
    "def compute_residual_gain_NO_FINAL_LN(model, tokenizer, prompts):\n",
    "    \"\"\"\n",
    "    Compute Residual Stream Gain with CORRECTED methodology.\n",
    "    \n",
    "    WICHTIG: In HuggingFace ist hidden_states[-1] = Output NACH finalem LayerNorm!\n",
    "    \n",
    "    FALSCH:  G = ||hidden_states[-1]|| / ||hidden_states[-2]||  (includes final LN artifact)\n",
    "    KORREKT: G = ||hidden_states[-2]|| / ||hidden_states[-3]||  (true last layer gain)\n",
    "    \n",
    "    Returns:\n",
    "        gain_no_ln_mean: Mean gain WITHOUT final LayerNorm (correct)\n",
    "        gain_no_ln_std: Std of correct metric\n",
    "        gain_with_ln_mean: Mean gain WITH final LayerNorm (for comparison, wrong)\n",
    "        all_layer_gains: List of all layer-wise gains\n",
    "    \"\"\"\n",
    "    gains_no_ln = []\n",
    "    gains_with_ln = []\n",
    "    all_layer_gains_per_prompt = []\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        hidden_states = outputs.hidden_states\n",
    "        n_hidden = len(hidden_states)  # embed + n_layers + (sometimes final_ln)\n",
    "        \n",
    "        # Compute ALL layer gains\n",
    "        layer_gains = []\n",
    "        for i in range(1, n_hidden):\n",
    "            h_curr = hidden_states[i][:, -1, :].float()  # Last token\n",
    "            h_prev = hidden_states[i-1][:, -1, :].float()\n",
    "            \n",
    "            norm_curr = torch.norm(h_curr, dim=-1).item()\n",
    "            norm_prev = torch.norm(h_prev, dim=-1).item()\n",
    "            \n",
    "            gain = norm_curr / (norm_prev + 1e-10)\n",
    "            layer_gains.append(gain)\n",
    "        \n",
    "        all_layer_gains_per_prompt.append(layer_gains)\n",
    "        \n",
    "        # WRONG metric (includes final LN): last gain\n",
    "        gain_with_ln = layer_gains[-1] if layer_gains else 1.0\n",
    "        gains_with_ln.append(gain_with_ln)\n",
    "        \n",
    "        # CORRECT metric (no final LN): second-to-last gain\n",
    "        gain_no_ln = layer_gains[-2] if len(layer_gains) >= 2 else layer_gains[-1] if layer_gains else 1.0\n",
    "        gains_no_ln.append(gain_no_ln)\n",
    "    \n",
    "    # Average layer gains across prompts\n",
    "    avg_layer_gains = np.mean(all_layer_gains_per_prompt, axis=0).tolist()\n",
    "    \n",
    "    return {\n",
    "        'gain_no_ln_mean': float(np.mean(gains_no_ln)),\n",
    "        'gain_no_ln_std': float(np.std(gains_no_ln)),\n",
    "        'gain_with_ln_mean': float(np.mean(gains_with_ln)),\n",
    "        'gain_with_ln_std': float(np.std(gains_with_ln)),\n",
    "        'all_layer_gains': avg_layer_gains,\n",
    "        'n_hidden_states': len(hidden_states)\n",
    "    }\n",
    "\n",
    "print(\"compute_residual_gain_NO_FINAL_LN() defined with CORRECTED methodology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select models based on GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    available_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"Available GPU memory: {available_mem:.1f} GB\")\n",
    "else:\n",
    "    available_mem = 8\n",
    "\n",
    "# Memory estimates\n",
    "MEMORY_ESTIMATES = {\n",
    "    'opt-125m': 0.5, 'opt-350m': 1.5, 'opt-1.3b': 5, 'opt-2.7b': 8, 'opt-6.7b': 15,\n",
    "    'bloom-560m': 2, 'bloom-1b1': 4, 'bloom-1b7': 6, 'bloom-3b': 10,\n",
    "    'falcon-7b': 18,\n",
    "    'gpt-neo-125M': 0.5, 'gpt-neo-1.3B': 5, 'gpt-neo-2.7B': 8,\n",
    "    'stablelm-base-alpha-3b': 10,\n",
    "    'pythia-6.9b': 20, 'gpt-j-6B': 18,\n",
    "}\n",
    "\n",
    "# Select models that fit\n",
    "MODELS_TO_TEST = []\n",
    "for c in sorted_configs:\n",
    "    short_name = c['model'].split('/')[-1]\n",
    "    mem_needed = MEMORY_ESTIMATES.get(short_name, 10)\n",
    "    if mem_needed < (available_mem - 2):\n",
    "        MODELS_TO_TEST.append(c)\n",
    "\n",
    "print(f\"\\nModels to test: {len(MODELS_TO_TEST)}\")\n",
    "for c in MODELS_TO_TEST:\n",
    "    print(f\"  - {c['model'].split('/')[-1]} (œÅ = {c['rho']:.4f}, Lab = {c['lab']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each model with CORRECTED methodology\n",
    "results = []\n",
    "\n",
    "for config in MODELS_TO_TEST:\n",
    "    model_name = config['model']\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing: {model_name}\")\n",
    "    print(f\"Lab: {config['lab']}, œÅ = {config['rho']:.4f}, Layers = {config['n_layers']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "            trust_remote_code=True,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        model.eval()\n",
    "        \n",
    "        # Compute gains with CORRECTED methodology\n",
    "        gain_results = compute_residual_gain_NO_FINAL_LN(model, tokenizer, TEST_PROMPTS)\n",
    "        \n",
    "        # Use CORRECT metric (no final LN)\n",
    "        gain_no_ln = gain_results['gain_no_ln_mean']\n",
    "        gain_with_ln = gain_results['gain_with_ln_mean']\n",
    "        \n",
    "        is_dampening = gain_no_ln < 1.0\n",
    "        status = \"DAMPENING\" if is_dampening else \"EXPANSION\"\n",
    "        \n",
    "        # H25 prediction based on œÅ\n",
    "        h25_pred_dampen = config['rho'] >= 0.2\n",
    "        h25_correct = (h25_pred_dampen and is_dampening) or (not h25_pred_dampen and not is_dampening)\n",
    "        \n",
    "        print(f\"\\n  RESULTS:\")\n",
    "        print(f\"    G (WITH final LN):    {gain_with_ln:.4f} ¬± {gain_results['gain_with_ln_std']:.4f}  [ARTIFACT!]\")\n",
    "        print(f\"    G (NO final LN):      {gain_no_ln:.4f} ¬± {gain_results['gain_no_ln_std']:.4f}  [CORRECT]\")\n",
    "        print(f\"    Status:               {status}\")\n",
    "        print(f\"    H25 (œÅ‚â•0.2‚ÜíDampen):   {'‚úÖ CORRECT' if h25_correct else '‚ùå WRONG'}\")\n",
    "        \n",
    "        result = config.copy()\n",
    "        result.update({\n",
    "            'gain_no_ln_mean': gain_no_ln,\n",
    "            'gain_no_ln_std': gain_results['gain_no_ln_std'],\n",
    "            'gain_with_ln_mean': gain_with_ln,\n",
    "            'gain_with_ln_std': gain_results['gain_with_ln_std'],\n",
    "            'all_layer_gains': gain_results['all_layer_gains'],\n",
    "            'n_hidden_states': gain_results['n_hidden_states'],\n",
    "            'is_dampening': bool(is_dampening),\n",
    "            'h25_prediction_correct': bool(h25_correct)\n",
    "        })\n",
    "        results.append(result)\n",
    "        \n",
    "        del model, tokenizer\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        result = config.copy()\n",
    "        result['status'] = f'ERROR: {str(e)[:50]}'\n",
    "        results.append(result)\n",
    "\n",
    "print(f\"\\n\\nTested: {len(results)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Table\n",
    "tested_results = [r for r in results if 'gain_no_ln_mean' in r]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 110)\n",
    "print(\"CROSS-ARCHITECTURE VALIDATION (NO FINAL LN) - H25 + H26\")\n",
    "print(\"=\" * 110)\n",
    "\n",
    "print(f\"\\n{'Model':<30} {'Lab':<12} {'œÅ':>8} {'G(w/ LN)':>10} {'G(no LN)':>10} {'Status':>10} {'H25':>6}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "for r in sorted(tested_results, key=lambda x: x['rho'], reverse=True):\n",
    "    short_name = r['model'].split('/')[-1]\n",
    "    status = \"DAMPEN\" if r['is_dampening'] else \"EXPAND\"\n",
    "    h25 = \"‚úÖ\" if r['h25_prediction_correct'] else \"‚ùå\"\n",
    "    \n",
    "    print(f\"{short_name:<30} {r['lab']:<12} {r['rho']:>8.4f} {r['gain_with_ln_mean']:>10.4f} {r['gain_no_ln_mean']:>10.4f} {status:>10} {h25:>6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H26 Analysis: Group by Lab (Training Heritage)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"H26 ANALYSIS: TRAINING HERITAGE (Lab ‚Üí Thermodynamic Signature)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "lab_results = defaultdict(list)\n",
    "for r in tested_results:\n",
    "    lab_results[r['lab']].append(r)\n",
    "\n",
    "print(f\"\\n{'Lab':<15} {'Models':>8} {'Mean G':>10} {'Std G':>10} {'Dampen %':>12} {'Signature':>15}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "lab_signatures = {}\n",
    "for lab, models in sorted(lab_results.items()):\n",
    "    gains = [m['gain_no_ln_mean'] for m in models]\n",
    "    dampen_pct = 100 * sum(1 for m in models if m['is_dampening']) / len(models)\n",
    "    \n",
    "    mean_g = np.mean(gains)\n",
    "    std_g = np.std(gains)\n",
    "    \n",
    "    if mean_g < 0.95:\n",
    "        signature = \"DAMPENER\"\n",
    "    elif mean_g > 1.05:\n",
    "        signature = \"EXPANDER\"\n",
    "    else:\n",
    "        signature = \"NEUTRAL\"\n",
    "    \n",
    "    lab_signatures[lab] = {\n",
    "        'mean_gain': mean_g,\n",
    "        'std_gain': std_g,\n",
    "        'dampen_pct': dampen_pct,\n",
    "        'signature': signature,\n",
    "        'n_models': len(models)\n",
    "    }\n",
    "    \n",
    "    print(f\"{lab:<15} {len(models):>8} {mean_g:>10.4f} {std_g:>10.4f} {dampen_pct:>11.1f}% {signature:>15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "if tested_results:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    # Color by lab\n",
    "    lab_colors = {\n",
    "        'EleutherAI': 'blue',\n",
    "        'Meta': 'red',\n",
    "        'BigScience': 'green',\n",
    "        'TII': 'orange',\n",
    "        'StabilityAI': 'purple',\n",
    "        'Unknown': 'gray'\n",
    "    }\n",
    "    \n",
    "    # Panel 1: œÅ vs Gain (NO FINAL LN) - colored by lab\n",
    "    ax1 = axes[0, 0]\n",
    "    for r in tested_results:\n",
    "        color = lab_colors.get(r['lab'], 'gray')\n",
    "        marker = 'o' if r['is_dampening'] else 's'\n",
    "        ax1.scatter(r['rho'], r['gain_no_ln_mean'], c=color, s=150, marker=marker,\n",
    "                   edgecolors='black', linewidth=1, alpha=0.8, label=r['lab'])\n",
    "    \n",
    "    ax1.axhline(y=1.0, color='black', linestyle='--', alpha=0.7, label='G=1.0 (Bentov)')\n",
    "    ax1.axvline(x=0.2, color='purple', linestyle=':', alpha=0.7, label='œÅ=0.2')\n",
    "    ax1.set_xlabel('œÅ = n_heads / d_head', fontsize=12)\n",
    "    ax1.set_ylabel('Residual Gain (NO Final LN)', fontsize=12)\n",
    "    ax1.set_title('H25: œÅ vs Gain (CORRECTED)', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add model names\n",
    "    for r in tested_results:\n",
    "        name = r['model'].split('/')[-1]\n",
    "        ax1.annotate(name, (r['rho'], r['gain_no_ln_mean']), \n",
    "                    textcoords=\"offset points\", xytext=(3, 3), fontsize=7, rotation=15)\n",
    "    \n",
    "    # Panel 2: Lab comparison (H26)\n",
    "    ax2 = axes[0, 1]\n",
    "    labs = list(lab_signatures.keys())\n",
    "    mean_gains = [lab_signatures[l]['mean_gain'] for l in labs]\n",
    "    colors = [lab_colors.get(l, 'gray') for l in labs]\n",
    "    \n",
    "    bars = ax2.bar(labs, mean_gains, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax2.axhline(y=1.0, color='black', linestyle='--', alpha=0.7)\n",
    "    ax2.set_ylabel('Mean Gain (NO Final LN)', fontsize=12)\n",
    "    ax2.set_title('H26: Training Heritage ‚Üí Thermodynamic Signature', fontsize=14, fontweight='bold')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    for bar, val in zip(bars, mean_gains):\n",
    "        ax2.annotate(f'{val:.3f}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Panel 3: WITH vs WITHOUT Final LN comparison\n",
    "    ax3 = axes[1, 0]\n",
    "    gains_with = [r['gain_with_ln_mean'] for r in tested_results]\n",
    "    gains_no = [r['gain_no_ln_mean'] for r in tested_results]\n",
    "    names = [r['model'].split('/')[-1] for r in tested_results]\n",
    "    \n",
    "    ax3.scatter(gains_with, gains_no, c=[lab_colors.get(r['lab'], 'gray') for r in tested_results],\n",
    "               s=150, edgecolors='black', linewidth=1)\n",
    "    ax3.plot([0, 2], [0, 2], 'k--', alpha=0.3, label='y=x')\n",
    "    ax3.axhline(y=1.0, color='red', linestyle=':', alpha=0.5)\n",
    "    ax3.axvline(x=1.0, color='red', linestyle=':', alpha=0.5)\n",
    "    ax3.set_xlabel('Gain WITH Final LN (WRONG)', fontsize=12)\n",
    "    ax3.set_ylabel('Gain NO Final LN (CORRECT)', fontsize=12)\n",
    "    ax3.set_title('Final LayerNorm Artifact Comparison', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Panel 4: Layer-wise gains for selected models\n",
    "    ax4 = axes[1, 1]\n",
    "    for r in tested_results:\n",
    "        if r['lab'] in ['EleutherAI', 'Meta', 'BigScience']:\n",
    "            color = lab_colors.get(r['lab'], 'gray')\n",
    "            gains = r['all_layer_gains']\n",
    "            ax4.plot(range(len(gains)), gains, '-o', markersize=2, \n",
    "                    label=f\"{r['model'].split('/')[-1]}\", color=color, alpha=0.7)\n",
    "    \n",
    "    ax4.axhline(y=1.0, color='black', linestyle='--', alpha=0.5)\n",
    "    ax4.set_xlabel('Layer', fontsize=12)\n",
    "    ax4.set_ylabel('Layer Gain', fontsize=12)\n",
    "    ax4.set_title('Layer-wise Dynamics (Selected Models)', fontsize=14, fontweight='bold')\n",
    "    ax4.legend(fontsize=8, loc='upper right')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('high_rho_hunt_NO_FINAL_LN.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nSaved: high_rho_hunt_NO_FINAL_LN.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H25 + H26 Verdict\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL VERDICT: H25 + H26\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# H25 Analysis\n",
    "h25_correct = sum(1 for r in tested_results if r['h25_prediction_correct'])\n",
    "h25_accuracy = h25_correct / len(tested_results) if tested_results else 0\n",
    "\n",
    "print(f\"\\nüìê H25 (Dimensional Crowding): œÅ ‚â• 0.2 ‚Üí DAMPEN\")\n",
    "print(f\"   Accuracy: {h25_correct}/{len(tested_results)} = {h25_accuracy*100:.1f}%\")\n",
    "\n",
    "if h25_accuracy >= 0.75:\n",
    "    h25_verdict = \"VALIDATED\"\n",
    "elif h25_accuracy >= 0.50:\n",
    "    h25_verdict = \"PARTIAL\"\n",
    "else:\n",
    "    h25_verdict = \"FALSIFIED\"\n",
    "print(f\"   Verdict: {h25_verdict}\")\n",
    "\n",
    "# H26 Analysis\n",
    "print(f\"\\nüèõÔ∏è H26 (Training Heritage): Lab ‚Üí Thermodynamic Signature\")\n",
    "for lab, sig in lab_signatures.items():\n",
    "    print(f\"   {lab}: {sig['signature']} (G = {sig['mean_gain']:.4f})\")\n",
    "\n",
    "# Check if labs have distinct signatures\n",
    "signatures = set(s['signature'] for s in lab_signatures.values())\n",
    "if len(signatures) >= 2:\n",
    "    h26_verdict = \"VALIDATED\"\n",
    "    print(f\"\\n   ‚úÖ H26 VALIDATED: Different labs show different thermodynamic profiles!\")\n",
    "else:\n",
    "    h26_verdict = \"INCONCLUSIVE\"\n",
    "    print(f\"\\n   ‚ö†Ô∏è H26 INCONCLUSIVE: All labs show similar profiles\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(f\"SUMMARY\")\n",
    "print(f\"=\" * 80)\n",
    "print(f\"\\n   H25 (œÅ ‚Üí Phase):       {h25_verdict}\")\n",
    "print(f\"   H26 (Lab ‚Üí Heritage):  {h26_verdict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "output_data = {\n",
    "    'experiment': 'High-œÅ Model Hunt - NO FINAL LN (Corrected)',\n",
    "    'hypotheses': {\n",
    "        'H25': 'œÅ ‚â• 0.2 ‚Üí Dampening',\n",
    "        'H26': 'Training Lab ‚Üí Thermodynamic Signature'\n",
    "    },\n",
    "    'methodology': {\n",
    "        'wrong': 'hidden_states[-1] / hidden_states[-2] (includes final LN)',\n",
    "        'correct': 'hidden_states[-2] / hidden_states[-3] (excludes final LN)'\n",
    "    },\n",
    "    'date': datetime.now().isoformat(),\n",
    "    'models_scanned': len(all_configs),\n",
    "    'models_tested': len(tested_results),\n",
    "    'h25_accuracy': float(h25_accuracy),\n",
    "    'h25_verdict': h25_verdict,\n",
    "    'h26_lab_signatures': {k: {kk: float(vv) if isinstance(vv, (int, float, np.floating)) else vv \n",
    "                               for kk, vv in v.items()} \n",
    "                          for k, v in lab_signatures.items()},\n",
    "    'h26_verdict': h26_verdict,\n",
    "    'tested_results': [{k: (float(v) if isinstance(v, (np.floating, np.integer)) else \n",
    "                           bool(v) if isinstance(v, np.bool_) else \n",
    "                           [float(x) for x in v] if isinstance(v, list) and v and isinstance(v[0], (np.floating, float)) else v)\n",
    "                       for k, v in r.items()} for r in tested_results]\n",
    "}\n",
    "\n",
    "filename = f'high_rho_hunt_NO_FINAL_LN_{timestamp}.json'\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(output_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nSaved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-download\n",
    "import zipfile\n",
    "\n",
    "archive_name = f'high_rho_hunt_NO_FINAL_LN_{timestamp}.zip'\n",
    "\n",
    "with zipfile.ZipFile(archive_name, 'w') as zf:\n",
    "    zf.write(filename)\n",
    "    zf.write('high_rho_hunt_NO_FINAL_LN.png')\n",
    "\n",
    "print(f\"Created archive: {archive_name}\")\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(filename)\n",
    "    files.download('high_rho_hunt_NO_FINAL_LN.png')\n",
    "    files.download(archive_name)\n",
    "except ImportError:\n",
    "    print(\"Not in Colab - manual download required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY: High-œÅ Model Hunt (CORRECTED)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìä Models Scanned: {len(all_configs)}\")\n",
    "print(f\"üî¨ Models Tested: {len(tested_results)}\")\n",
    "print(f\"\\nüéØ H25 Accuracy: {h25_accuracy*100:.1f}%\")\n",
    "print(f\"üìã H25 Verdict: {h25_verdict}\")\n",
    "print(f\"\\nüèõÔ∏è H26 Verdict: {h26_verdict}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY INSIGHT: Final LayerNorm Artifact\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\"\"\n",
    "Das urspr√ºngliche Experiment (43.75% Accuracy) war durch den\n",
    "Final LayerNorm Artifact verf√§lscht.\n",
    "\n",
    "Mit der korrigierten Methodik:\n",
    "  G = ||hidden_states[-2]|| / ||hidden_states[-3]||\n",
    "\n",
    "zeigt sich die wahre thermodynamische Signatur jedes Modells.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

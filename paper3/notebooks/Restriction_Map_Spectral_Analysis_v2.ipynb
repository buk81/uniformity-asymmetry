{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restriction Map Spectral Analysis v2 (Fixed Architectures)\n",
    "\n",
    "## Fixes in v2:\n",
    "- GPT-Neo: Uses `attention.k_proj`, `v_proj`, `q_proj`, `out_proj`\n",
    "- OPT: Uses `model.model.decoder.layers` with `self_attn.*_proj`\n",
    "- BLOOM: Uses `transformer.h` with `self_attention.query_key_value`\n",
    "\n",
    "---\n",
    "*Paper #3: Thermodynamics of Language Models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch matplotlib seaborn pandas scipy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "import gc\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to test - Representatives from each lab\n",
    "MODELS_CONFIG = {\n",
    "    # EleutherAI (Dampener Heritage)\n",
    "    \"EleutherAI/pythia-160m\": {\n",
    "        \"lab\": \"EleutherAI\",\n",
    "        \"expected\": \"DAMPENER\",\n",
    "        \"color\": \"#E74C3C\",\n",
    "        \"marker\": \"o\"\n",
    "    },\n",
    "    \"EleutherAI/pythia-410m\": {\n",
    "        \"lab\": \"EleutherAI\",\n",
    "        \"expected\": \"DAMPENER\",\n",
    "        \"color\": \"#C0392B\",\n",
    "        \"marker\": \"s\"\n",
    "    },\n",
    "    \"EleutherAI/gpt-neo-125M\": {\n",
    "        \"lab\": \"EleutherAI\",\n",
    "        \"expected\": \"DAMPENER\",\n",
    "        \"color\": \"#F39C12\",\n",
    "        \"marker\": \"^\"\n",
    "    },\n",
    "    \n",
    "    # Meta (Expander Heritage)\n",
    "    \"facebook/opt-125m\": {\n",
    "        \"lab\": \"Meta\",\n",
    "        \"expected\": \"EXPANDER\",\n",
    "        \"color\": \"#3498DB\",\n",
    "        \"marker\": \"o\"\n",
    "    },\n",
    "    \"facebook/opt-350m\": {\n",
    "        \"lab\": \"Meta\",\n",
    "        \"expected\": \"EXPANDER\",\n",
    "        \"color\": \"#2980B9\",\n",
    "        \"marker\": \"s\"\n",
    "    },\n",
    "    \n",
    "    # BigScience (Expander Heritage - ALiBi)\n",
    "    \"bigscience/bloom-560m\": {\n",
    "        \"lab\": \"BigScience\",\n",
    "        \"expected\": \"EXPANDER\",\n",
    "        \"color\": \"#27AE60\",\n",
    "        \"marker\": \"o\"\n",
    "    },\n",
    "    \n",
    "    # OpenAI (Baseline)\n",
    "    \"gpt2\": {\n",
    "        \"lab\": \"OpenAI\",\n",
    "        \"expected\": \"NEUTRAL\",\n",
    "        \"color\": \"#9B59B6\",\n",
    "        \"marker\": \"o\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Testing {len(MODELS_CONFIG)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_architecture(model, model_name: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Detect model architecture and return (layers, arch_type).\n",
    "    \n",
    "    Supported architectures:\n",
    "    - neox: Pythia (gpt_neox.layers)\n",
    "    - gpt_neo: GPT-Neo (transformer.h with attention.k_proj)\n",
    "    - gpt2: GPT-2 (transformer.h with attn.c_attn)\n",
    "    - opt: OPT (model.model.decoder.layers)\n",
    "    - bloom: BLOOM (transformer.h with self_attention)\n",
    "    - llama: Llama/Mistral (model.layers)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check for Pythia (GPT-NeoX)\n",
    "    if hasattr(model, 'gpt_neox'):\n",
    "        return model.gpt_neox.layers, 'neox'\n",
    "    \n",
    "    # Check for OPT (has model.model.decoder)\n",
    "    if hasattr(model, 'model') and hasattr(model.model, 'decoder'):\n",
    "        return model.model.decoder.layers, 'opt'\n",
    "    \n",
    "    # Check for Llama/Mistral (has model.model.layers)\n",
    "    if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
    "        return model.model.layers, 'llama'\n",
    "    \n",
    "    # Check for transformer.h based models (GPT-2, GPT-Neo, GPT-J, BLOOM)\n",
    "    if hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n",
    "        layers = model.transformer.h\n",
    "        layer0 = layers[0]\n",
    "        \n",
    "        # BLOOM: has self_attention.query_key_value\n",
    "        if hasattr(layer0, 'self_attention') and hasattr(layer0.self_attention, 'query_key_value'):\n",
    "            return layers, 'bloom'\n",
    "        \n",
    "        # GPT-Neo: has attn.attention with k_proj, v_proj, q_proj\n",
    "        if hasattr(layer0, 'attn') and hasattr(layer0.attn, 'attention'):\n",
    "            if hasattr(layer0.attn.attention, 'k_proj'):\n",
    "                return layers, 'gpt_neo'\n",
    "        \n",
    "        # GPT-J: has attn.out_proj directly\n",
    "        if hasattr(layer0, 'attn') and hasattr(layer0.attn, 'out_proj'):\n",
    "            return layers, 'gptj'\n",
    "        \n",
    "        # GPT-2: has attn.c_attn\n",
    "        if hasattr(layer0, 'attn') and hasattr(layer0.attn, 'c_attn'):\n",
    "            return layers, 'gpt2'\n",
    "    \n",
    "    return None, 'unknown'\n",
    "\n",
    "\n",
    "def get_projection_matrices(model, model_name: str) -> Dict[str, List[torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Extract W_V and W_O from all layers.\n",
    "    Handles multiple architectures correctly.\n",
    "    \"\"\"\n",
    "    W_V_list = []\n",
    "    W_O_list = []\n",
    "    W_Q_list = []\n",
    "    W_K_list = []\n",
    "    \n",
    "    layers, arch = detect_architecture(model, model_name)\n",
    "    \n",
    "    if layers is None:\n",
    "        print(f\"  Unknown architecture for {model_name}\")\n",
    "        # Debug: print model structure\n",
    "        print(f\"  Model attributes: {[a for a in dir(model) if not a.startswith('_')]}\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"  Architecture: {arch}, Layers: {len(layers)}\")\n",
    "    \n",
    "    for i, layer in enumerate(layers):\n",
    "        try:\n",
    "            W_Q, W_K, W_V, W_O = None, None, None, None\n",
    "            \n",
    "            if arch == 'neox':  # Pythia\n",
    "                qkv = layer.attention.query_key_value.weight.detach()\n",
    "                hidden_size = qkv.shape[0] // 3\n",
    "                W_Q = qkv[:hidden_size, :]\n",
    "                W_K = qkv[hidden_size:2*hidden_size, :]\n",
    "                W_V = qkv[2*hidden_size:, :]\n",
    "                W_O = layer.attention.dense.weight.detach()\n",
    "                \n",
    "            elif arch == 'gpt_neo':  # GPT-Neo\n",
    "                # GPT-Neo has nested attention structure\n",
    "                attn = layer.attn.attention\n",
    "                W_Q = attn.q_proj.weight.detach()\n",
    "                W_K = attn.k_proj.weight.detach()\n",
    "                W_V = attn.v_proj.weight.detach()\n",
    "                W_O = attn.out_proj.weight.detach()\n",
    "                \n",
    "            elif arch == 'gptj':  # GPT-J\n",
    "                W_Q = layer.attn.q_proj.weight.detach()\n",
    "                W_K = layer.attn.k_proj.weight.detach()\n",
    "                W_V = layer.attn.v_proj.weight.detach()\n",
    "                W_O = layer.attn.out_proj.weight.detach()\n",
    "                \n",
    "            elif arch == 'gpt2':  # GPT-2\n",
    "                c_attn = layer.attn.c_attn.weight.detach()\n",
    "                hidden_size = c_attn.shape[1] // 3\n",
    "                W_Q = c_attn[:, :hidden_size].T\n",
    "                W_K = c_attn[:, hidden_size:2*hidden_size].T\n",
    "                W_V = c_attn[:, 2*hidden_size:].T\n",
    "                W_O = layer.attn.c_proj.weight.detach().T\n",
    "                \n",
    "            elif arch == 'opt':  # OPT\n",
    "                attn = layer.self_attn\n",
    "                W_Q = attn.q_proj.weight.detach()\n",
    "                W_K = attn.k_proj.weight.detach()\n",
    "                W_V = attn.v_proj.weight.detach()\n",
    "                W_O = attn.out_proj.weight.detach()\n",
    "                \n",
    "            elif arch == 'bloom':  # BLOOM\n",
    "                qkv = layer.self_attention.query_key_value.weight.detach()\n",
    "                hidden_size = qkv.shape[0] // 3\n",
    "                W_Q = qkv[:hidden_size, :]\n",
    "                W_K = qkv[hidden_size:2*hidden_size, :]\n",
    "                W_V = qkv[2*hidden_size:, :]\n",
    "                W_O = layer.self_attention.dense.weight.detach()\n",
    "                \n",
    "            elif arch == 'llama':  # Llama/Mistral\n",
    "                W_Q = layer.self_attn.q_proj.weight.detach()\n",
    "                W_K = layer.self_attn.k_proj.weight.detach()\n",
    "                W_V = layer.self_attn.v_proj.weight.detach()\n",
    "                W_O = layer.self_attn.o_proj.weight.detach()\n",
    "            \n",
    "            if W_V is not None:\n",
    "                W_Q_list.append(W_Q.float())\n",
    "                W_K_list.append(W_K.float())\n",
    "                W_V_list.append(W_V.float())\n",
    "                W_O_list.append(W_O.float())\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Layer {i} error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return {\n",
    "        'W_Q': W_Q_list,\n",
    "        'W_K': W_K_list,\n",
    "        'W_V': W_V_list,\n",
    "        'W_O': W_O_list,\n",
    "        'arch': arch,\n",
    "        'n_layers': len(layers)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_signature(matrices: List[torch.Tensor]) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute SVD spectral signatures.\n",
    "    \"\"\"\n",
    "    if not matrices:\n",
    "        return {}\n",
    "    \n",
    "    all_singular_values = []\n",
    "    spectral_norms = []\n",
    "    frobenius_norms = []\n",
    "    effective_ranks = []\n",
    "    \n",
    "    for W in matrices:\n",
    "        try:\n",
    "            S = torch.linalg.svdvals(W)\n",
    "            s = S.cpu().numpy()\n",
    "            \n",
    "            all_singular_values.append(s)\n",
    "            spectral_norms.append(s[0])\n",
    "            frobenius_norms.append(np.sqrt(np.sum(s**2)))\n",
    "            \n",
    "            s_norm = s / (s.sum() + 1e-10)\n",
    "            entropy = -np.sum(s_norm * np.log(s_norm + 1e-10))\n",
    "            effective_ranks.append(np.exp(entropy))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  SVD error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return {\n",
    "        'singular_values': all_singular_values,\n",
    "        'spectral_norm': np.array(spectral_norms),\n",
    "        'frobenius_norm': np.array(frobenius_norms),\n",
    "        'effective_rank': np.array(effective_ranks)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(model_name: str, config: Dict) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Full spectral analysis for a single model.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Analyzing: {model_name}\")\n",
    "    print(f\"Lab: {config['lab']}, Expected: {config['expected']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"  Loading model...\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float32,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        model.eval()\n",
    "        \n",
    "        print(\"  Extracting projection matrices...\")\n",
    "        matrices = get_projection_matrices(model, model_name)\n",
    "        \n",
    "        if not matrices or not matrices.get('W_V'):\n",
    "            print(\"  No matrices extracted!\")\n",
    "            del model\n",
    "            gc.collect()\n",
    "            return None\n",
    "        \n",
    "        print(\"  Computing spectral signatures...\")\n",
    "        results = {\n",
    "            'model': model_name,\n",
    "            'lab': config['lab'],\n",
    "            'expected': config['expected'],\n",
    "            'color': config['color'],\n",
    "            'marker': config['marker'],\n",
    "            'arch': matrices['arch'],\n",
    "            'n_layers': matrices['n_layers']\n",
    "        }\n",
    "        \n",
    "        for matrix_type in ['W_V', 'W_O', 'W_Q', 'W_K']:\n",
    "            if matrices.get(matrix_type):\n",
    "                spectral = compute_spectral_signature(matrices[matrix_type])\n",
    "                if spectral:\n",
    "                    results[f'{matrix_type}_spectral_norm'] = spectral['spectral_norm']\n",
    "                    results[f'{matrix_type}_frobenius_norm'] = spectral['frobenius_norm']\n",
    "                    results[f'{matrix_type}_effective_rank'] = spectral['effective_rank']\n",
    "                    results[f'{matrix_type}_mean_spectral'] = float(np.mean(spectral['spectral_norm']))\n",
    "                    results[f'{matrix_type}_std_spectral'] = float(np.std(spectral['spectral_norm']))\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        wv_mean = results.get('W_V_mean_spectral', 'N/A')\n",
    "        wo_mean = results.get('W_O_mean_spectral', 'N/A')\n",
    "        if isinstance(wv_mean, float):\n",
    "            print(f\"  W_V mean spectral norm: {wv_mean:.4f}\")\n",
    "        if isinstance(wo_mean, float):\n",
    "            print(f\"  W_O mean spectral norm: {wo_mean:.4f}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis on all models\n",
    "all_results = []\n",
    "\n",
    "for model_name, config in MODELS_CONFIG.items():\n",
    "    result = analyze_model(model_name, config)\n",
    "    if result:\n",
    "        all_results.append(result)\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(f\"Successfully analyzed {len(all_results)} / {len(MODELS_CONFIG)} models\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_results:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    # Plot 1: W_V Spectral Norm by Layer\n",
    "    ax1 = axes[0, 0]\n",
    "    for res in all_results:\n",
    "        if 'W_V_spectral_norm' in res:\n",
    "            ax1.plot(\n",
    "                res['W_V_spectral_norm'],\n",
    "                label=f\"{res['model'].split('/')[-1]} ({res['lab']})\",\n",
    "                color=res['color'],\n",
    "                marker=res['marker'],\n",
    "                markersize=4,\n",
    "                alpha=0.8\n",
    "            )\n",
    "    ax1.set_title('W_V Spectral Norm by Layer', fontsize=14)\n",
    "    ax1.set_xlabel('Layer')\n",
    "    ax1.set_ylabel('||W_V||_2')\n",
    "    ax1.legend(fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: W_O Spectral Norm by Layer\n",
    "    ax2 = axes[0, 1]\n",
    "    for res in all_results:\n",
    "        if 'W_O_spectral_norm' in res:\n",
    "            ax2.plot(\n",
    "                res['W_O_spectral_norm'],\n",
    "                label=f\"{res['model'].split('/')[-1]} ({res['lab']})\",\n",
    "                color=res['color'],\n",
    "                marker=res['marker'],\n",
    "                markersize=4,\n",
    "                alpha=0.8\n",
    "            )\n",
    "    ax2.set_title('W_O Spectral Norm by Layer', fontsize=14)\n",
    "    ax2.set_xlabel('Layer')\n",
    "    ax2.set_ylabel('||W_O||_2')\n",
    "    ax2.legend(fontsize=8)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Lab Comparison Bar Chart\n",
    "    ax3 = axes[1, 0]\n",
    "    lab_data = {}\n",
    "    for res in all_results:\n",
    "        lab = res['lab']\n",
    "        if lab not in lab_data:\n",
    "            lab_data[lab] = {'W_V': [], 'W_O': [], 'color': res['color']}\n",
    "        if 'W_V_mean_spectral' in res:\n",
    "            lab_data[lab]['W_V'].append(res['W_V_mean_spectral'])\n",
    "        if 'W_O_mean_spectral' in res:\n",
    "            lab_data[lab]['W_O'].append(res['W_O_mean_spectral'])\n",
    "    \n",
    "    labs = list(lab_data.keys())\n",
    "    x = np.arange(len(labs))\n",
    "    width = 0.35\n",
    "    \n",
    "    wv_means = [np.mean(lab_data[l]['W_V']) if lab_data[l]['W_V'] else 0 for l in labs]\n",
    "    wo_means = [np.mean(lab_data[l]['W_O']) if lab_data[l]['W_O'] else 0 for l in labs]\n",
    "    colors = [lab_data[l]['color'] for l in labs]\n",
    "    \n",
    "    ax3.bar(x - width/2, wv_means, width, label='W_V', color=colors, alpha=0.7)\n",
    "    ax3.bar(x + width/2, wo_means, width, label='W_O', color=colors, alpha=0.4, hatch='//')\n",
    "    ax3.set_title('Mean Spectral Norm by Lab', fontsize=14)\n",
    "    ax3.set_xlabel('Lab')\n",
    "    ax3.set_ylabel('Mean Spectral Norm')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(labs)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 4: Effective Rank\n",
    "    ax4 = axes[1, 1]\n",
    "    for res in all_results:\n",
    "        if 'W_V_effective_rank' in res:\n",
    "            ax4.plot(\n",
    "                res['W_V_effective_rank'],\n",
    "                label=f\"{res['model'].split('/')[-1]}\",\n",
    "                color=res['color'],\n",
    "                marker=res['marker'],\n",
    "                markersize=4,\n",
    "                alpha=0.8\n",
    "            )\n",
    "    ax4.set_title('W_V Effective Rank by Layer', fontsize=14)\n",
    "    ax4.set_xlabel('Layer')\n",
    "    ax4.set_ylabel('Effective Rank')\n",
    "    ax4.legend(fontsize=8)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('restriction_map_spectral_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\nFigure saved: restriction_map_spectral_analysis.png\")\n",
    "else:\n",
    "    print(\"No results to visualize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_results:\n",
    "    # Summary table\n",
    "    summary_data = []\n",
    "    for res in all_results:\n",
    "        summary_data.append({\n",
    "            'Model': res['model'].split('/')[-1],\n",
    "            'Lab': res['lab'],\n",
    "            'Expected': res['expected'],\n",
    "            'Layers': res['n_layers'],\n",
    "            'W_V Mean': res.get('W_V_mean_spectral', np.nan),\n",
    "            'W_O Mean': res.get('W_O_mean_spectral', np.nan),\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SPECTRAL SIGNATURE SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Lab averages\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LAB AVERAGES\")\n",
    "    print(\"=\"*80)\n",
    "    lab_avg = df.groupby('Lab')[['W_V Mean', 'W_O Mean']].mean().round(4)\n",
    "    print(lab_avg)\n",
    "    \n",
    "    # Hypothesis test\n",
    "    from scipy import stats\n",
    "    \n",
    "    eleuther_wv = df[df['Lab'] == 'EleutherAI']['W_V Mean'].dropna().values\n",
    "    others_wv = df[df['Lab'] != 'EleutherAI']['W_V Mean'].dropna().values\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"HYPOTHESIS TEST: EleutherAI vs Others\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if len(eleuther_wv) > 0 and len(others_wv) > 0:\n",
    "        print(f\"\\nEleutherAI W_V mean: {np.mean(eleuther_wv):.4f}\")\n",
    "        print(f\"Others W_V mean: {np.mean(others_wv):.4f}\")\n",
    "        \n",
    "        if len(eleuther_wv) >= 2 and len(others_wv) >= 2:\n",
    "            stat, p = stats.mannwhitneyu(eleuther_wv, others_wv, alternative='two-sided')\n",
    "            print(f\"\\nMann-Whitney U: {stat:.2f}, p = {p:.4f}\")\n",
    "            print(f\"Significant difference: {'YES' if p < 0.05 else 'NO'}\")\n",
    "else:\n",
    "    print(\"No data for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "if all_results:\n",
    "    def convert_to_serializable(obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, (np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.int32, np.int64)):\n",
    "            return int(obj)\n",
    "        return obj\n",
    "    \n",
    "    serializable_results = []\n",
    "    for res in all_results:\n",
    "        clean_res = {k: convert_to_serializable(v) for k, v in res.items()}\n",
    "        serializable_results.append(clean_res)\n",
    "    \n",
    "    output = {\n",
    "        'experiment': 'Restriction Map Spectral Analysis v2',\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'hypothesis': 'Different labs have different spectral signatures in restriction maps',\n",
    "        'models_tested': len(all_results),\n",
    "        'results': serializable_results,\n",
    "        'summary': df.to_dict('records') if len(df) > 0 else []\n",
    "    }\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'restriction_map_spectral_{timestamp}.json'\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nResults saved to: {filename}\")\n",
    "    \n",
    "    # Also save summary CSV\n",
    "    df.to_csv(f'restriction_map_summary_{timestamp}.csv', index=False)\n",
    "    print(f\"Summary saved to: restriction_map_summary_{timestamp}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nDownload these files:\")\n",
    "print(\"  - restriction_map_spectral_analysis.png\")\n",
    "print(\"  - restriction_map_spectral_*.json\")\n",
    "print(\"  - restriction_map_summary_*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Download Results (Colab)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Download all result files from Colab\nimport os\nimport glob\n\ntry:\n    from google.colab import files\n    \n    print(\"Downloading results from Colab...\")\n    \n    # Download PNG\n    if os.path.exists('restriction_map_spectral_analysis.png'):\n        files.download('restriction_map_spectral_analysis.png')\n        print(\"  Downloaded: restriction_map_spectral_analysis.png\")\n    \n    # Download JSON files\n    json_files = glob.glob('restriction_map_spectral_*.json')\n    for f in json_files:\n        files.download(f)\n        print(f\"  Downloaded: {f}\")\n    \n    # Download CSV files\n    csv_files = glob.glob('restriction_map_summary_*.csv')\n    for f in csv_files:\n        files.download(f)\n        print(f\"  Downloaded: {f}\")\n    \n    print(\"\\nAll files downloaded!\")\n    \nexcept ImportError:\n    print(\"Not running in Colab - files saved locally:\")\n    print(f\"  - restriction_map_spectral_analysis.png\")\n    for f in glob.glob('restriction_map_*.json'):\n        print(f\"  - {f}\")\n    for f in glob.glob('restriction_map_*.csv'):\n        print(f\"  - {f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
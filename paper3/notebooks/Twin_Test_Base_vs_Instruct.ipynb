{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Twin Test: Base vs Instruct Models\n\n**Paper #3 - Nature vs Nurture Hypothesis**\n\n**Date:** 2026-01-05\n\n**Purpose:** Test whether thermodynamic profiles (Gain) are \"genetic traits\" that persist through fine-tuning (RLHF).\n\n---\n\n## The Hypothesis\n\n```\nNATURE (Architecture) â†’ Determines BASE LEVEL (Gain magnitude)\nNURTURE (RLHF)       â†’ Modulates but does NOT invert\n```\n\n**Prediction:**\n- If Gemma-Base explodes (Gain > 2.0), Gemma-Instruct should also explode\n- If Mistral-Base is neutral (Gain â‰ˆ 1.0), Mistral-Instruct should also be neutral\n- RLHF may AMPLIFY the trait, but not REVERSE it\n\n---\n\n## Twin Pairs to Test\n\n| Family | Base Model | Instruct Model | Expected Base Gain |\n|--------|------------|----------------|--------------------|\n| Mistral | mistralai/Mistral-7B-v0.1 | mistralai/Mistral-7B-Instruct-v0.2 | ~1.11 (Neutral) |\n| Gemma | google/gemma-7b | google/gemma-7b-it | ~2.31 (Explosion) |\n| LLaMA 3.1 | meta-llama/Llama-3.1-8B | meta-llama/Llama-3.1-8B-Instruct | ~1.48 (Expansion) |\n\n---\n\n## Success Criteria\n\n**Nature dominates if:**\n- Base and Instruct have the SAME SIGN relative to 1.0\n- Correlation between Base Gain and Instruct Gain > 0.8\n\n**Nurture dominates if:**\n- RLHF changes the sign (e.g., Base > 1.0 but Instruct < 1.0)\n- Correlation < 0.5",
   "metadata": {
    "id": "header"
   }
  },
  {
   "cell_type": "code",
   "source": "# Cell 1: Setup with ROBUST HF Token Handling\n!pip install -q transformers accelerate scipy seaborn huggingface_hub\n\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom scipy.stats import entropy, pearsonr, spearmanr, ttest_rel\nimport gc\nimport json\nfrom datetime import datetime\nfrom google.colab import files\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================\n# HF TOKEN HANDLING - ROBUST VERSION\n# ============================================================\nHF_TOKEN = None\n\n# Method 1: Try Colab secrets (primary method)\ntry:\n    from google.colab import userdata\n    HF_TOKEN = userdata.get('HF_TOKEN')\n    if HF_TOKEN:\n        print(f\"âœ“ HF_TOKEN loaded from Colab secrets\")\n        print(f\"  Token starts with: {HF_TOKEN[:10]}...\")\nexcept Exception as e:\n    print(f\"  Colab secrets method failed: {e}\")\n\n# Method 2: Try environment variable as fallback\nif not HF_TOKEN:\n    HF_TOKEN = os.environ.get('HF_TOKEN') or os.environ.get('HUGGINGFACE_TOKEN')\n    if HF_TOKEN:\n        print(f\"âœ“ HF_TOKEN loaded from environment variable\")\n\n# Method 3: Explicit login to HuggingFace Hub\nif HF_TOKEN:\n    try:\n        from huggingface_hub import login, whoami\n        login(token=HF_TOKEN, add_to_git_credential=False)\n        user_info = whoami()\n        print(f\"âœ“ Logged in to HuggingFace Hub as: {user_info.get('name', 'unknown')}\")\n    except Exception as e:\n        print(f\"âš ï¸ HF Hub login issue: {e}\")\n        print(\"  Will try to use token directly in model loading...\")\nelse:\n    print(\"=\" * 60)\n    print(\"âš ï¸ WARNING: No HF_TOKEN found!\")\n    print(\"  Gated models (Gemma, LLaMA) will FAIL!\")\n    print(\"  \")\n    print(\"  To fix: Add HF_TOKEN to Colab secrets:\")\n    print(\"  1. Click the ğŸ”‘ icon in the left sidebar\")\n    print(\"  2. Add secret named 'HF_TOKEN' with your token\")\n    print(\"  3. Toggle 'Notebook access' ON\")\n    print(\"=\" * 60)\n\n# ============================================================\n# Configure visualization\nplt.style.use('seaborn-v0_8-paper')\nsns.set_context(\"talk\")\n\n# Global timestamp\nTIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nprint(f\"\\nSession timestamp: {TIMESTAMP}\")\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")",
   "metadata": {
    "id": "setup"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 2: PROMPT SET (Same as Grand Unified Benchmark)\n\nPROMPT_DATASET = {\n    \"Factual\": [\n        \"The capital city of France is\",\n        \"The atomic number of oxygen is\",\n        \"Water boils at a temperature of\",\n        \"The largest planet in our solar system is\",\n        \"The currency used in Japan is\"\n    ],\n    \"Syntactic\": [\n        \"The agreement, which, notwithstanding the fact that it was signed only yesterday, effectively binds all parties immediately, stipulates that\",\n        \"Although the weather was extremely cold, and despite the fact that they had no coats, the children decided to\",\n        \"The professor, having reviewed the complex derivation multiple times without finding the error, finally realized that\",\n        \"To imply that such a fundamental shift in policy could occur without significant public debate is to suggest that\",\n        \"Not only did the experiment fail to yield the expected results, but it also demonstrated that the initial hypothesis was\"\n    ],\n    \"Cliche\": [\n        \"The true meaning of happiness is often found in\",\n        \"Actions speak louder than\",\n        \"It is what it is, and we must simply\",\n        \"Time heals all\",\n        \"Life is a journey, not a\"\n    ],\n    \"Novel\": [\n        \"The epistemological implications of quantum decoherence suggest that the observer is\",\n        \"If consciousness creates reality, then the paradox of the unobserved electron implies\",\n        \"The intersection of baroque architecture and cybernetic theory creates a space where\",\n        \"Calculating the trajectory of a hyperspace jump requires factoring in the variability of\",\n        \"The symbiotic relationship between fungal mycelium and digital neural networks results in\"\n    ],\n    \"Nonsense\": [\n        \"Table sky run blue jump quickly under over\",\n        \"Purple idea furiously sleep colorless green\",\n        \"Clock river dance potato seven fast\",\n        \"Window eat loud tomorrow yellow under\",\n        \"Fish bicycle logic cloud mountain swim\"\n    ]\n}\n\ntotal_prompts = sum(len(v) for v in PROMPT_DATASET.values())\nprint(f\"Total prompts: {total_prompts} (5 categories x 5 prompts)\")",
   "metadata": {
    "id": "prompts"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 3: TWIN PAIRS CONFIGURATION\n\nTWIN_PAIRS = {\n    \"Mistral-7B\": {\n        \"base\": {\n            \"hf_path\": \"mistralai/Mistral-7B-v0.1\",\n            \"name\": \"Mistral-7B-Base\",\n            \"type\": \"base\"\n        },\n        \"instruct\": {\n            \"hf_path\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n            \"name\": \"Mistral-7B-Instruct\",\n            \"type\": \"instruct\"\n        },\n        \"expected_base_gain\": 1.11,\n        \"norm_type\": \"RMSNorm\"\n    },\n    \"Gemma-7B\": {\n        \"base\": {\n            \"hf_path\": \"google/gemma-7b\",\n            \"name\": \"Gemma-7B-Base\",\n            \"type\": \"base\"\n        },\n        \"instruct\": {\n            \"hf_path\": \"google/gemma-7b-it\",\n            \"name\": \"Gemma-7B-IT\",\n            \"type\": \"instruct\"\n        },\n        \"expected_base_gain\": 2.31,\n        \"norm_type\": \"RMSNorm\"\n    },\n    \"LLaMA-3.1-8B\": {\n        \"base\": {\n            \"hf_path\": \"meta-llama/Llama-3.1-8B\",\n            \"name\": \"LLaMA-3.1-8B-Base\",\n            \"type\": \"base\"\n        },\n        \"instruct\": {\n            \"hf_path\": \"meta-llama/Llama-3.1-8B-Instruct\",\n            \"name\": \"LLaMA-3.1-8B-Instruct\",\n            \"type\": \"instruct\"\n        },\n        \"expected_base_gain\": 1.48,\n        \"norm_type\": \"RMSNorm\"\n    }\n}\n\n# Reference from Grand Unified Benchmark\nREFERENCE_GAINS = {\n    \"Pythia-6.9B\": 0.80,\n    \"GPT-J-6B\": 1.065,\n    \"GPT2-XL\": 1.02,\n    \"Mistral-7B\": 1.11,\n    \"LLaMA-3.1-8B\": 1.48,\n    \"Gemma-7B\": 2.31\n}\n\nprint(\"Twin Pairs to test:\")\nfor family, pair in TWIN_PAIRS.items():\n    print(f\"\\n{family}:\")\n    print(f\"  Base:     {pair['base']['hf_path']}\")\n    print(f\"  Instruct: {pair['instruct']['hf_path']}\")\n    print(f\"  Expected Base Gain: {pair['expected_base_gain']}\")",
   "metadata": {
    "id": "twins"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 4: MEASUREMENT ENGINE\n\ndef get_layer_list(model):\n    \"\"\"Get the transformer layers from different model architectures.\"\"\"\n    # LLaMA/Mistral/Gemma style\n    if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n        return model.model.layers\n    # GPT-2/GPT-J style\n    elif hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n        return model.transformer.h\n    # Pythia style\n    elif hasattr(model, 'gpt_neox') and hasattr(model.gpt_neox, 'layers'):\n        return model.gpt_neox.layers\n    else:\n        raise ValueError(f\"Unknown model architecture: {type(model)}\")\n\ndef measure_thermodynamics(model, tokenizer, text, device='cuda'):\n    \"\"\"Measure residual stream gain and output entropy.\"\"\"\n    \n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n    \n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    \n    norms = []\n    \n    def get_norm_hook():\n        def hook(module, input, output):\n            if isinstance(output, tuple):\n                hidden_state = output[0]\n            else:\n                hidden_state = output\n            \n            if hasattr(hidden_state, 'last_hidden_state'):\n                hidden_state = hidden_state.last_hidden_state\n            \n            try:\n                last_token_norm = float(torch.norm(hidden_state[0, -1]).cpu().item())\n                norms.append(last_token_norm)\n            except Exception as e:\n                print(f\"Warning: Could not compute norm: {e}\")\n        return hook\n    \n    handles = []\n    try:\n        layers = get_layer_list(model)\n        for layer in layers:\n            handles.append(layer.register_forward_hook(get_norm_hook()))\n    except Exception as e:\n        print(f\"Warning: Could not register hooks: {e}\")\n        return None\n    \n    try:\n        with torch.no_grad():\n            outputs = model(**inputs)\n            logits = outputs.logits\n    except Exception as e:\n        print(f\"Error in forward pass: {e}\")\n        for h in handles:\n            h.remove()\n        return None\n    \n    for h in handles:\n        h.remove()\n    \n    if len(norms) >= 2:\n        last_gain = float(norms[-1] / norms[-2]) if norms[-2] > 0 else 1.0\n        total_amp = float(norms[-1] / norms[0]) if norms[0] > 0 else 1.0\n    else:\n        last_gain = 1.0\n        total_amp = 1.0\n    \n    last_token_logits = logits[0, -1, :].float()\n    probs = torch.softmax(last_token_logits, dim=0).cpu().numpy().astype(np.float64)\n    probs = np.clip(probs, 1e-10, 1.0)\n    probs = probs / probs.sum()\n    ent = float(entropy(probs))\n    \n    top_idx = int(torch.argmax(last_token_logits).item())\n    top_prob = float(probs[top_idx])\n    top_token = tokenizer.decode([top_idx])\n    \n    return {\n        \"last_gain\": float(last_gain),\n        \"total_amp\": float(total_amp),\n        \"entropy\": float(ent),\n        \"top_token\": str(top_token),\n        \"top_prob\": float(top_prob),\n        \"n_layers\": int(len(norms))\n    }\n\nprint(\"Measurement engine ready.\")",
   "metadata": {
    "id": "engine"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 5: RUN TWIN TEST\n\nall_results = []\ntwin_summary = {}\n\nprint(\"=\"*70)\nprint(\"TWIN TEST: BASE vs INSTRUCT\")\nprint(\"Testing Nature vs Nurture Hypothesis\")\nprint(\"=\"*70 + \"\\n\")\n\nfor family_name, pair_config in TWIN_PAIRS.items():\n    print(f\"\\n{'='*60}\")\n    print(f\"FAMILY: {family_name}\")\n    print(f\"{'='*60}\")\n    \n    family_results = {}\n    \n    for variant in [\"base\", \"instruct\"]:\n        model_config = pair_config[variant]\n        hf_path = model_config[\"hf_path\"]\n        model_name = model_config[\"name\"]\n        \n        print(f\"\\n  Loading {model_name}...\")\n        print(f\"    Path: {hf_path}\")\n        \n        try:\n            # Load tokenizer\n            tokenizer = AutoTokenizer.from_pretrained(\n                hf_path,\n                token=HF_TOKEN if HF_TOKEN else None\n            )\n            if tokenizer.pad_token is None:\n                tokenizer.pad_token = tokenizer.eos_token\n            \n            # Load model\n            model = AutoModelForCausalLM.from_pretrained(\n                hf_path,\n                torch_dtype=torch.bfloat16,\n                device_map=\"auto\",\n                token=HF_TOKEN if HF_TOKEN else None,\n                low_cpu_mem_usage=True\n            )\n            model.eval()\n            \n            print(f\"    Model loaded. Testing {total_prompts} prompts...\")\n            \n            model_results = []\n            \n            for category, prompts in PROMPT_DATASET.items():\n                print(f\"      {category}: \", end=\"\")\n                for prompt in prompts:\n                    res = measure_thermodynamics(model, tokenizer, prompt)\n                    \n                    if res is not None:\n                        result_entry = {\n                            \"Family\": str(family_name),\n                            \"Model\": str(model_name),\n                            \"Variant\": str(variant),\n                            \"Norm_Type\": str(pair_config[\"norm_type\"]),\n                            \"Category\": str(category),\n                            \"Prompt\": str(prompt),\n                            \"Entropy\": float(res[\"entropy\"]),\n                            \"Last_Gain\": float(res[\"last_gain\"]),\n                            \"Total_Amp\": float(res[\"total_amp\"]),\n                            \"Top_Token\": str(res[\"top_token\"]),\n                            \"Top_Prob\": float(res[\"top_prob\"])\n                        }\n                        all_results.append(result_entry)\n                        model_results.append(res[\"last_gain\"])\n                        print(\".\", end=\"\", flush=True)\n                    else:\n                        print(\"X\", end=\"\", flush=True)\n                print(\" Done\")\n            \n            # Calculate statistics\n            mean_gain = float(np.mean(model_results))\n            std_gain = float(np.std(model_results))\n            \n            family_results[variant] = {\n                \"mean_gain\": mean_gain,\n                \"std_gain\": std_gain,\n                \"n_samples\": len(model_results)\n            }\n            \n            print(f\"\\n    {model_name}: Mean Gain = {mean_gain:.4f} Â± {std_gain:.4f}\")\n            \n            # Cleanup\n            del model\n            del tokenizer\n            torch.cuda.empty_cache()\n            gc.collect()\n            \n        except Exception as e:\n            print(f\"\\n    FAILED: {e}\")\n            import traceback\n            traceback.print_exc()\n            family_results[variant] = None\n    \n    # Store twin summary\n    twin_summary[family_name] = family_results\n    \n    # Compare twins\n    if family_results.get(\"base\") and family_results.get(\"instruct\"):\n        base_gain = family_results[\"base\"][\"mean_gain\"]\n        instruct_gain = family_results[\"instruct\"][\"mean_gain\"]\n        \n        print(f\"\\n  TWIN COMPARISON ({family_name}):\")\n        print(f\"    Base:     {base_gain:.4f}\")\n        print(f\"    Instruct: {instruct_gain:.4f}\")\n        print(f\"    Delta:    {instruct_gain - base_gain:+.4f}\")\n        print(f\"    Ratio:    {instruct_gain / base_gain:.3f}x\")\n        \n        # Same sign test\n        base_sign = \"EXPANSION\" if base_gain > 1.0 else \"DAMPENING\" if base_gain < 1.0 else \"NEUTRAL\"\n        inst_sign = \"EXPANSION\" if instruct_gain > 1.0 else \"DAMPENING\" if instruct_gain < 1.0 else \"NEUTRAL\"\n        \n        if base_sign == inst_sign:\n            print(f\"    Sign:     SAME ({base_sign}) âœ“\")\n        else:\n            print(f\"    Sign:     DIFFERENT! Base={base_sign}, Instruct={inst_sign} âœ—\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"TWIN TEST COMPLETE\")\nprint(f\"Total measurements: {len(all_results)}\")\nprint(\"=\"*70)",
   "metadata": {
    "id": "execution"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 6: CREATE DATAFRAME & ANALYZE\n\ndf = pd.DataFrame(all_results)\n\n# Define filenames\nCSV_FILE = f\"twin_test_results_{TIMESTAMP}.csv\"\nJSON_FILE = f\"twin_test_results_{TIMESTAMP}.json\"\nPNG_MAIN = f\"twin_test_results_{TIMESTAMP}.png\"\nPNG_SCATTER = f\"twin_test_scatter_{TIMESTAMP}.png\"\n\n# Save raw data\ndf.to_csv(CSV_FILE, index=False)\nprint(f\"Saved: {CSV_FILE}\")\n\n# Summary statistics\nprint(\"\\n\" + \"=\"*70)\nprint(\"TWIN TEST RESULTS SUMMARY\")\nprint(\"=\"*70)\n\nprint(\"\\nMean Gain per Model:\")\nsummary = df.groupby(['Family', 'Model', 'Variant'])['Last_Gain'].agg(['mean', 'std', 'count'])\nprint(summary.round(4))\n\nprint(\"\\nMean Gain per Category (aggregated):\")\nprint(df.groupby(['Variant', 'Category'])['Last_Gain'].mean().unstack().round(4))",
   "metadata": {
    "id": "analysis"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 7: NATURE VS NURTURE STATISTICAL TEST\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"NATURE VS NURTURE HYPOTHESIS TEST\")\nprint(\"=\"*70)\n\nhypothesis_results = []\n\nfor family_name in TWIN_PAIRS.keys():\n    if family_name not in twin_summary:\n        continue\n    \n    base_data = twin_summary[family_name].get(\"base\")\n    inst_data = twin_summary[family_name].get(\"instruct\")\n    \n    if not base_data or not inst_data:\n        continue\n    \n    base_gain = base_data[\"mean_gain\"]\n    inst_gain = inst_data[\"mean_gain\"]\n    \n    # Same sign test\n    base_sign = 1 if base_gain > 1.0 else -1 if base_gain < 1.0 else 0\n    inst_sign = 1 if inst_gain > 1.0 else -1 if inst_gain < 1.0 else 0\n    same_sign = base_sign == inst_sign\n    \n    # Calculate metrics\n    delta = inst_gain - base_gain\n    ratio = inst_gain / base_gain if base_gain != 0 else 1.0\n    \n    # RLHF effect direction\n    if delta > 0.05:\n        rlhf_effect = \"AMPLIFIES\"\n    elif delta < -0.05:\n        rlhf_effect = \"DAMPENS\"\n    else:\n        rlhf_effect = \"NEUTRAL\"\n    \n    hypothesis_results.append({\n        \"Family\": family_name,\n        \"Base_Gain\": base_gain,\n        \"Instruct_Gain\": inst_gain,\n        \"Delta\": delta,\n        \"Ratio\": ratio,\n        \"Same_Sign\": same_sign,\n        \"RLHF_Effect\": rlhf_effect\n    })\n    \n    print(f\"\\n{family_name}:\")\n    print(f\"  Base:     {base_gain:.4f} ({'>' if base_gain > 1 else '<'} 1.0)\")\n    print(f\"  Instruct: {inst_gain:.4f} ({'>' if inst_gain > 1 else '<'} 1.0)\")\n    print(f\"  Delta:    {delta:+.4f}\")\n    print(f\"  Ratio:    {ratio:.3f}x\")\n    print(f\"  Same Sign: {'âœ“ YES' if same_sign else 'âœ— NO'}\")\n    print(f\"  RLHF Effect: {rlhf_effect}\")\n\n# Overall verdict\nprint(\"\\n\" + \"=\"*70)\nprint(\"OVERALL VERDICT\")\nprint(\"=\"*70)\n\nall_same_sign = all(r[\"Same_Sign\"] for r in hypothesis_results)\nn_pairs = len(hypothesis_results)\n\nif all_same_sign:\n    print(f\"\\n  NATURE DOMINATES: {n_pairs}/{n_pairs} pairs have SAME SIGN\")\n    print(\"  â†’ Thermodynamic profile is an architectural 'genetic trait'\")\n    print(\"  â†’ RLHF modulates magnitude but does NOT invert sign\")\n    verdict = \"NATURE_DOMINATES\"\nelse:\n    n_same = sum(1 for r in hypothesis_results if r[\"Same_Sign\"])\n    print(f\"\\n  MIXED RESULT: {n_same}/{n_pairs} pairs have same sign\")\n    if n_same >= n_pairs * 0.5:\n        print(\"  â†’ Nature partially dominates\")\n        verdict = \"NATURE_PARTIAL\"\n    else:\n        print(\"  â†’ Nurture can override nature\")\n        verdict = \"NURTURE_DOMINATES\"\n\nprint(f\"\\n  Verdict: {verdict}\")",
   "metadata": {
    "id": "hypothesis_test"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 8: VISUALIZATION - Twin Comparison\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 14))\n\n# A. Bar chart: Base vs Instruct per Family\nax1 = axes[0, 0]\n\nfamilies = list(TWIN_PAIRS.keys())\nx = np.arange(len(families))\nwidth = 0.35\n\nbase_gains = [twin_summary[f][\"base\"][\"mean_gain\"] if twin_summary.get(f, {}).get(\"base\") else 0 for f in families]\ninst_gains = [twin_summary[f][\"instruct\"][\"mean_gain\"] if twin_summary.get(f, {}).get(\"instruct\") else 0 for f in families]\n\nbars1 = ax1.bar(x - width/2, base_gains, width, label='Base', color='#1f77b4', alpha=0.8)\nbars2 = ax1.bar(x + width/2, inst_gains, width, label='Instruct', color='#ff7f0e', alpha=0.8)\n\nax1.axhline(1.0, ls='--', c='red', lw=2, alpha=0.7, label='Neutral (1.0)')\nax1.set_ylabel('Mean Last Layer Gain')\nax1.set_xlabel('Model Family')\nax1.set_title('A. Twin Test: Base vs Instruct')\nax1.set_xticks(x)\nax1.set_xticklabels(families)\nax1.legend()\nax1.grid(True, alpha=0.3, axis='y')\n\n# Add value labels\nfor bar in bars1:\n    height = bar.get_height()\n    ax1.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width()/2, height),\n                 xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=10)\nfor bar in bars2:\n    height = bar.get_height()\n    ax1.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width()/2, height),\n                 xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=10)\n\n# B. Scatter: Base vs Instruct Gain\nax2 = axes[0, 1]\n\nif len(base_gains) > 0 and len(inst_gains) > 0:\n    ax2.scatter(base_gains, inst_gains, s=200, c=['#2ca02c', '#d62728', '#9467bd'][:len(families)], \n                edgecolors='black', linewidths=2, zorder=5)\n    \n    # Add family labels\n    for i, family in enumerate(families):\n        ax2.annotate(family, (base_gains[i], inst_gains[i]), \n                     xytext=(10, 10), textcoords='offset points', fontsize=11)\n    \n    # Identity line (Nature = Nurture)\n    min_val = min(min(base_gains), min(inst_gains)) * 0.9\n    max_val = max(max(base_gains), max(inst_gains)) * 1.1\n    ax2.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Identity (Nature=Nurture)')\n    \n    # Neutral lines\n    ax2.axhline(1.0, ls=':', c='red', alpha=0.3)\n    ax2.axvline(1.0, ls=':', c='red', alpha=0.3)\n    \n    ax2.set_xlabel('Base Model Gain')\n    ax2.set_ylabel('Instruct Model Gain')\n    ax2.set_title('B. Base vs Instruct Correlation')\n    ax2.legend(loc='lower right')\n    ax2.grid(True, alpha=0.3)\n\n# C. Box plot: Gain distribution by Variant\nax3 = axes[1, 0]\nif len(df) > 0:\n    sns.boxplot(data=df, x='Family', y='Last_Gain', hue='Variant', ax=ax3)\n    ax3.axhline(1.0, ls='--', c='red', alpha=0.5)\n    ax3.set_xlabel('Model Family')\n    ax3.set_ylabel('Last Layer Gain')\n    ax3.set_title('C. Gain Distribution by Family and Variant')\n    ax3.legend(loc='upper right')\n\n# D. Complete hierarchy with twins\nax4 = axes[1, 1]\n\n# Collect all models\nall_models = []\nfor family, results in twin_summary.items():\n    if results.get(\"base\"):\n        all_models.append((f\"{family}\\n(Base)\", results[\"base\"][\"mean_gain\"], \"base\"))\n    if results.get(\"instruct\"):\n        all_models.append((f\"{family}\\n(Instruct)\", results[\"instruct\"][\"mean_gain\"], \"instruct\"))\n\n# Add reference models\nfor name, gain in REFERENCE_GAINS.items():\n    if \"Mistral\" not in name and \"LLaMA\" not in name and \"Gemma\" not in name:\n        all_models.append((name, gain, \"reference\"))\n\n# Sort by gain\nall_models_sorted = sorted(all_models, key=lambda x: x[1])\n\nnames = [m[0] for m in all_models_sorted]\ngains = [m[1] for m in all_models_sorted]\ncolors = []\nfor m in all_models_sorted:\n    if m[2] == \"base\":\n        colors.append('#1f77b4')\n    elif m[2] == \"instruct\":\n        colors.append('#ff7f0e')\n    else:\n        colors.append('#7f7f7f')\n\nbars = ax4.barh(range(len(names)), gains, color=colors, alpha=0.8)\nax4.axvline(1.0, ls='--', c='red', lw=2, alpha=0.7)\nax4.set_yticks(range(len(names)))\nax4.set_yticklabels(names, fontsize=9)\nax4.set_xlabel('Mean Last Layer Gain')\nax4.set_title('D. Complete Hierarchy\\n(Blue=Base, Orange=Instruct, Gray=Reference)')\nax4.grid(True, alpha=0.3, axis='x')\n\n# Value labels\nfor bar, val in zip(bars, gains):\n    ax4.text(val + 0.02, bar.get_y() + bar.get_height()/2, \n             f'{val:.2f}', ha='left', va='center', fontsize=9)\n\nplt.tight_layout()\nplt.savefig(PNG_MAIN, dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"\\nFigure saved: {PNG_MAIN}\")",
   "metadata": {
    "id": "visualization"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 9: SAVE COMPREHENSIVE JSON\n\ndef make_serializable(obj):\n    if isinstance(obj, (np.integer, np.floating)):\n        return float(obj)\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    elif isinstance(obj, np.bool_):\n        return bool(obj)\n    elif isinstance(obj, dict):\n        return {k: make_serializable(v) for k, v in obj.items()}\n    elif isinstance(obj, list):\n        return [make_serializable(v) for v in obj]\n    return obj\n\nresults_json = {\n    \"experiment\": \"Twin Test: Base vs Instruct\",\n    \"purpose\": \"Test Nature vs Nurture hypothesis - is thermodynamic profile genetic?\",\n    \"date\": TIMESTAMP,\n    \"n_families\": len(TWIN_PAIRS),\n    \"n_prompts_per_model\": total_prompts,\n    \"n_total_measurements\": len(df),\n    \n    \"twin_pairs_tested\": list(TWIN_PAIRS.keys()),\n    \n    \"twin_summary\": make_serializable(twin_summary),\n    \n    \"hypothesis_results\": make_serializable(hypothesis_results),\n    \n    \"verdict\": verdict,\n    \n    \"interpretation\": {\n        \"NATURE_DOMINATES\": \"Thermodynamic profile (Gain) is an architectural invariant that persists through fine-tuning\",\n        \"NATURE_PARTIAL\": \"Architecture sets a strong prior, but RLHF can modulate significantly\",\n        \"NURTURE_DOMINATES\": \"RLHF can fundamentally change the thermodynamic profile\"\n    }[verdict],\n    \n    \"reference_gains\": REFERENCE_GAINS,\n    \n    \"all_results\": make_serializable(all_results)\n}\n\nwith open(JSON_FILE, 'w') as f:\n    json.dump(results_json, f, indent=2, default=str)\n\nprint(f\"Results saved to {JSON_FILE}\")",
   "metadata": {
    "id": "save_json"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 10: FINAL VERDICT\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"TWIN TEST: FINAL VERDICT\")\nprint(\"=\"*70)\n\nprint(f\"\"\"\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    TWIN TEST: NATURE vs NURTURE                              â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                              â”‚\nâ”‚   Hypothesis: \"Thermodynamic profile is a genetic trait\"                    â”‚\nâ”‚                                                                              â”‚\nâ”‚   If TRUE:  Base and Instruct should have SAME SIGN relative to 1.0         â”‚\nâ”‚   If FALSE: RLHF can INVERT the thermodynamic behavior                       â”‚\nâ”‚                                                                              â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                              â”‚\nâ”‚   RESULTS:                                                                   â”‚\nâ”‚                                                                              â”‚\n\"\"\")\n\nfor r in hypothesis_results:\n    sign_str = \"âœ“\" if r[\"Same_Sign\"] else \"âœ—\"\n    print(f\"â”‚   {r['Family']:15} Base={r['Base_Gain']:.2f}  Instruct={r['Instruct_Gain']:.2f}  {sign_str}       â”‚\")\n\nprint(f\"\"\"\nâ”‚                                                                              â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                              â”‚\nâ”‚   VERDICT: {verdict:20}                                       â”‚\nâ”‚                                                                              â”‚\nâ”‚   Interpretation:                                                            â”‚\nâ”‚   {results_json['interpretation'][:70]:70} â”‚\nâ”‚                                                                              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\"\"\")\n\nif verdict == \"NATURE_DOMINATES\":\n    print(\"\\n  IMPLICATION FOR PAPER #3:\")\n    print(\"  â†’ Thermodynamic profiles ARE genetic traits\")\n    print(\"  â†’ RLHF fine-tuning modulates but does NOT override\")\n    print(\"  â†’ The Pythia anomaly is ARCHITECTURAL, not training-related\")\n    print(\"  â†’ We can claim: 'Gain is determined by architecture, not alignment'\")",
   "metadata": {
    "id": "verdict"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 11: DOWNLOAD ALL RESULTS\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DOWNLOADING RESULTS\")\nprint(\"=\"*70)\n\nfiles_to_download = [CSV_FILE, JSON_FILE, PNG_MAIN]\n\nprint(\"\\nFiles to download:\")\nfor f in files_to_download:\n    if os.path.exists(f):\n        size = os.path.getsize(f) / 1024\n        print(f\"  {f} ({size:.1f} KB)\")\n    else:\n        print(f\"  {f} (NOT FOUND)\")\n\nprint(\"\\nStarting downloads...\")\n\nfor f in files_to_download:\n    if os.path.exists(f):\n        try:\n            files.download(f)\n            print(f\"  Downloaded: {f}\")\n        except Exception as e:\n            print(f\"  FAILED: {f}: {e}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"TWIN TEST COMPLETE\")\nprint(\"=\"*70)\nprint(\"\\nNext steps:\")\nprint(\"  1. If NATURE_DOMINATES: Pythia anomaly is architectural mystery\")\nprint(\"  2. Add Twin Test results to Paper #3\")\nprint(\"  3. Formulate: 'Thermodynamic profiles are genetic traits'\")",
   "metadata": {
    "id": "download"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
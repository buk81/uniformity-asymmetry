{
  "experiment": "LLaMA 2 vs LLaMA 3.1 - Long-Context Hypothesis Test",
  "date": "2026-01-05",
  "hypothesis": "Long-context models require dampening (contraction) for numerical stability",
  "models": {
    "llama2-7b": {
      "model": "llama2-7b",
      "hf_name": "meta-llama/Llama-2-7b-hf",
      "num_layers": 32,
      "residual": {
        "norms": [
          0.8342146277427673,
          2.572565793991089,
          299.2936096191406,
          300.9410705566406,
          302.0577087402344,
          305.0940246582031,
          306.48333740234375,
          307.8753356933594,
          309.0143127441406,
          310.34033203125,
          311.8052673339844,
          313.47491455078125,
          314.201171875,
          315.7373046875,
          317.3487243652344,
          319.85772705078125,
          323.162353515625,
          326.64508056640625,
          329.4653015136719,
          332.97222900390625,
          337.8805236816406,
          342.361083984375,
          346.87359619140625,
          351.8294982910156,
          355.1611328125,
          359.95977783203125,
          363.32611083984375,
          368.6872253417969,
          372.7328796386719,
          378.7878112792969,
          381.1778259277344,
          128.1094207763672,
          118.18384552001953
        ],
        "gains": [
          3.08381765128236,
          116.34050733249288,
          1.0055044975387093,
          1.003710487842448,
          1.0100521053762608,
          1.0045537199415724,
          1.0045418400321982,
          1.0036994748157275,
          1.0042911257906921,
          1.0047204154650027,
          1.0053547755336938,
          1.002316795668513,
          1.0048890104493662,
          1.0051036721154292,
          1.007906137611126,
          1.0103315511409205,
          1.0107770197019958,
          1.00863389995764,
          1.0106442999433396,
          1.0147408529907063,
          1.0132607829948674,
          1.0131805640831457,
          1.0142873431533102,
          1.0094694576141783,
          1.013511177255042,
          1.0093519699008797,
          1.0147556543336802,
          1.0109731339162198,
          1.0162446941801717,
          1.0063096397963958,
          0.3360883347937842,
          0.9225226747869376
        ],
        "embedding_norm": 0.8342146277427673,
        "final_norm": 118.18384552001953,
        "initial_gain": 3.08381765128236,
        "last_gain": 0.9225226747869376,
        "last_expands": false,
        "cumulative_energy": 141.67079021354903,
        "num_layers": 32,
        "contracting_layers": 2,
        "expanding_layers": 30
      },
      "w_u": {
        "shape": [
          32000,
          4096
        ],
        "vocab_size": 32000,
        "hidden_dim": 4096,
        "frobenius_norm": 197.87191772460938,
        "spectral_norm": 44.400177001953125,
        "mean_row_norm": 1.0958846807479858
      },
      "rope": {
        "rope_theta": 10000.0,
        "rope_scaling": null,
        "max_position": 4096
      }
    },
    "llama3.1-8b": {
      "model": "llama3.1-8b",
      "hf_name": "meta-llama/Llama-3.1-8B",
      "num_layers": 32,
      "residual": {
        "norms": [
          0.5586393475532532,
          2.2254865169525146,
          46.4610710144043,
          47.02727127075195,
          47.843406677246094,
          48.56107711791992,
          49.29155349731445,
          50.10919952392578,
          50.67298126220703,
          51.27826690673828,
          51.89731216430664,
          52.43351364135742,
          52.574249267578125,
          53.10568618774414,
          53.49204635620117,
          54.09923553466797,
          55.01980972290039,
          56.212276458740234,
          57.489585876464844,
          59.10654830932617,
          61.22098159790039,
          62.65043640136719,
          64.36524963378906,
          65.82598876953125,
          67.36248779296875,
          69.16934967041016,
          71.14901733398438,
          73.76588439941406,
          76.34745025634766,
          79.88191223144531,
          84.8061752319336,
          89.9202651977539,
          137.86570739746094
        ],
        "gains": [
          3.9837625593323724,
          20.8768153212746,
          1.0121865519667448,
          1.0173545133374924,
          1.0150004042461958,
          1.0150424253897978,
          1.0165879540935117,
          1.011251062552138,
          1.011944938494919,
          1.0120722733998448,
          1.0103319700903424,
          1.0026840777290518,
          1.0101083121027796,
          1.007275306962255,
          1.011351017951782,
          1.017016399199255,
          1.0216734071209177,
          1.0227229619256242,
          1.028126179867357,
          1.0357732493108651,
          1.0233490997066244,
          1.0273711298902373,
          1.0226945307297521,
          1.0233418297568924,
          1.0268229683409942,
          1.0286205909554922,
          1.036780087251883,
          1.0349967451478708,
          1.0462944337136366,
          1.061644280450135,
          1.0603032733386921,
          1.5331995195328298
        ],
        "embedding_norm": 0.5586393475532532,
        "final_norm": 137.86570739746094,
        "initial_gain": 3.9837625593323724,
        "last_gain": 1.5331995195328298,
        "last_expands": true,
        "cumulative_energy": 246.78839398135784,
        "num_layers": 32,
        "contracting_layers": 0,
        "expanding_layers": 32
      },
      "w_u": {
        "shape": [
          128256,
          4096
        ],
        "vocab_size": 128256,
        "hidden_dim": 4096,
        "frobenius_norm": 331.49127197265625,
        "spectral_norm": 94.60694885253906,
        "mean_row_norm": 0.916771411895752
      },
      "rope": {
        "rope_theta": 500000.0,
        "rope_scaling": {
          "factor": 8.0,
          "low_freq_factor": 1.0,
          "high_freq_factor": 4.0,
          "original_max_position_embeddings": 8192,
          "rope_type": "llama3"
        },
        "max_position": 131072
      }
    }
  },
  "hypothesis_test": {
    "llama2_expands": false,
    "llama31_expands": true,
    "theta_ratio": 50.0,
    "gain_ratio": 1.6619640486201945,
    "wu_ratio": 2.1307786419044543,
    "verdict": "INVERTED"
  },
  "references": {
    "llama3.1-8b": {
      "last_gain": 0.48,
      "w_u_spectral": 94.61,
      "rope_theta": 500000,
      "behavior": "CONTRACTS"
    },
    "mistral-7b": {
      "last_gain": 1.37,
      "w_u_spectral": 16.14,
      "rope_theta": 10000,
      "behavior": "EXPANDS"
    }
  }
}
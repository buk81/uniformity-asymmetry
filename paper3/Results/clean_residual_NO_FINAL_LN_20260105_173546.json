{
  "experiment": "Clean Residual Gain - NO FINAL LAYERNORM",
  "date": "2026-01-05T17:35:46.289979",
  "prompts": [
    "The capital of France is",
    "Water freezes at",
    "The quick brown fox"
  ],
  "precision": "float32",
  "methodology": {
    "wrong_metric": "hidden_states[-1] / hidden_states[-2] (includes final LN)",
    "correct_metric": "hidden_states[-2] / hidden_states[-3] (true last layer gain)"
  },
  "h25_verdict": "VALIDATED",
  "h25_accuracy": 100.0,
  "results": {
    "pythia-6.9b": {
      "gain_with_ln_mean": 0.31992625084363047,
      "gain_with_ln_std": 0.061995952001355825,
      "gain_no_ln_mean": 0.9866687545017112,
      "gain_no_ln_std": 0.014788709087850925,
      "all_layer_gains": [
        56.853030849241584,
        1.1358361235559025,
        1.1135580767791147,
        0.9647316342421973,
        1.11030945717381,
        1.062278086552052,
        1.0377805064177437,
        1.059920956786312,
        1.067895039498297,
        1.103076733111582,
        1.1173022499785985,
        1.0053541232484628,
        1.1008971837405257,
        1.1233442452709805,
        1.0631769053120237,
        1.146928426518542,
        1.1639595613347364,
        1.092727883252208,
        1.0728054406146275,
        1.1154389651774153,
        1.074473323973449,
        1.0412824726401642,
        1.0308951237105446,
        1.0161706750219561,
        1.0151349463676487,
        0.9984051709213434,
        0.9928210714382969,
        1.001717411779369,
        0.9922072289206887,
        0.9865848298995211,
        0.9866687545017112,
        0.31992625084363047
      ],
      "is_dampening_with_ln": true,
      "is_dampening_no_ln": true,
      "n_hidden_states": 33,
      "model": "pythia-6.9b",
      "path": "EleutherAI/pythia-6.9b",
      "n_heads": 32,
      "d_model": 4096,
      "d_head": 128,
      "n_layers": 32,
      "rho": 0.25
    },
    "gpt-j-6b": {
      "gain_with_ln_mean": 0.3726684662728539,
      "gain_with_ln_std": 0.10143459573948696,
      "gain_no_ln_mean": 1.1328371992519364,
      "gain_no_ln_std": 0.01243626780624469,
      "all_layer_gains": [
        21.739590245171097,
        1.0064247789940415,
        0.9649291599460321,
        1.0946417949503757,
        1.1035751608693158,
        1.0748623531808355,
        1.105594192661923,
        1.0613182005825268,
        1.0988839751829376,
        1.1216229678070118,
        1.0924272800185084,
        1.0053351519616693,
        1.05559243067159,
        1.0685508565369866,
        1.0567033122424656,
        1.04499313277031,
        1.0927016743947118,
        1.071182016566684,
        1.054227034425838,
        1.1038750566481255,
        1.075696153016099,
        1.0510876915705014,
        1.0492557897008628,
        1.0483498973693937,
        1.0607885371586028,
        1.0742010928163233,
        1.1328371992519364,
        0.3726684662728539
      ],
      "is_dampening_with_ln": true,
      "is_dampening_no_ln": false,
      "n_hidden_states": 29,
      "model": "gpt-j-6b",
      "path": "EleutherAI/gpt-j-6B",
      "n_heads": 16,
      "d_model": 4096,
      "d_head": 256,
      "n_layers": 28,
      "rho": 0.0625
    }
  }
}
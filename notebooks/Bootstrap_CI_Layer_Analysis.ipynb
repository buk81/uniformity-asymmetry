{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {"id": "header"},
      "source": [
        "# Bootstrap CI for Layer-wise Correlations\n",
        "\n",
        "**Research Question:**\n",
        "> Ist das Mid-Layer-Regime statistisch stabil oder nur ein Trend?\n",
        "\n",
        "**Method:** Bootstrap resampling of category-level data to compute 95% CI for r(UA, Output) per layer.\n",
        "\n",
        "**Key Test:** Does the CI for mid-layers (Layer 8-12) exclude 0?\n",
        "- If CI excludes 0 → Statistically distinguishable from no correlation\n",
        "- If CI includes 0 → Could be noise\n",
        "\n",
        "**Note:** With n=6 categories, CIs will be wide. This is expected and honest.\n",
        "\n",
        "---\n",
        "\n",
        "**Author:** Davide D'Elia  \n",
        "**Date:** 2026-01-03  \n",
        "**Model:** Pythia-6.9B (strongest mid-layer effect)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "setup-header"},
      "source": ["## 1. Setup"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "install"},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q transformers accelerate torch numpy scipy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "imports"},
      "outputs": [],
      "source": [
        "import json\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "N_BOOTSTRAP = 10000  # Number of bootstrap iterations\n",
        "CI_LEVEL = 0.95\n",
        "\n",
        "print(f\"Bootstrap iterations: {N_BOOTSTRAP}\")\n",
        "print(f\"Confidence level: {CI_LEVEL*100}%\")\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "load-model"},
      "outputs": [],
      "source": [
        "# Model configuration - using 6.9B (strongest effect)\n",
        "MODEL_NAME = \"EleutherAI/pythia-6.9b\"\n",
        "MODEL_DISPLAY = \"Pythia-6.9B\"\n",
        "\n",
        "print(f\"Loading {MODEL_DISPLAY}...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    output_hidden_states=True\n",
        ")\n",
        "\n",
        "print(f\"Model loaded. Layers: {model.config.num_hidden_layers}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "load-dataset"},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "!wget -q https://raw.githubusercontent.com/buk81/uniformity-asymmetry/main/dataset.json\n",
        "\n",
        "with open('dataset.json', 'r') as f:\n",
        "    DATASET = json.load(f)\n",
        "\n",
        "CATEGORIES = list(DATASET.keys())\n",
        "print(f\"Categories (n={len(CATEGORIES)}): {CATEGORIES}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "functions-header"},
      "source": ["## 2. Core Functions"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "core-functions"},
      "outputs": [],
      "source": [
        "def get_layer_embeddings(text: str, model, tokenizer, layer_step: int = 4) -> Dict[str, np.ndarray]:\n",
        "    \"\"\"Extract embeddings from every Nth layer.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states\n",
        "        \n",
        "    n_layers = len(hidden_states) - 1\n",
        "    embeddings = {}\n",
        "    \n",
        "    layer_indices = list(range(0, n_layers + 1, layer_step))\n",
        "    if n_layers not in layer_indices:\n",
        "        layer_indices.append(n_layers)\n",
        "    \n",
        "    for layer_idx in layer_indices:\n",
        "        layer_hidden = hidden_states[layer_idx]\n",
        "        embeddings[layer_idx] = layer_hidden[0, 1:, :].mean(dim=0).cpu().numpy().astype(np.float32)\n",
        "    \n",
        "    return embeddings\n",
        "\n",
        "\n",
        "def get_output_preference(text_a: str, text_b: str, model, tokenizer) -> float:\n",
        "    \"\"\"Calculate output preference as NLL(B) - NLL(A).\"\"\"\n",
        "    def get_nll(text):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "            return outputs.loss.item()\n",
        "    \n",
        "    return get_nll(text_b) - get_nll(text_a)\n",
        "\n",
        "\n",
        "def uniformity_score(embeddings: np.ndarray) -> float:\n",
        "    \"\"\"Calculate average pairwise cosine similarity.\"\"\"\n",
        "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    normalized = embeddings / (norms + 1e-10)\n",
        "    kernel = normalized @ normalized.T\n",
        "    n = kernel.shape[0]\n",
        "    idx = np.triu_indices(n, k=1)\n",
        "    return float(np.mean(kernel[idx]))\n",
        "\n",
        "\n",
        "def bootstrap_correlation(x: np.ndarray, y: np.ndarray, n_bootstrap: int = 10000, \n",
        "                          ci_level: float = 0.95) -> Tuple[float, float, float, float]:\n",
        "    \"\"\"\n",
        "    Compute bootstrap CI for Pearson correlation.\n",
        "    \n",
        "    Returns:\n",
        "        (r_observed, ci_lower, ci_upper, p_value)\n",
        "    \"\"\"\n",
        "    n = len(x)\n",
        "    r_observed, p_value = stats.pearsonr(x, y)\n",
        "    \n",
        "    # Bootstrap\n",
        "    bootstrap_rs = []\n",
        "    for _ in range(n_bootstrap):\n",
        "        idx = np.random.choice(n, size=n, replace=True)\n",
        "        x_boot = x[idx]\n",
        "        y_boot = y[idx]\n",
        "        \n",
        "        # Handle edge case: if all values same, correlation undefined\n",
        "        if np.std(x_boot) > 0 and np.std(y_boot) > 0:\n",
        "            r_boot, _ = stats.pearsonr(x_boot, y_boot)\n",
        "            bootstrap_rs.append(r_boot)\n",
        "    \n",
        "    bootstrap_rs = np.array(bootstrap_rs)\n",
        "    \n",
        "    # Percentile CI\n",
        "    alpha = 1 - ci_level\n",
        "    ci_lower = np.percentile(bootstrap_rs, alpha/2 * 100)\n",
        "    ci_upper = np.percentile(bootstrap_rs, (1 - alpha/2) * 100)\n",
        "    \n",
        "    return float(r_observed), float(ci_lower), float(ci_upper), float(p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "collect-header"},
      "source": ["## 3. Collect Category-Level Data"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "collect-data"},
      "outputs": [],
      "source": [
        "def collect_category_data(model, tokenizer, dataset: dict) -> Dict[int, Dict]:\n",
        "    \"\"\"\n",
        "    Collect per-category UA and output preference for each layer.\n",
        "    \n",
        "    Returns:\n",
        "        {layer_num: {'uas': [...], 'prefs': [...], 'categories': [...]}}\n",
        "    \"\"\"\n",
        "    # First pass: collect all embeddings\n",
        "    all_embeddings_a = {}  # layer -> category -> list of embeddings\n",
        "    all_embeddings_b = {}\n",
        "    all_preferences = {}  # category -> list of preferences\n",
        "    \n",
        "    total_pairs = sum(len(cat[\"pairs\"]) for cat in dataset.values())\n",
        "    processed = 0\n",
        "    \n",
        "    print(f\"Collecting embeddings for {total_pairs} pairs...\")\n",
        "    \n",
        "    for category_name, category_data in dataset.items():\n",
        "        pairs = category_data[\"pairs\"]\n",
        "        all_preferences[category_name] = []\n",
        "        \n",
        "        for stmt_a, stmt_b in pairs:\n",
        "            processed += 1\n",
        "            if processed % 50 == 0:\n",
        "                print(f\"  [{processed:03d}/{total_pairs}]\")\n",
        "            \n",
        "            # Get embeddings\n",
        "            embs_a = get_layer_embeddings(stmt_a, model, tokenizer)\n",
        "            embs_b = get_layer_embeddings(stmt_b, model, tokenizer)\n",
        "            \n",
        "            for layer_num, emb in embs_a.items():\n",
        "                if layer_num not in all_embeddings_a:\n",
        "                    all_embeddings_a[layer_num] = {cat: [] for cat in dataset.keys()}\n",
        "                    all_embeddings_b[layer_num] = {cat: [] for cat in dataset.keys()}\n",
        "                all_embeddings_a[layer_num][category_name].append(emb)\n",
        "                all_embeddings_b[layer_num][category_name].append(embs_b[layer_num])\n",
        "            \n",
        "            # Get output preference\n",
        "            pref = get_output_preference(stmt_a, stmt_b, model, tokenizer)\n",
        "            all_preferences[category_name].append(pref)\n",
        "    \n",
        "    print(\"\\nComputing per-category UA...\")\n",
        "    \n",
        "    # Second pass: compute per-category UA for each layer\n",
        "    layer_data = {}\n",
        "    \n",
        "    for layer_num in sorted(all_embeddings_a.keys()):\n",
        "        uas = []\n",
        "        prefs = []\n",
        "        categories = []\n",
        "        \n",
        "        for cat_name in dataset.keys():\n",
        "            cat_embs_a = np.array(all_embeddings_a[layer_num][cat_name])\n",
        "            cat_embs_b = np.array(all_embeddings_b[layer_num][cat_name])\n",
        "            \n",
        "            u_a = uniformity_score(cat_embs_a)\n",
        "            u_b = uniformity_score(cat_embs_b)\n",
        "            ua = u_a - u_b\n",
        "            \n",
        "            mean_pref = np.mean(all_preferences[cat_name])\n",
        "            \n",
        "            uas.append(ua)\n",
        "            prefs.append(mean_pref)\n",
        "            categories.append(cat_name)\n",
        "        \n",
        "        layer_data[layer_num] = {\n",
        "            'uas': np.array(uas),\n",
        "            'prefs': np.array(prefs),\n",
        "            'categories': categories\n",
        "        }\n",
        "    \n",
        "    return layer_data\n",
        "\n",
        "\n",
        "print(f\"Starting data collection for {MODEL_DISPLAY}...\")\n",
        "layer_data = collect_category_data(model, tokenizer, DATASET)\n",
        "print(f\"\\nData collected for {len(layer_data)} layers.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "bootstrap-header"},
      "source": ["## 4. Bootstrap CI Analysis"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "bootstrap-analysis"},
      "outputs": [],
      "source": [
        "print(f\"\\n{'='*70}\")\n",
        "print(f\" BOOTSTRAP CI ANALYSIS: {MODEL_DISPLAY}\")\n",
        "print(f\" n = {len(CATEGORIES)} categories, {N_BOOTSTRAP} bootstrap iterations\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(f\"\\n{'Layer':<10} {'r':<10} {'95% CI':<25} {'CI includes 0?':<15} {'p-value'}\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "for layer_num in sorted(layer_data.keys()):\n",
        "    data = layer_data[layer_num]\n",
        "    uas = data['uas']\n",
        "    prefs = data['prefs']\n",
        "    \n",
        "    r, ci_lower, ci_upper, p_value = bootstrap_correlation(\n",
        "        uas, prefs, n_bootstrap=N_BOOTSTRAP, ci_level=CI_LEVEL\n",
        "    )\n",
        "    \n",
        "    # Check if CI includes 0\n",
        "    includes_zero = ci_lower <= 0 <= ci_upper\n",
        "    \n",
        "    results[layer_num] = {\n",
        "        'r': r,\n",
        "        'ci_lower': ci_lower,\n",
        "        'ci_upper': ci_upper,\n",
        "        'p_value': p_value,\n",
        "        'includes_zero': includes_zero\n",
        "    }\n",
        "    \n",
        "    ci_str = f\"[{ci_lower:+.3f}, {ci_upper:+.3f}]\"\n",
        "    zero_str = \"YES\" if includes_zero else \"NO ***\"\n",
        "    sig_marker = \"*\" if p_value < 0.05 else \"\"\n",
        "    \n",
        "    print(f\"Layer {layer_num:<4} {r:+.3f}     {ci_str:<25} {zero_str:<15} {p_value:.4f}{sig_marker}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "viz-header"},
      "source": ["## 5. Visualization"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "visualization"},
      "outputs": [],
      "source": [
        "# Create visualization with error bars\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "layers = sorted(results.keys())\n",
        "rs = [results[l]['r'] for l in layers]\n",
        "ci_lowers = [results[l]['ci_lower'] for l in layers]\n",
        "ci_uppers = [results[l]['ci_upper'] for l in layers]\n",
        "includes_zeros = [results[l]['includes_zero'] for l in layers]\n",
        "\n",
        "# Error bar heights (asymmetric)\n",
        "yerr_lower = [r - ci_l for r, ci_l in zip(rs, ci_lowers)]\n",
        "yerr_upper = [ci_u - r for r, ci_u in zip(rs, ci_uppers)]\n",
        "\n",
        "# Plot 1: Layer correlation with CI\n",
        "ax1 = axes[0]\n",
        "\n",
        "# Color based on whether CI includes 0\n",
        "colors = ['green' if not inc else 'gray' for inc in includes_zeros]\n",
        "\n",
        "ax1.errorbar(layers, rs, yerr=[yerr_lower, yerr_upper], \n",
        "             fmt='o', capsize=5, capthick=2, markersize=10,\n",
        "             color='blue', ecolor='blue', alpha=0.7)\n",
        "\n",
        "# Highlight points where CI excludes 0\n",
        "for i, (layer, r, inc) in enumerate(zip(layers, rs, includes_zeros)):\n",
        "    if not inc:\n",
        "        ax1.scatter([layer], [r], color='red', s=150, zorder=5, marker='*')\n",
        "\n",
        "ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5, linewidth=2)\n",
        "ax1.set_xlabel('Layer', fontsize=12)\n",
        "ax1.set_ylabel('r(UA, Output Preference)', fontsize=12)\n",
        "ax1.set_title(f'{MODEL_DISPLAY}: Layer Correlation with 95% Bootstrap CI\\n(Red stars = CI excludes 0)', \n",
        "              fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(-1.2, 1.2)\n",
        "\n",
        "# Plot 2: CI width by layer\n",
        "ax2 = axes[1]\n",
        "\n",
        "ci_widths = [ci_u - ci_l for ci_l, ci_u in zip(ci_lowers, ci_uppers)]\n",
        "bars = ax2.bar(layers, ci_widths, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "\n",
        "ax2.set_xlabel('Layer', fontsize=12)\n",
        "ax2.set_ylabel('CI Width', fontsize=12)\n",
        "ax2.set_title('95% CI Width by Layer\\n(Wider = more uncertainty)', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add mean CI width line\n",
        "mean_width = np.mean(ci_widths)\n",
        "ax2.axhline(y=mean_width, color='red', linestyle='--', label=f'Mean: {mean_width:.2f}')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('bootstrap_ci_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nPlot saved to: bootstrap_ci_results.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "summary-header"},
      "source": ["## 6. Summary: Is the Mid-Layer Regime Statistically Stable?"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "summary"},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"#\"*70)\n",
        "print(\"# KEY QUESTION: Is the mid-layer positive regime statistically stable?\")\n",
        "print(\"#\"*70)\n",
        "\n",
        "# Identify mid-layers (roughly 25-50% of depth)\n",
        "n_layers = model.config.num_hidden_layers\n",
        "mid_layer_range = (int(n_layers * 0.2), int(n_layers * 0.5))\n",
        "\n",
        "print(f\"\\nModel depth: {n_layers} layers\")\n",
        "print(f\"Mid-layer range: Layer {mid_layer_range[0]} to {mid_layer_range[1]} (~20-50% depth)\")\n",
        "\n",
        "mid_layers = [l for l in layers if mid_layer_range[0] <= l <= mid_layer_range[1]]\n",
        "\n",
        "print(f\"\\nMid-layer analysis:\")\n",
        "mid_layer_stable = []\n",
        "\n",
        "for layer in mid_layers:\n",
        "    r = results[layer]['r']\n",
        "    ci_l = results[layer]['ci_lower']\n",
        "    ci_u = results[layer]['ci_upper']\n",
        "    inc_zero = results[layer]['includes_zero']\n",
        "    \n",
        "    status = \"INCLUDES 0 (not stable)\" if inc_zero else \"EXCLUDES 0 (stable)\"\n",
        "    print(f\"  Layer {layer}: r = {r:+.3f}, CI = [{ci_l:+.3f}, {ci_u:+.3f}] → {status}\")\n",
        "    \n",
        "    if r > 0:  # Positive correlation\n",
        "        mid_layer_stable.append(not inc_zero)\n",
        "\n",
        "# Late layers\n",
        "late_layers = [l for l in layers if l >= int(n_layers * 0.75)]\n",
        "\n",
        "print(f\"\\nLate-layer analysis (>75% depth):\")\n",
        "late_layer_stable = []\n",
        "\n",
        "for layer in late_layers:\n",
        "    r = results[layer]['r']\n",
        "    ci_l = results[layer]['ci_lower']\n",
        "    ci_u = results[layer]['ci_upper']\n",
        "    inc_zero = results[layer]['includes_zero']\n",
        "    \n",
        "    status = \"INCLUDES 0\" if inc_zero else \"EXCLUDES 0 (significant)\"\n",
        "    print(f\"  Layer {layer}: r = {r:+.3f}, CI = [{ci_l:+.3f}, {ci_u:+.3f}] → {status}\")\n",
        "    \n",
        "    if r < 0:  # Negative correlation\n",
        "        late_layer_stable.append(not inc_zero)\n",
        "\n",
        "# Final answer\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" ANSWER\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "any_mid_stable = any(mid_layer_stable) if mid_layer_stable else False\n",
        "any_late_stable = any(late_layer_stable) if late_layer_stable else False\n",
        "\n",
        "if any_mid_stable:\n",
        "    print(\"\\n>>> Mid-layer positive regime: STATISTICALLY DISTINGUISHABLE from 0\")\n",
        "    print(\"    At least one mid-layer has CI that excludes 0.\")\n",
        "else:\n",
        "    print(\"\\n>>> Mid-layer positive regime: NOT statistically stable\")\n",
        "    print(\"    All mid-layer CIs include 0 - could be noise.\")\n",
        "    print(\"    NOTE: With n=6 categories, wide CIs are expected.\")\n",
        "\n",
        "if any_late_stable:\n",
        "    print(\"\\n>>> Late-layer negative regime: STATISTICALLY SIGNIFICANT\")\n",
        "    print(\"    CI excludes 0 - this is a robust finding.\")\n",
        "else:\n",
        "    print(\"\\n>>> Late-layer negative regime: Not statistically significant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "save-header"},
      "source": ["## 7. Save Results"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "save-results"},
      "outputs": [],
      "source": [
        "# Prepare results for saving\n",
        "save_data = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'model': MODEL_NAME,\n",
        "    'model_display': MODEL_DISPLAY,\n",
        "    'n_categories': len(CATEGORIES),\n",
        "    'n_bootstrap': N_BOOTSTRAP,\n",
        "    'ci_level': CI_LEVEL,\n",
        "    'layer_results': {str(k): v for k, v in results.items()},\n",
        "    'summary': {\n",
        "        'mid_layer_range': list(mid_layer_range),\n",
        "        'mid_layers_tested': mid_layers,\n",
        "        'any_mid_layer_stable': bool(any_mid_stable),\n",
        "        'late_layers_tested': late_layers,\n",
        "        'any_late_layer_stable': bool(any_late_stable)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "output_file = f\"bootstrap_ci_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(save_data, f, indent=2)\n",
        "\n",
        "print(f\"Results saved to: {output_file}\")\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "files.download(output_file)\n",
        "files.download('bootstrap_ci_results.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "interpretation-header"},
      "source": ["## 8. Interpretation"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "interpretation"},
      "outputs": [],
      "source": [
        "interpretation = f\"\"\"\n",
        "## Bootstrap CI Analysis: {MODEL_DISPLAY}\n",
        "\n",
        "### Method\n",
        "- n = {len(CATEGORIES)} categories\n",
        "- {N_BOOTSTRAP} bootstrap iterations\n",
        "- {CI_LEVEL*100}% confidence intervals\n",
        "\n",
        "### Results by Layer\n",
        "\n",
        "| Layer | r | 95% CI | CI includes 0? |\n",
        "|-------|---|--------|----------------|\n",
        "\"\"\"\n",
        "\n",
        "for layer in sorted(results.keys()):\n",
        "    r = results[layer]['r']\n",
        "    ci_l = results[layer]['ci_lower']\n",
        "    ci_u = results[layer]['ci_upper']\n",
        "    inc = \"Yes\" if results[layer]['includes_zero'] else \"**No**\"\n",
        "    interpretation += f\"| {layer} | {r:+.3f} | [{ci_l:+.3f}, {ci_u:+.3f}] | {inc} |\\n\"\n",
        "\n",
        "interpretation += f\"\"\"\n",
        "### Key Finding\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "if any_mid_stable:\n",
        "    interpretation += \"\"\"The mid-layer positive regime is **statistically distinguishable from 0**.\n",
        "This is not just noise - there is evidence for a qualitatively different regime in mid-layers.\n",
        "\"\"\"\n",
        "else:\n",
        "    interpretation += \"\"\"The mid-layer positive regime **cannot be distinguished from 0** with n=6 categories.\n",
        "This doesn't mean it's not real - just that we lack statistical power to confirm it.\n",
        "Wide CIs are expected with small n.\n",
        "\"\"\"\n",
        "\n",
        "if any_late_stable:\n",
        "    interpretation += \"\"\"\\nThe late-layer negative regime **is statistically significant** (CI excludes 0).\n",
        "This is the most robust finding.\n",
        "\"\"\"\n",
        "\n",
        "interpretation += \"\"\"\n",
        "### Honest Assessment\n",
        "\n",
        "With n=6 categories, bootstrap CIs will be wide. This is **honest uncertainty**.\n",
        "The pattern (positive mid-layer, negative late-layer) is **consistent** across models,\n",
        "but statistical significance is limited by small sample size.\n",
        "\n",
        "**Recommendation:** Pair-level analysis (n=230) would provide more statistical power.\n",
        "\"\"\"\n",
        "\n",
        "print(interpretation)"
      ]
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {"id": "header"},
      "source": [
        "# Option B: Pair-Level Analysis (New Metric, n=230)\n",
        "\n",
        "**Research Question:**\n",
        "> Can we define a pair-level UA proxy that correlates with output preference at n=230?\n",
        "\n",
        "**IMPORTANT:** This is a **NEW METRIC**, not the same as category-level UA.\n",
        "\n",
        "**Method:**\n",
        "- Define \"Local UA\" for each pair (A_i, B_i)\n",
        "- Correlate with output preference\n",
        "- n=230 gives much more statistical power\n",
        "\n",
        "**Proposed Local UA Metrics:**\n",
        "1. **Centroid Distance Asymmetry:** dist(A_i, centroid_A) - dist(B_i, centroid_B)\n",
        "2. **kNN Density Asymmetry:** density around A_i vs density around B_i\n",
        "3. **Relative Position:** Where does this pair sit relative to cluster structure?\n",
        "\n",
        "**Caveat:** Results are NOT directly comparable to category-level UA.\n",
        "\n",
        "---\n",
        "\n",
        "**Author:** Davide D'Elia  \n",
        "**Date:** 2026-01-03  \n",
        "**Model:** Pythia-6.9B  \n",
        "**Status:** EXPERIMENTAL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "setup-header"},
      "source": ["## 1. Setup"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "install"},
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate torch numpy scipy matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "imports"},
      "outputs": [],
      "source": [
        "import json\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "N_BOOTSTRAP = 10000\n",
        "CI_LEVEL = 0.95\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "load-model"},
      "outputs": [],
      "source": [
        "MODEL_NAME = \"EleutherAI/pythia-6.9b\"\n",
        "MODEL_DISPLAY = \"Pythia-6.9B\"\n",
        "\n",
        "print(f\"Loading {MODEL_DISPLAY}...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    output_hidden_states=True\n",
        ")\n",
        "\n",
        "print(f\"Model loaded. Layers: {model.config.num_hidden_layers}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "load-dataset"},
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/buk81/uniformity-asymmetry/main/dataset.json\n",
        "\n",
        "with open('dataset.json', 'r') as f:\n",
        "    DATASET = json.load(f)\n",
        "\n",
        "ALL_PAIRS = []\n",
        "for cat_name, cat_data in DATASET.items():\n",
        "    for pair in cat_data['pairs']:\n",
        "        ALL_PAIRS.append({\n",
        "            'stmt_a': pair[0],\n",
        "            'stmt_b': pair[1],\n",
        "            'category': cat_name\n",
        "        })\n",
        "\n",
        "print(f\"Total pairs: {len(ALL_PAIRS)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "functions-header"},
      "source": ["## 2. Core Functions"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "core-functions"},
      "outputs": [],
      "source": [
        "def get_layer_embedding(text: str, model, tokenizer, layer_idx: int) -> np.ndarray:\n",
        "    \"\"\"Get mean-pooled embedding from a specific layer.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states\n",
        "    \n",
        "    layer_hidden = hidden_states[layer_idx]\n",
        "    embedding = layer_hidden[0, 1:, :].mean(dim=0).cpu().numpy().astype(np.float32)\n",
        "    \n",
        "    return embedding\n",
        "\n",
        "\n",
        "def get_output_preference(text_a: str, text_b: str, model, tokenizer) -> float:\n",
        "    \"\"\"Calculate output preference as NLL(B) - NLL(A).\"\"\"\n",
        "    def get_nll(text):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "            return outputs.loss.item()\n",
        "    \n",
        "    return get_nll(text_b) - get_nll(text_a)\n",
        "\n",
        "\n",
        "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
        "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10))\n",
        "\n",
        "\n",
        "def bootstrap_correlation(x: np.ndarray, y: np.ndarray, n_bootstrap: int = 10000,\n",
        "                          ci_level: float = 0.95) -> Tuple[float, float, float, float]:\n",
        "    \"\"\"Compute bootstrap CI for Pearson correlation.\"\"\"\n",
        "    n = len(x)\n",
        "    r_observed, p_value = stats.pearsonr(x, y)\n",
        "    \n",
        "    bootstrap_rs = []\n",
        "    for _ in range(n_bootstrap):\n",
        "        idx = np.random.choice(n, size=n, replace=True)\n",
        "        x_boot = x[idx]\n",
        "        y_boot = y[idx]\n",
        "        \n",
        "        if np.std(x_boot) > 0 and np.std(y_boot) > 0:\n",
        "            r_boot, _ = stats.pearsonr(x_boot, y_boot)\n",
        "            bootstrap_rs.append(r_boot)\n",
        "    \n",
        "    bootstrap_rs = np.array(bootstrap_rs)\n",
        "    alpha = 1 - ci_level\n",
        "    ci_lower = np.percentile(bootstrap_rs, alpha/2 * 100)\n",
        "    ci_upper = np.percentile(bootstrap_rs, (1 - alpha/2) * 100)\n",
        "    \n",
        "    return float(r_observed), float(ci_lower), float(ci_upper), float(p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "collect-header"},
      "source": ["## 3. Collect All Embeddings"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "collect-embeddings"},
      "outputs": [],
      "source": [
        "LAYERS_TO_TEST = [0, 4, 8, 12, 16, 20, 24, 28, 32]\n",
        "\n",
        "print(f\"Collecting embeddings for {len(ALL_PAIRS)} pairs...\")\n",
        "\n",
        "pair_data = []\n",
        "\n",
        "for i, pair in enumerate(ALL_PAIRS):\n",
        "    if (i + 1) % 25 == 0:\n",
        "        print(f\"  [{i+1:03d}/{len(ALL_PAIRS)}]\")\n",
        "    \n",
        "    stmt_a = pair['stmt_a']\n",
        "    stmt_b = pair['stmt_b']\n",
        "    \n",
        "    pref = get_output_preference(stmt_a, stmt_b, model, tokenizer)\n",
        "    \n",
        "    layer_embeddings = {}\n",
        "    for layer_idx in LAYERS_TO_TEST:\n",
        "        emb_a = get_layer_embedding(stmt_a, model, tokenizer, layer_idx)\n",
        "        emb_b = get_layer_embedding(stmt_b, model, tokenizer, layer_idx)\n",
        "        layer_embeddings[layer_idx] = {'emb_a': emb_a, 'emb_b': emb_b}\n",
        "    \n",
        "    pair_data.append({\n",
        "        'pref': pref,\n",
        "        'category': pair['category'],\n",
        "        'layer_embeddings': layer_embeddings\n",
        "    })\n",
        "\n",
        "print(f\"\\nDone! Collected {len(pair_data)} pairs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "metrics-header"},
      "source": ["## 4. Define Pair-Level UA Metrics"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "define-metrics"},
      "outputs": [],
      "source": [
        "def compute_pair_metrics(pair_data: list, layer_idx: int) -> Dict[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Compute multiple pair-level UA proxies.\n",
        "    \n",
        "    Returns dict with different metric arrays (one value per pair).\n",
        "    \"\"\"\n",
        "    n_pairs = len(pair_data)\n",
        "    \n",
        "    # Collect all embeddings\n",
        "    all_embs_a = np.array([p['layer_embeddings'][layer_idx]['emb_a'] for p in pair_data])\n",
        "    all_embs_b = np.array([p['layer_embeddings'][layer_idx]['emb_b'] for p in pair_data])\n",
        "    \n",
        "    # Compute centroids\n",
        "    centroid_a = all_embs_a.mean(axis=0)\n",
        "    centroid_b = all_embs_b.mean(axis=0)\n",
        "    \n",
        "    metrics = {}\n",
        "    \n",
        "    # ----- Metric 1: Centroid Distance Asymmetry -----\n",
        "    # How far is this A from all A's centroid vs this B from all B's centroid?\n",
        "    # High value = A is more \"typical\" of its side than B is of its side\n",
        "    centroid_dist_a = np.array([cosine_similarity(emb, centroid_a) for emb in all_embs_a])\n",
        "    centroid_dist_b = np.array([cosine_similarity(emb, centroid_b) for emb in all_embs_b])\n",
        "    metrics['centroid_asymmetry'] = centroid_dist_a - centroid_dist_b\n",
        "    \n",
        "    # ----- Metric 2: Cross-Centroid Distance -----\n",
        "    # How far is A from B's centroid vs B from A's centroid?\n",
        "    cross_dist_a = np.array([cosine_similarity(emb, centroid_b) for emb in all_embs_a])\n",
        "    cross_dist_b = np.array([cosine_similarity(emb, centroid_a) for emb in all_embs_b])\n",
        "    metrics['cross_centroid'] = cross_dist_a - cross_dist_b\n",
        "    \n",
        "    # ----- Metric 3: Within-Pair Similarity -----\n",
        "    # How similar is A to B within this pair?\n",
        "    # Low similarity might indicate more \"distinctive\" pairs\n",
        "    within_pair_sim = np.array([cosine_similarity(all_embs_a[i], all_embs_b[i]) \n",
        "                                 for i in range(n_pairs)])\n",
        "    metrics['within_pair_sim'] = within_pair_sim\n",
        "    \n",
        "    # ----- Metric 4: kNN Density Asymmetry -----\n",
        "    # Is A in a denser region than B?\n",
        "    k = min(10, n_pairs - 1)\n",
        "    \n",
        "    nn_a = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
        "    nn_a.fit(all_embs_a)\n",
        "    distances_a, _ = nn_a.kneighbors(all_embs_a)\n",
        "    density_a = 1 / (distances_a.mean(axis=1) + 1e-10)\n",
        "    \n",
        "    nn_b = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
        "    nn_b.fit(all_embs_b)\n",
        "    distances_b, _ = nn_b.kneighbors(all_embs_b)\n",
        "    density_b = 1 / (distances_b.mean(axis=1) + 1e-10)\n",
        "    \n",
        "    # Normalize densities\n",
        "    density_a_norm = (density_a - density_a.mean()) / (density_a.std() + 1e-10)\n",
        "    density_b_norm = (density_b - density_b.mean()) / (density_b.std() + 1e-10)\n",
        "    \n",
        "    metrics['knn_density_asymmetry'] = density_a_norm - density_b_norm\n",
        "    \n",
        "    # ----- Metric 5: Margin to Decision Boundary -----\n",
        "    # Conceptual: How far is each embedding from the \"middle\" between centroids?\n",
        "    midpoint = (centroid_a + centroid_b) / 2\n",
        "    dist_to_mid_a = np.array([np.linalg.norm(emb - midpoint) for emb in all_embs_a])\n",
        "    dist_to_mid_b = np.array([np.linalg.norm(emb - midpoint) for emb in all_embs_b])\n",
        "    metrics['margin_asymmetry'] = dist_to_mid_a - dist_to_mid_b\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "\n",
        "print(\"Pair-level metrics defined:\")\n",
        "print(\"  1. centroid_asymmetry: sim(A, centroid_A) - sim(B, centroid_B)\")\n",
        "print(\"  2. cross_centroid: sim(A, centroid_B) - sim(B, centroid_A)\")\n",
        "print(\"  3. within_pair_sim: sim(A, B) for each pair\")\n",
        "print(\"  4. knn_density_asymmetry: normalized kNN density difference\")\n",
        "print(\"  5. margin_asymmetry: distance to midpoint difference\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "analysis-header"},
      "source": ["## 5. Pair-Level Correlation Analysis"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "pair-analysis"},
      "outputs": [],
      "source": [
        "# Get output preferences\n",
        "all_prefs = np.array([p['pref'] for p in pair_data])\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\" PAIR-LEVEL ANALYSIS (n={len(pair_data)})\")\n",
        "print(f\" NOTE: This is a DIFFERENT metric than category-level UA\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "results = {}\n",
        "\n",
        "for layer_idx in LAYERS_TO_TEST:\n",
        "    print(f\"\\n--- Layer {layer_idx} ---\")\n",
        "    \n",
        "    metrics = compute_pair_metrics(pair_data, layer_idx)\n",
        "    layer_results = {}\n",
        "    \n",
        "    for metric_name, metric_values in metrics.items():\n",
        "        r, ci_lower, ci_upper, p = bootstrap_correlation(\n",
        "            metric_values, all_prefs, N_BOOTSTRAP, CI_LEVEL\n",
        "        )\n",
        "        \n",
        "        includes_zero = ci_lower <= 0 <= ci_upper\n",
        "        sig_marker = \"\" if includes_zero else \"***\"\n",
        "        \n",
        "        layer_results[metric_name] = {\n",
        "            'r': r,\n",
        "            'ci_lower': ci_lower,\n",
        "            'ci_upper': ci_upper,\n",
        "            'p_value': p,\n",
        "            'includes_zero': includes_zero\n",
        "        }\n",
        "        \n",
        "        print(f\"  {metric_name:<25} r={r:+.3f}  CI=[{ci_lower:+.3f}, {ci_upper:+.3f}] {sig_marker}\")\n",
        "    \n",
        "    results[layer_idx] = layer_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "best-metric-header"},
      "source": ["## 6. Find Best Metric"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "best-metric"},
      "outputs": [],
      "source": [
        "print(f\"\\n{'='*80}\")\n",
        "print(f\" BEST PAIR-LEVEL METRIC BY LAYER\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# For each layer, find metric with highest |r| that excludes 0\n",
        "print(f\"\\n{'Layer':<8} {'Best Metric':<25} {'r':<10} {'CI excludes 0?'}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "best_metrics_summary = []\n",
        "\n",
        "for layer_idx in LAYERS_TO_TEST:\n",
        "    layer_results = results[layer_idx]\n",
        "    \n",
        "    # Find best (highest |r| with CI excluding 0)\n",
        "    best_metric = None\n",
        "    best_r = 0\n",
        "    best_excludes_zero = False\n",
        "    \n",
        "    for metric_name, res in layer_results.items():\n",
        "        if abs(res['r']) > abs(best_r):\n",
        "            best_r = res['r']\n",
        "            best_metric = metric_name\n",
        "            best_excludes_zero = not res['includes_zero']\n",
        "    \n",
        "    status = \"YES ***\" if best_excludes_zero else \"no\"\n",
        "    print(f\"Layer {layer_idx:<3} {best_metric:<25} {best_r:+.3f}     {status}\")\n",
        "    \n",
        "    best_metrics_summary.append({\n",
        "        'layer': layer_idx,\n",
        "        'best_metric': best_metric,\n",
        "        'r': best_r,\n",
        "        'excludes_zero': best_excludes_zero\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "viz-header"},
      "source": ["## 7. Visualization"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "visualization"},
      "outputs": [],
      "source": [
        "# Plot correlation by layer for each metric\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "metric_names = list(results[LAYERS_TO_TEST[0]].keys())\n",
        "\n",
        "for idx, metric_name in enumerate(metric_names):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    rs = [results[l][metric_name]['r'] for l in LAYERS_TO_TEST]\n",
        "    ci_lowers = [results[l][metric_name]['ci_lower'] for l in LAYERS_TO_TEST]\n",
        "    ci_uppers = [results[l][metric_name]['ci_upper'] for l in LAYERS_TO_TEST]\n",
        "    \n",
        "    yerr_lower = [r - ci_l for r, ci_l in zip(rs, ci_lowers)]\n",
        "    yerr_upper = [ci_u - r for r, ci_u in zip(rs, ci_uppers)]\n",
        "    \n",
        "    ax.errorbar(LAYERS_TO_TEST, rs, yerr=[yerr_lower, yerr_upper],\n",
        "                fmt='o-', capsize=5, capthick=2, markersize=8,\n",
        "                color='blue', ecolor='blue', alpha=0.7)\n",
        "    \n",
        "    # Highlight significant layers\n",
        "    for l, r in zip(LAYERS_TO_TEST, rs):\n",
        "        if not results[l][metric_name]['includes_zero']:\n",
        "            ax.scatter([l], [r], color='red', s=150, zorder=5, marker='*')\n",
        "    \n",
        "    ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    ax.set_xlabel('Layer')\n",
        "    ax.set_ylabel('r')\n",
        "    ax.set_title(metric_name, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_ylim(-0.5, 0.5)\n",
        "\n",
        "# Hide extra subplot\n",
        "if len(metric_names) < len(axes):\n",
        "    axes[-1].axis('off')\n",
        "\n",
        "plt.suptitle(f'Pair-Level Correlations (n={len(pair_data)}) - Red stars = significant',\n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('option_b_pair_level.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPlot saved to: option_b_pair_level.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "summary-header"},
      "source": ["## 8. Summary & Interpretation"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "summary"},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"#\"*80)\n",
        "print(\"# OPTION B SUMMARY: Pair-Level Analysis (EXPERIMENTAL)\")\n",
        "print(\"#\"*80)\n",
        "\n",
        "# Count significant findings\n",
        "total_tests = len(LAYERS_TO_TEST) * len(metric_names)\n",
        "sig_tests = sum(1 for l in results for m in results[l] if not results[l][m]['includes_zero'])\n",
        "\n",
        "print(f\"\\nTotal tests: {total_tests}\")\n",
        "print(f\"Significant (CI excludes 0): {sig_tests}\")\n",
        "print(f\"Significance rate: {sig_tests/total_tests*100:.1f}%\")\n",
        "\n",
        "print(f\"\\n--- Key Observations ---\")\n",
        "\n",
        "# Check if mid-layers are different\n",
        "mid_layers = [8, 12]\n",
        "late_layers = [28, 32]\n",
        "\n",
        "mid_sig = [(l, m) for l in mid_layers for m in results[l] if not results[l][m]['includes_zero']]\n",
        "late_sig = [(l, m) for l in late_layers for m in results[l] if not results[l][m]['includes_zero']]\n",
        "\n",
        "print(f\"\\nMid-layer (8, 12) significant correlations: {len(mid_sig)}\")\n",
        "for l, m in mid_sig:\n",
        "    print(f\"  Layer {l}, {m}: r = {results[l][m]['r']:+.3f}\")\n",
        "\n",
        "print(f\"\\nLate-layer (28, 32) significant correlations: {len(late_sig)}\")\n",
        "for l, m in late_sig:\n",
        "    print(f\"  Layer {l}, {m}: r = {results[l][m]['r']:+.3f}\")\n",
        "\n",
        "print(f\"\\n--- IMPORTANT CAVEAT ---\")\n",
        "print(f\"These pair-level metrics are NOT the same as category-level UA.\")\n",
        "print(f\"They measure different properties:\")\n",
        "print(f\"  - Category-level UA: Group geometry (uniformity within clusters)\")\n",
        "print(f\"  - Pair-level metrics: Individual position relative to clusters\")\n",
        "print(f\"\")\n",
        "print(f\"Pair-level results should be interpreted as:\")\n",
        "print(f\"  'Individual embedding position correlates with output preference'\")\n",
        "print(f\"NOT as:\")\n",
        "print(f\"  'The same UA metric works at pair level'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "save-results"},
      "outputs": [],
      "source": [
        "# Save results\n",
        "save_data = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'model': MODEL_NAME,\n",
        "    'method': 'Option B: Pair-Level Analysis (EXPERIMENTAL)',\n",
        "    'n_pairs': len(pair_data),\n",
        "    'n_bootstrap': N_BOOTSTRAP,\n",
        "    'metrics_tested': metric_names,\n",
        "    'results': {str(k): {m: v for m, v in layer_res.items()} \n",
        "                for k, layer_res in results.items()},\n",
        "    'best_per_layer': best_metrics_summary,\n",
        "    'summary': {\n",
        "        'total_tests': total_tests,\n",
        "        'significant_tests': sig_tests,\n",
        "        'mid_layer_significant': len(mid_sig),\n",
        "        'late_layer_significant': len(late_sig)\n",
        "    },\n",
        "    'caveat': 'Pair-level metrics are NOT the same as category-level UA. Different interpretation required.'\n",
        "}\n",
        "\n",
        "output_file = f\"option_b_pair_level_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(save_data, f, indent=2)\n",
        "\n",
        "print(f\"\\nResults saved to: {output_file}\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(output_file)\n",
        "files.download('option_b_pair_level.png')"
      ]
    }
  ]
}

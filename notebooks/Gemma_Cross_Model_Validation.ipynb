{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Model Validation: Gemma-2B Layer Analysis\n\n",
    "**Purpose:** Test if phase-structured embedding-output relationship exists in SFT models.\n\n",
    "**Research Question:** Does Gemma-2B (SFT, not RLHF) show:\n",
    "1. The same late-layer inversion as Pythia/Llama?\n",
    "2. Different phase structure due to SFT training?\n\n",
    "**Context:** Original paper showed r\u2248+0.95 at category level (confounded by GT-Numeric).\n",
    "Layer analysis will reveal the true pattern.\n\n",
    "**Expected Runtime:** ~1.5h on A100\n\n",
    "---\n\n",
    "**Author:** Davide D'Elia  \n",
    "**Date:** 2026-01-03  \n",
    "**Model:** google/gemma-2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install -q transformers accelerate torch numpy scipy matplotlib scikit-learn huggingface_hub"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n\n",
    "warnings.filterwarnings('ignore')\n\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n\n",
    "N_BOOTSTRAP = 10000\n",
    "CI_LEVEL = 0.95\n\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ========================================\n",
    "# HUGGINGFACE LOGIN\n",
    "# ========================================\n",
    "# Gemma requires accepting terms at: https://huggingface.co/google/gemma-2b\n\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "    print('Token aus Colab Secrets geladen')\n",
    "except:\n",
    "    HF_TOKEN = None\n\n",
    "if not HF_TOKEN:\n",
    "    HF_TOKEN = ''  # <-- Token hier einfuegen\n\n",
    "if not HF_TOKEN:\n",
    "    from huggingface_hub import notebook_login\n",
    "    notebook_login()\n",
    "else:\n",
    "    from huggingface_hub import login\n",
    "    login(token=HF_TOKEN)\n",
    "    print('Eingeloggt')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "MODEL_NAME = 'google/gemma-2b'\n",
    "MODEL_DISPLAY = 'Gemma-2B'\n\n",
    "print(f'Loading {MODEL_DISPLAY}...')\n",
    "print('NOTE: SFT model (Supervised Fine-Tuning, not RLHF)')\n\n",
    "token_arg = HF_TOKEN if HF_TOKEN else True\n\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=token_arg)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=token_arg,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto',\n",
    "    output_hidden_states=True\n",
    ")\n\n",
    "print(f'Model loaded')\n",
    "print(f'Layers: {model.config.num_hidden_layers}')\n",
    "print(f'Hidden size: {model.config.hidden_size}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!wget -q https://raw.githubusercontent.com/buk81/uniformity-asymmetry/main/dataset.json\n\n",
    "with open('dataset.json', 'r') as f:\n",
    "    DATASET = json.load(f)\n\n",
    "ALL_PAIRS = []\n",
    "for cat_name, cat_data in DATASET.items():\n",
    "    for pair in cat_data['pairs']:\n",
    "        ALL_PAIRS.append({'stmt_a': pair[0], 'stmt_b': pair[1], 'category': cat_name})\n\n",
    "print(f'Categories: {list(DATASET.keys())}')\n",
    "print(f'Total pairs: {len(ALL_PAIRS)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_layer_embedding(text, model, tokenizer, layer_idx):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    layer_hidden = outputs.hidden_states[layer_idx]\n",
    "    return layer_hidden[0, 1:, :].mean(dim=0).cpu().numpy().astype(np.float32)\n\n",
    "def get_output_preference(text_a, text_b, model, tokenizer):\n",
    "    def get_nll(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "        return outputs.loss.item()\n",
    "    return get_nll(text_b) - get_nll(text_a)\n\n",
    "def cosine_similarity(a, b):\n",
    "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10))\n\n",
    "def bootstrap_correlation(x, y, n_bootstrap=10000, ci_level=0.95):\n",
    "    n = len(x)\n",
    "    r_obs, p = stats.pearsonr(x, y)\n",
    "    rs = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        if np.std(x[idx]) > 0 and np.std(y[idx]) > 0:\n",
    "            r, _ = stats.pearsonr(x[idx], y[idx])\n",
    "            rs.append(r)\n",
    "    rs = np.array(rs)\n",
    "    alpha = 1 - ci_level\n",
    "    return float(r_obs), float(np.percentile(rs, alpha/2*100)), float(np.percentile(rs, (1-alpha/2)*100)), float(p)\n\n",
    "print('Functions defined.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Collect Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "N_LAYERS = model.config.num_hidden_layers\n",
    "# Gemma-2B has 18 layers, sample every 3rd\n",
    "LAYERS_TO_TEST = list(range(0, N_LAYERS + 1, max(1, N_LAYERS // 8)))\n",
    "if N_LAYERS not in LAYERS_TO_TEST:\n",
    "    LAYERS_TO_TEST.append(N_LAYERS)\n\n",
    "print(f'Testing layers: {LAYERS_TO_TEST}')\n",
    "print(f'Collecting embeddings for {len(ALL_PAIRS)} pairs...')\n\n",
    "pair_data = []\n",
    "start = datetime.now()\n\n",
    "for i, pair in enumerate(ALL_PAIRS):\n",
    "    if (i + 1) % 25 == 0:\n",
    "        elapsed = (datetime.now() - start).total_seconds() / 60\n",
    "        print(f'  [{i+1:03d}/{len(ALL_PAIRS)}] - {elapsed:.1f} min')\n",
    "    \n",
    "    pref = get_output_preference(pair['stmt_a'], pair['stmt_b'], model, tokenizer)\n",
    "    layer_embs = {}\n",
    "    for l in LAYERS_TO_TEST:\n",
    "        emb_a = get_layer_embedding(pair['stmt_a'], model, tokenizer, l)\n",
    "        emb_b = get_layer_embedding(pair['stmt_b'], model, tokenizer, l)\n",
    "        layer_embs[l] = {'a': emb_a, 'b': emb_b}\n",
    "    pair_data.append({'pref': pref, 'cat': pair['category'], 'embs': layer_embs})\n\n",
    "print(f'Done in {(datetime.now() - start).total_seconds() / 60:.1f} min')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pair-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def compute_centroid_asymmetry(pair_data, layer_idx):\n",
    "    embs_a = np.array([p['embs'][layer_idx]['a'] for p in pair_data])\n",
    "    embs_b = np.array([p['embs'][layer_idx]['b'] for p in pair_data])\n",
    "    cent_a, cent_b = embs_a.mean(0), embs_b.mean(0)\n",
    "    dist_a = np.array([cosine_similarity(e, cent_a) for e in embs_a])\n",
    "    dist_b = np.array([cosine_similarity(e, cent_b) for e in embs_b])\n",
    "    return dist_a - dist_b\n\n",
    "all_prefs = np.array([p['pref'] for p in pair_data])\n\n",
    "print('=' * 70)\n",
    "print(f' {MODEL_DISPLAY}: PAIR-LEVEL ANALYSIS (n={len(pair_data)})')\n",
    "print('=' * 70)\n\n",
    "results = {}\n",
    "for l in LAYERS_TO_TEST:\n",
    "    metric = compute_centroid_asymmetry(pair_data, l)\n",
    "    r, ci_lo, ci_hi, p = bootstrap_correlation(metric, all_prefs, N_BOOTSTRAP, CI_LEVEL)\n",
    "    sig = '***' if not (ci_lo <= 0 <= ci_hi) else ''\n",
    "    results[l] = {'r': r, 'ci_lo': ci_lo, 'ci_hi': ci_hi, 'sig': not (ci_lo <= 0 <= ci_hi)}\n",
    "    print(f'Layer {l:2d}: r={r:+.3f} CI=[{ci_lo:+.3f},{ci_hi:+.3f}] {sig}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Phase Structure"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Determine phase boundaries based on layer count\n",
    "n_layers = len(LAYERS_TO_TEST)\n",
    "early_layers = LAYERS_TO_TEST[:n_layers//3]\n",
    "mid_layers = LAYERS_TO_TEST[n_layers//3:2*n_layers//3]\n",
    "late_layers = LAYERS_TO_TEST[2*n_layers//3:]\n\n",
    "early_mean = np.mean([results[l]['r'] for l in early_layers])\n",
    "mid_mean = np.mean([results[l]['r'] for l in mid_layers])\n",
    "late_mean = np.mean([results[l]['r'] for l in late_layers])\n\n",
    "print(f'\\nPhase Structure:')\n",
    "print(f'  Early {early_layers}: mean r = {early_mean:+.3f}')\n",
    "print(f'  Mid   {mid_layers}: mean r = {mid_mean:+.3f}')\n",
    "print(f'  Late  {late_layers}: mean r = {late_mean:+.3f}')\n\n",
    "# Determine pattern\n",
    "if early_mean > 0.1 and late_mean < -0.1:\n",
    "    pattern = 'PYTHIA_PATTERN: positive early, negative late'\n",
    "elif late_mean < -0.1:\n",
    "    pattern = 'LATE_INVERSION: negative in late layers'\n",
    "elif abs(early_mean) < 0.15 and abs(mid_mean) < 0.15 and abs(late_mean) < 0.15:\n",
    "    pattern = 'DECOUPLED: weak correlations throughout'\n",
    "else:\n",
    "    pattern = 'OTHER'\n\n",
    "print(f'\\n>>> Pattern: {pattern} <<<')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison with Other Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Reference values from Pythia and Llama\n",
    "print('=' * 70)\n",
    "print(' CROSS-MODEL COMPARISON')\n",
    "print('=' * 70)\n\n",
    "print(f'\\nPhase Means Comparison:')\n",
    "print(f'{\"Model\":<25} {\"Early\":>10} {\"Mid\":>10} {\"Late\":>10}')\n",
    "print('-' * 55)\n",
    "print(f'{\"Pythia-6.9B\":<25} {+0.44:>+10.2f} {+0.36:>+10.2f} {-0.17:>+10.2f}')\n",
    "print(f'{\"Llama-3.1-8B Base\":<25} {+0.05:>+10.2f} {-0.16:>+10.2f} {-0.30:>+10.2f}')\n",
    "print(f'{\"Llama-3.1 Instruct+Templ\":<25} {-0.47:>+10.2f} {-0.58:>+10.2f} {-0.60:>+10.2f}')\n",
    "print(f'{MODEL_DISPLAY:<25} {early_mean:>+10.2f} {mid_mean:>+10.2f} {late_mean:>+10.2f}')\n\n",
    "# Check late layer inversion\n",
    "final_layer = LAYERS_TO_TEST[-1]\n",
    "final_r = results[final_layer]['r']\n",
    "print(f'\\nFinal layer ({final_layer}) correlation: r = {final_r:+.3f}')\n",
    "if final_r < -0.1 and results[final_layer]['sig']:\n",
    "    print('>>> LATE-LAYER INVERSION CONFIRMED <<<')\n",
    "elif final_r < 0:\n",
    "    print('>>> Negative trend in late layer (not significant) <<<')\n",
    "else:\n",
    "    print('>>> NO late-layer inversion <<<')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n\n",
    "layers = list(results.keys())\n",
    "rs = [results[l]['r'] for l in layers]\n",
    "ci_los = [results[l]['ci_lo'] for l in layers]\n",
    "ci_his = [results[l]['ci_hi'] for l in layers]\n\n",
    "yerr_lo = [r - ci_lo for r, ci_lo in zip(rs, ci_los)]\n",
    "yerr_hi = [ci_hi - r for r, ci_hi in zip(rs, ci_his)]\n\n",
    "ax.errorbar(layers, rs, yerr=[yerr_lo, yerr_hi], fmt='o-', capsize=5, \n",
    "            capthick=2, markersize=8, color='green', label=MODEL_DISPLAY)\n\n",
    "# Mark significant\n",
    "for l, r in zip(layers, rs):\n",
    "    if results[l]['sig']:\n",
    "        ax.scatter([l], [r], color='red', s=150, zorder=5, marker='*')\n\n",
    "ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Layer', fontsize=12)\n",
    "ax.set_ylabel('r(centroid_asymmetry, output)', fontsize=12)\n",
    "ax.set_title(f'{MODEL_DISPLAY}: Layer-wise Correlation\\nPattern: {pattern}', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n\n",
    "plt.tight_layout()\n",
    "plt.savefig('gemma_layer_analysis.png', dpi=150)\n",
    "plt.show()\n",
    "print('Plot saved')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "save_data = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': MODEL_NAME,\n",
    "    'model_display': MODEL_DISPLAY,\n",
    "    'model_type': 'SFT (Supervised Fine-Tuning)',\n",
    "    'n_layers': N_LAYERS,\n",
    "    'layers_tested': LAYERS_TO_TEST,\n",
    "    'n_pairs': len(pair_data),\n",
    "    'n_bootstrap': N_BOOTSTRAP,\n",
    "    'results': {str(k): v for k, v in results.items()},\n",
    "    'phase_structure': {\n",
    "        'early_mean': float(early_mean),\n",
    "        'mid_mean': float(mid_mean),\n",
    "        'late_mean': float(late_mean),\n",
    "        'pattern': pattern\n",
    "    }\n",
    "}\n\n",
    "fname = f'gemma_cross_validation_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(save_data, f, indent=2)\n",
    "print(f'Saved: {fname}')\n\n",
    "from google.colab import files\n",
    "files.download(fname)\n",
    "files.download('gemma_layer_analysis.png')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}